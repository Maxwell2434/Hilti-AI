{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8N1ZTVYl06v"
      },
      "source": [
        "## Requirements and setup\n",
        "\n",
        "* Local NVIDIA GPU (I used a NVIDIA RTX 4090 on a Windows 11 machine) or Google Colab with access to a GPU.\n",
        "* Environment setup (see [setup details on GitHub](https://github.com/mrdbourke/simple-local-rag/?tab=readme-ov-file#setup)).\n",
        "* Data source (for example, a PDF).\n",
        "* Internet connection (to download the models, but once you have them, it'll run offline)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IB-1Zkd-l06v"
      },
      "outputs": [],
      "source": [
        "# Perform Google Colab installs (if running in Google Colab)\n",
        "import os\n",
        "\n",
        "if \"COLAB_GPU\" in os.environ:\n",
        "    print(\"[INFO] Running in Google Colab, installing requirements.\")\n",
        "    !pip install -U torch # requires torch 2.1.1+ (for efficient sdpa implementation)\n",
        "    !pip install PyMuPDF # for reading PDFs with Python\n",
        "    !pip install tqdm # for progress bars\n",
        "    !pip install sentence-transformers # for embedding models\n",
        "    !pip install accelerate # for quantization model loading\n",
        "    !pip install bitsandbytes # for quantizing models (less storage space)\n",
        "    !pip install flash-attn --no-build-isolation # for faster attention mechanism = faster LLM inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeBms9dWl06w"
      },
      "source": [
        "## 1. Document/Text Processing and Embedding Creation\n",
        "\n",
        "Ingredients:\n",
        "* PDF document of choice.\n",
        "* Embedding model of choice.\n",
        "\n",
        "Steps:\n",
        "1. Import PDF document.\n",
        "2. Process text for embedding (e.g. split into chunks of sentences).\n",
        "3. Embed text chunks with embedding model.\n",
        "4. Save embeddings to file for later use (embeddings will store on file for many years or until you lose your hard drive)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZzYVFeKl06w"
      },
      "source": [
        "### Import PDF Document\n",
        "\n",
        "This will work with many other kinds of documents.\n",
        "\n",
        "However, we'll start with PDF since many people have PDFs.\n",
        "\n",
        "But just keep in mind, text files, email chains, support documentation, articles and more can also work.\n",
        "\n",
        "We're going to pretend we're nutrition students at the University of Hawai'i, reading through the open-source PDF textbook [*Human Nutrition: 2020 Edition*](https://pressbooks.oer.hawaii.edu/humannutrition2/).\n",
        "\n",
        "There are several libraries to open PDFs with Python but I found that [PyMuPDF](https://github.com/pymupdf/pymupdf) works quite well in many cases.\n",
        "\n",
        "First we'll download the PDF if it doesn't exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "YBGE8j95l06w",
        "outputId": "b04233c3-8a6c-4fe2-9d5c-30285c691354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hiltipdfs\\Hilti Malaysia - Terms and Conditions 2019.pdf\n",
            "Hiltipdfs\\Hilti-Submittal-Package-OSHA-1926.1153.pdf\n",
            "Hiltipdfs\\Hilti_BindingCorporateRules.pdf\n",
            "Hiltipdfs\\Hilti_GB_2020_en_pdf.pdf\n",
            "Hiltipdfs\\Technical-information-ASSET-DOC-LOC-10908813.pdf\n"
          ]
        }
      ],
      "source": [
        "# Download PDF file\n",
        "#import os\n",
        "#import requests\n",
        "#\n",
        "## Get PDF document\n",
        "#pdf_path = \"human-nutrition-text.pdf\"\n",
        "#\n",
        "## Download PDF if it doesn't already exist\n",
        "#if not os.path.exists(pdf_path):\n",
        "#  print(\"File doesn't exist, downloading...\")\n",
        "#\n",
        "#  # The URL of the PDF you want to download\n",
        "#  url = \"https://pressbooks.oer.hawaii.edu/humannutrition2/open/download?type=pdf\"\n",
        "#\n",
        "#  # The local filename to save the downloaded file\n",
        "#  filename = pdf_path\n",
        "#\n",
        "#  # Send a GET request to the URL\n",
        "#  response = requests.get(url)\n",
        "#\n",
        "#  # Check if the request was successful\n",
        "#  if response.status_code == 200:\n",
        "#      # Open a file in binary write mode and save the content to it\n",
        "#      with open(filename, \"wb\") as file:\n",
        "#          file.write(response.content)\n",
        "#      print(f\"The file has been downloaded and saved as {filename}\")\n",
        "#  else:\n",
        "#      print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
        "#else:\n",
        "#  print(f\"File {pdf_path} exists.\")\n",
        "import os\n",
        "\n",
        "folder_path = 'Hiltipdfs' # replace with the path to your folder\n",
        "pdf_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
        "\n",
        "for pdf_path in pdf_paths:\n",
        "    print(pdf_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pBQjhIgl06x"
      },
      "source": [
        "PDF acquired!\n",
        "\n",
        "We can import the pages of our PDF to text by first defining the PDF path and then opening and reading it with PyMuPDF (`import fitz`).\n",
        "\n",
        "We'll write a small helper function to preprocess the text as it gets read. Note that not all text will be read in the same so keep this in mind for when you prepare your text.\n",
        "\n",
        "We'll save each page to a dictionary and then append that dictionary to a list for ease of use later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "357da8cd990d4ec494ca9bb7110a0b47"
          ]
        },
        "id": "4scku8g1l06x",
        "outputId": "b02a2752-cd4b-47cc-caa9-9c1030ecf34a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12it [00:00, 206.42it/s]\n",
            "5it [00:00, 228.25it/s]\n",
            "19it [00:00, 226.66it/s]\n",
            "45it [00:00, 157.97it/s]\n",
            "1it [00:00, 34.53it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'page_number': 1,\n",
              "  'pdf_name': 'Hilti Malaysia - Terms and Conditions 2019.pdf',\n",
              "  'page_char_count': 2282,\n",
              "  'page_word_count': 451,\n",
              "  'page_sentence_count_raw': 11,\n",
              "  'page_token_count': 570.5,\n",
              "  'text': 'Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | Sime Darby Brunsfield Tower  No. 2 | Jalan PJU 1A/7A  Oasis Square I Oasis Damansara  47301 Petaling Jaya I Selangor I Malaysia  Toll Free 1800 880 985 | F +603 7848 7399 | www.hilti.com.my  HILTI (MALAYSIA) SDN. BHD.  TERMS AND CONDITIONS      1.   GENERAL    1.1   In these conditions the following words have the meanings shown:     \"Buyer\"   means the person, firm or company purchasing Goods       \"Company\" means Hilti (Malaysia) Sdn Bhd or one of its associated or subsidiary  companies as the case may be       \"Contract\"  means the agreement between the Company and the Buyer for the  purchase of Goods from the Company by the Buyer        \"Contracts\" includes all agreements between the Company and the Buyer for the  purchase of Goods from the Company by the Buyer        \"Goods\"  means the goods and services supplied by the Company and  purchased by the Buyer on the terms of the Contract     “Saleable means those unused items in original packaging, Condition” defect-free  and in unbroken quantities    1.2   Unless agreed otherwise, these conditions shall be incorporated in all Contracts of  the Company to sell Goods and shall be the entire conditions under which the sale  takes place. All other terms, conditions or other representations are excluded from  the Contracts between the Buyer and the Company including any terms and  conditions which the Buyer may purport to apply under any order for Goods.    1.3   These conditions shall prevail unless expressly varied in writing and signed by a  Director on behalf of the Company.    1.4   No statement, description, information, warranty, condition or recommendation  contained in any catalogue, price list, advertisement or communication or made  verbally by any of the agents or employees of the Company shall be construed to  vary in any way any of the conditions under this Contract unless otherwise agreed in  accordance with Clause 1.3 above.    1.5   Any written quotation, estimate and/or advertised price for the Goods shall be an  invitation to treat and no binding contract shall be created by placing an order on the  Company’s website or otherwise until the Company has acknowledged the order to  the Buyer either verbally or in writing as appropriate.'},\n",
              " {'page_number': 2,\n",
              "  'pdf_name': 'Hilti Malaysia - Terms and Conditions 2019.pdf',\n",
              "  'page_char_count': 2776,\n",
              "  'page_word_count': 562,\n",
              "  'page_sentence_count_raw': 18,\n",
              "  'page_token_count': 694.0,\n",
              "  'text': \"Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | Sime Darby Brunsfield Tower  No. 2 | Jalan PJU 1A/7A  Oasis Square I Oasis Damansara  47301 Petaling Jaya I Selangor I Malaysia  Toll Free 1800 880 985 | F +603 7848 7399 | www.hilti.com.my  2.   PRICE    2.1   Subject to Clause 2.2 below, the price payable for Goods shall, unless otherwise  stated by the Company in writing and agreed on its behalf, be the price list of the  Company current at the date of dispatch and in the case of an order for delivery by  installments the price payable for each installment shall be the Company's current  price list at the date of the dispatch of each installment.    2.2   Unless otherwise agreed, the Company's prices may be subject to variation to take  account of variations in wages, materials or other costs since the date of the  Company's quotation (or if no quotation is issued) the Buyer's order. The Company  accordingly reserves the right to adjust on reasonable basis (reasonable objection by  the Buyer not unreasonable withheld) the invoice price payable by the amount of any  increase or decrease in such costs after the price is quoted via notice in writing to the  Buyer and the invoice so adjusted shall be payable as if it were the original Contract  price.    2.3   All prices are exclusive of Goods and Services Tax. The Buyer shall be liable for all  and any local taxes or charges as appropriate.    2.4   The Buyer agrees that section 39(3) of the Sale of Goods Act 1957 (Act 32) (“the  Act”) shall not apply to Goods sent by the Company.    2.5   The Company shall be entitled to invoice the Buyer by post, facsimile or email for the  price of the Goods in Ringgit Malaysia or such other currency as the Company shall  agree in writing.    2.6   The Company has the right to invoice the Buyer for the cost of any packaging,  transportation of the Goods or any additional costs resulting from any other alteration  made by the Buyer on or at the time of delivery or upon notification by the Company  that the Goods are awaiting collection. Any such additional costs may be invoiced by  the Company in Ringgit Malaysia or such other currency as the Company shall agree  in writing.      3.   FUEL SURCHARGE/ CARRIAGE AND INSURANCE    3.1   The cost of fuel surcharge to the Buyer's premises in Malaysia shall be in accordance  with the charges pre-agreed between the Buyer and the Company.    3.2   The cost of carriage and insurance of the Goods to the Buyer’s premises in Malaysia  shall be in accordance with the charges laid out in the Company’s current price list.    3.3   In all other cases the price of the Goods shall be exclusive of carriage and insurance  to the Buyer's premises.    3.4   Export orders shall be charged Free On Board (port of Malaysia).\"}]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Requires !pip install PyMuPDF, see: https://github.com/pymupdf/pymupdf\n",
        "import fitz # (pymupdf, found this is better than pypdf for our use case, note: licence is AGPL-3.0, keep that in mind if you want to use any code commercially)\n",
        "from tqdm.auto import tqdm # for progress bars, requires !pip install tqdm\n",
        "\n",
        "def text_formatter(text: str) -> str:\n",
        "    \"\"\"Performs minor formatting on text.\"\"\"\n",
        "    cleaned_text = text.replace(\"\\n\", \" \").strip() # note: this might be different for each doc (best to experiment)\n",
        "\n",
        "    # Other potential text formatting functions can go here\n",
        "    return cleaned_text\n",
        "\n",
        "# Open PDF and get lines/pages\n",
        "# Note: this only focuses on text, rather than images/figures etc\n",
        "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Opens a PDF file, reads its text content page by page, and collects statistics.\n",
        "\n",
        "    Parameters:\n",
        "        pdf_path (str): The file path to the PDF document to be opened and read.\n",
        "\n",
        "    Returns:\n",
        "        list[dict]: A list of dictionaries, each containing the page number\n",
        "        (adjusted), character count, word count, sentence count, token count, and the extracted text\n",
        "        for each page.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_path)  # open a document\n",
        "    pdf_name = os.path.basename(pdf_path)\n",
        "    pages_and_texts = []\n",
        "    for page_number, page in tqdm(enumerate(doc)):  # iterate the document pages\n",
        "        text = page.get_text()  # get plain text encoded as UTF-8\n",
        "        text = text_formatter(text)\n",
        "        pages_and_texts.append({\"page_number\": page_number + 1, \n",
        "                                \"pdf_name\": pdf_name,\n",
        "                                \"page_char_count\": len(text),\n",
        "                                \"page_word_count\": len(text.split(\" \")),\n",
        "                                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
        "                                \"page_token_count\": len(text) / 4,  # 1 token = ~4 chars, see: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
        "                                \"text\": text})\n",
        "    return pages_and_texts\n",
        "\n",
        "\n",
        "pages_and_texts = []\n",
        "for pdf_path in pdf_paths:\n",
        "    pages_and_texts.extend(open_and_read_pdf(pdf_path=pdf_path))\n",
        "pages_and_texts[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lts3_uJ3l06x"
      },
      "source": [
        "Now let's get a random sample of the pages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "OtKr1pQul06x",
        "outputId": "9002ee73-521b-4425-d929-bc294858bc2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'page_number': 7,\n",
              "  'pdf_name': 'Hilti_BindingCorporateRules.pdf',\n",
              "  'page_char_count': 5705,\n",
              "  'page_word_count': 935,\n",
              "  'page_sentence_count_raw': 24,\n",
              "  'page_token_count': 1426.25,\n",
              "  'text': 'www.hilti.group 7 Data Processing Agreements and contractual relation- ship with Processors Controller instructs Processors to perform its processing  activities. Controller conducts due diligence and assesses  such processing activities to ensure that they meet Controller’s  standards. They are monitored periodically to ensure that  they ensure continuous implementation of organizational  and technical measures. Controller ensures proper contractual safeguards are in  place by means of a written agreement (DPA). Such agreement  is signed before conducting any processing activity and  includes all data protection legal requirements to govern the  parties’ contractual relationship. Where processing is to be carried out on behalf of a Controller,  the Controller shall use only Processors providing   sufficient guarantees to implement appropriate TOMs in  such a manner that processing will meet the requirements of  the herewith BCR and ensure the protection of the Data   Subjects’ rights. The DPA stipulates that Processor must and as provided by  Article 28(3) GDPR: •\\t Process Personal Data solely under written instructions from Controller, including with regards to transfers of Personal Data to a non-EEA country or organization •\\t \\t Ensure persons authorized to process the Personal Data have committed themselves to confidentiality or are under an appropriate statutory obligation of confidentiality •\\t \\t Ensure it has taken all appropriate TOMs •\\t \\t Only engages another Processor (Sub-Processor) with prior specific or general written authorization of the Controller and apply the same data protection obligations as set out in the contract or other legal act between the Controller and the Processor •\\t \\t Be held liable for any violation of its sub-Processors to the herewith BCR •\\t \\t Assist Controller with Data Subject Rights and complaints processes •\\t \\t Assists the Controller in ensuring compliance with the obligations pursuant to Articles 32 to 36 GDPR considering the nature of processing and the information available to the Processor •\\t \\t Either return or delete Personal Data processed in accordance with the Data Processing Agreement instructions •\\t \\t Make available to Controller all necessary information in order to demonstrate compliance with the BCR as well as contributing to audits •\\t \\t Immediately inform the Controller where an instruction may infringe GDPR or national data protection laws Furthermore, DPAs contain at least the following information  with regards to the processing activity: •\\t The subject-matter and duration of the processing •\\t The nature and purpose of the processing •\\t The type of Personal Data and categories of Data Subjects •\\t The obligations and rights of the Controller Personal Data Breach management process While Hilti processes Personal Data in accordance with  state-of-the-art TOMs, it also ensures a proper legal frame- work and implements incident response guidelines. Hilti has  established a Personal Data Breach process to anticipate  incidents. This process allows Hilti to ensure that the risks or  impacts for Data Subject rights and freedoms are mitigated  as much as possible or entirely prevented. Therefore, as soon as becoming aware of a Personal Data  Breach, Hilti Entities have a duty to report it to the Hilti HQ  without undue delay. Hilti HQ will take applicable preventive measures and ensure  that the relevant data protection, IT and security functions  and bodies are involved to conduct investigations, mitigation  measures and report adequately on the matter. Throughout this event, Hilti HQ will assess the situation to  ensure it meets its obligations of notification to the Supervisory  Authorities. Hilti will notify the competent Supervisory   Authority without undue delay, and where feasible no later  than 72 hours after having become aware of the Personal  Data Breach. Should the 72-hour period not be met, reason  must be given for the delay. Hilti will also inform Data   Subjects, should Hilti not be able to mitigate the   consequences of a Personal Data Breach which is likely to  result in a high risk for Data Subjects’ rights and freedoms. Any Personal Data breach is documented (comprising the  facts relating to the Personal Data Breach, its effects and  the remedial action taken). Such documentation is made  available to the Supervisory Authority on request. Requirements in respect of transfers and onward  transfers to Third-Parties not bound by the BCR Any transfer or onward transfers of Personal Data which are  undergoing processing or are intended for processing after  transfer to a third country or to an international organization  shall take place only if all provisions in Chapter V GDPR are  complied with.  A transfer or onward transfer may take place if a transfer  mechanism as described in the following table applies: # Transfer  mechanism Description 1. Transfers based  on an adequacy  decision A transfer of Personal Data to a third  country or an international organisa- tion may take place where the  European Commission has decided  that the third country, a territory or  one or more specified sectors within  that third country, or the international  organisation in question ensures an  adequate level of protection. Such a  transfer shall not require any specific  authorisation. 2. Standard Data  Protection  Clauses adopted  by the European  Commission Contractual clauses ensuring  appropriate data protection safe- guards can be used as a ground for  data transfers from the EU to third  countries. This includes model  contract clauses – so-called   standard contractual clauses (SCC)  – that have been “pre-approved” by the European Commission.'},\n",
              " {'page_number': 5,\n",
              "  'pdf_name': 'Hilti Malaysia - Terms and Conditions 2019.pdf',\n",
              "  'page_char_count': 2938,\n",
              "  'page_word_count': 572,\n",
              "  'page_sentence_count_raw': 16,\n",
              "  'page_token_count': 734.5,\n",
              "  'text': 'Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | Sime Darby Brunsfield Tower  No. 2 | Jalan PJU 1A/7A  Oasis Square I Oasis Damansara  47301 Petaling Jaya I Selangor I Malaysia  Toll Free 1800 880 985 | F +603 7848 7399 | www.hilti.com.my  Saleable condition is defined as those unused items in original packaging, defect- free and in unbroken quantities. All returns are subject to Hilti inspection and  acceptance. Request for return after 2 weeks of delivery will not be accepted. Non- stocking, non-standard items and discontinued items are not eligible for return credit.    7.2   The following products are not eligible for return,  a)  All Chemical products  b)  Products specially purchased / ordered for customer  c)  Products sold under promotion or selloff      8.   PASSING OF TITLE AND RISK    8.1   From the date of delivery to the Buyer the Goods shall be at the risk of the Buyer who  shall be solely responsible for their custody and maintenance, but unless otherwise  expressly agreed in writing, the Goods shall remain the property of the Company until  all payments due to the Company from the Buyer under the Contract or any other  contract have been made in full unconditionally and credited to the Company’s  account. Whilst the ownership of the Company continues the Buyer shall keep the  Goods separate and identifiable from all other goods in its possession as fiduciary  agent and bailee for the Company.    8.2   In the event of any resale by the Buyer of the Goods the beneficial entitlement of the  Company shall attach to the proceeds of the sale or other disposition thereof, so that  such proceeds or any claim thereof shall be assigned to the Company.    8.3   In the event of failure to pay the price in accordance with the Contract, the Company  shall have the power to re-sell the Goods, such power being additional to (and not in  substitution for) any other power of sale arising by operation of law or implication or  otherwise and for such purpose the Company and its servants and agents may  forthwith enter upon any premises or land occupied or owned by the Buyer to remove  the Goods.    8.4   Pending payment of the full purchase price of the Goods, the Buyer shall at all times  keep the Goods comprehensively insured against loss or damage by accident, fire,  theft and other risks usually covered by insurance in the type of business for which  the Goods are for the time being used in an amount at least equal to the balance of  the price for the same time to time remaining outstanding. The policy shall bear an  endorsement recording the Company’s interest and shall be produced to the  Company on request.      9.   REPAIR POLICY    9.1   The Hilti Lifetime Service means that the tool will be free from defects caused by  manufacture for a period of twelve (12) months from the date the invoice is issued  by Hilti, depending on the tool model, Provided That the tool is operated, handled,'},\n",
              " {'page_number': 9,\n",
              "  'pdf_name': 'Hilti_GB_2020_en_pdf.pdf',\n",
              "  'page_char_count': 287,\n",
              "  'page_word_count': 45,\n",
              "  'page_sentence_count_raw': 2,\n",
              "  'page_token_count': 71.75,\n",
              "  'text': 'Operational Excellence Direct   Customer Relationship High-Performing Global Team Product and Service Differentiation We are investing  in continuous  innovation to  provide our  customers  products, systems,  software and  services that are  world-class. 2020 Hilti Company Report 12–13'}]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "random.sample(pages_and_texts, k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBF_nevfl06y"
      },
      "source": [
        "### Get some stats on the text\n",
        "\n",
        "Let's perform a rough exploratory data analysis (EDA) to get an idea of the size of the texts (e.g. character counts, word counts etc) we're working with.\n",
        "\n",
        "The different sizes of texts will be a good indicator into how we should split our texts.\n",
        "\n",
        "Many embedding models have limits on the size of texts they can ingest, for example, the [`sentence-transformers`](https://www.sbert.net/docs/pretrained_models.html) model [`all-mpnet-base-v2`](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) has an input size of 384 tokens.\n",
        "\n",
        "This means that the model has been trained in ingest and turn into embeddings texts with 384 tokens (1 token ~= 4 characters ~= 0.75 words).\n",
        "\n",
        "Texts over 384 tokens which are encoded by this model will be auotmatically reduced to 384 tokens in length, potentially losing some information.\n",
        "\n",
        "We'll discuss this more in the embedding section.\n",
        "\n",
        "For now, let's turn our list of dictionaries into a DataFrame and explore it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "FHlCczGEl06y",
        "outputId": "53ed0141-ee5b-4f06-a494-264d291d3e82"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_number</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>page_char_count</th>\n",
              "      <th>page_word_count</th>\n",
              "      <th>page_sentence_count_raw</th>\n",
              "      <th>page_token_count</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
              "      <td>2282</td>\n",
              "      <td>451</td>\n",
              "      <td>11</td>\n",
              "      <td>570.50</td>\n",
              "      <td>Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
              "      <td>2776</td>\n",
              "      <td>562</td>\n",
              "      <td>18</td>\n",
              "      <td>694.00</td>\n",
              "      <td>Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
              "      <td>2728</td>\n",
              "      <td>558</td>\n",
              "      <td>16</td>\n",
              "      <td>682.00</td>\n",
              "      <td>Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
              "      <td>2867</td>\n",
              "      <td>595</td>\n",
              "      <td>14</td>\n",
              "      <td>716.75</td>\n",
              "      <td>Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
              "      <td>2938</td>\n",
              "      <td>572</td>\n",
              "      <td>16</td>\n",
              "      <td>734.50</td>\n",
              "      <td>Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   page_number                                        pdf_name  \\\n",
              "0            1  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
              "1            2  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
              "2            3  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
              "3            4  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
              "4            5  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
              "\n",
              "   page_char_count  page_word_count  page_sentence_count_raw  \\\n",
              "0             2282              451                       11   \n",
              "1             2776              562                       18   \n",
              "2             2728              558                       16   \n",
              "3             2867              595                       14   \n",
              "4             2938              572                       16   \n",
              "\n",
              "   page_token_count                                               text  \n",
              "0            570.50  Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...  \n",
              "1            694.00  Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...  \n",
              "2            682.00  Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...  \n",
              "3            716.75  Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...  \n",
              "4            734.50  Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(pages_and_texts)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "E309vNgjl06y",
        "outputId": "aadb5639-f30b-43bc-c27f-663bbbd658dd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_number</th>\n",
              "      <th>page_char_count</th>\n",
              "      <th>page_word_count</th>\n",
              "      <th>page_sentence_count_raw</th>\n",
              "      <th>page_token_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>82.00</td>\n",
              "      <td>82.00</td>\n",
              "      <td>82.00</td>\n",
              "      <td>82.00</td>\n",
              "      <td>82.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>16.09</td>\n",
              "      <td>2346.77</td>\n",
              "      <td>409.88</td>\n",
              "      <td>12.72</td>\n",
              "      <td>586.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.84</td>\n",
              "      <td>1861.12</td>\n",
              "      <td>318.34</td>\n",
              "      <td>10.33</td>\n",
              "      <td>465.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.25</td>\n",
              "      <td>982.00</td>\n",
              "      <td>162.25</td>\n",
              "      <td>6.00</td>\n",
              "      <td>245.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>12.00</td>\n",
              "      <td>1802.50</td>\n",
              "      <td>301.50</td>\n",
              "      <td>9.00</td>\n",
              "      <td>450.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>24.75</td>\n",
              "      <td>3003.25</td>\n",
              "      <td>577.25</td>\n",
              "      <td>18.75</td>\n",
              "      <td>750.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>45.00</td>\n",
              "      <td>7394.00</td>\n",
              "      <td>1307.00</td>\n",
              "      <td>47.00</td>\n",
              "      <td>1848.50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
              "count        82.00            82.00            82.00                    82.00   \n",
              "mean         16.09          2346.77           409.88                    12.72   \n",
              "std          12.84          1861.12           318.34                    10.33   \n",
              "min           1.00             0.00             1.00                     1.00   \n",
              "25%           5.25           982.00           162.25                     6.00   \n",
              "50%          12.00          1802.50           301.50                     9.00   \n",
              "75%          24.75          3003.25           577.25                    18.75   \n",
              "max          45.00          7394.00          1307.00                    47.00   \n",
              "\n",
              "       page_token_count  \n",
              "count             82.00  \n",
              "mean             586.69  \n",
              "std              465.28  \n",
              "min                0.00  \n",
              "25%              245.50  \n",
              "50%              450.62  \n",
              "75%              750.81  \n",
              "max             1848.50  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get stats\n",
        "df.describe().round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDaFCDlsl06y"
      },
      "source": [
        "Okay, looks like our average token count per page is 287.\n",
        "\n",
        "For this particular use case, it means we could embed an average whole page with the `all-mpnet-base-v2` model (this model has an input capacity of 384)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSjT4dTfl06y"
      },
      "source": [
        "### Further text processing (splitting pages into sentences)\n",
        "\n",
        "The ideal way of processing text before embedding it is still an active area of research.\n",
        "\n",
        "A simple method I've found helpful is to break the text into chunks of sentences.\n",
        "\n",
        "As in, chunk a page of text into groups of 5, 7, 10 or more sentences (these values are not set in stone and can be explored).\n",
        "\n",
        "But we want to follow the workflow of:\n",
        "\n",
        "`Ingest text -> split it into groups/chunks -> embed the groups/chunks -> use the embeddings`\n",
        "\n",
        "Some options for splitting text into sentences:\n",
        "\n",
        "1. Split into sentences with simple rules (e.g. split on \". \" with `text = text.split(\". \")`, like we did above).\n",
        "2. Split into sentences with a natural language processing (NLP) library such as [spaCy](https://spacy.io/) or [nltk](https://www.nltk.org/).\n",
        "\n",
        "Why split into sentences?\n",
        "\n",
        "* Easier to handle than larger pages of text (especially if pages are densely filled with text).\n",
        "* Can get specific and find out which group of sentences were used to help within a RAG pipeline.\n",
        "\n",
        "> **Resource:** See [spaCy install instructions](https://spacy.io/usage).\n",
        "\n",
        "Let's use spaCy to break our text into sentences since it's likely a bit more robust than just using `text.split(\". \")`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "7kheP2iyl06y",
        "outputId": "d537727e-6dc6-4cd1-962c-48bfaadb2d66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[This is a sentence., This another sentence.]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from spacy.lang.en import English # see https://spacy.io/usage for install instructions\n",
        "\n",
        "nlp = English()\n",
        "\n",
        "# Add a sentencizer pipeline, see https://spacy.io/api/sentencizer/\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "# Create a document instance as an example\n",
        "doc = nlp(\"This is a sentence. This another sentence.\")\n",
        "assert len(list(doc.sents)) == 2\n",
        "\n",
        "# Access the sentences of the document\n",
        "list(doc.sents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKvNeALwl06y"
      },
      "source": [
        "We don't necessarily need to use spaCy, however, it's an open-source library designed to do NLP tasks like this at scale.\n",
        "\n",
        "So let's run our small sentencizing pipeline on our pages of text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "177454fcc3344b03b750eda50269c27f"
          ]
        },
        "id": "Qs-KNV6Rl06z",
        "outputId": "dac6a0b0-ab05-4fe6-d8a2-af4c1f8c9f64"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 17/82 [00:00<00:00, 164.28it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 82/82 [00:00<00:00, 197.04it/s]\n"
          ]
        }
      ],
      "source": [
        "for item in tqdm(pages_and_texts):\n",
        "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
        "\n",
        "    # Make sure all sentences are strings\n",
        "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
        "\n",
        "    # Count the sentences\n",
        "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ZOG_TGOgl06z",
        "outputId": "25946c61-eecf-4c8c-ab3b-9c1a2b488327"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'page_number': 23,\n",
              "  'pdf_name': 'Hilti_GB_2020_en_pdf.pdf',\n",
              "  'page_char_count': 1099,\n",
              "  'page_word_count': 185,\n",
              "  'page_sentence_count_raw': 7,\n",
              "  'page_token_count': 274.75,\n",
              "  'text': 'It took the Swiss retailer Migros Ostschweiz just one year to complete the  renovation of a shopping center in Schaffhausen. The team finished the work  twice as fast as if it would have with a traditional approach. This was possible because a  digital twin of the project, based on Building Information Modeling, or BIM, already  existed in 3D. All the project’s ideas, requirements and participants’ tasks are integrated  in the model and created the basis for the remodeling. Through our BIM Design Services  the Hilti team offered a comprehensive solution package, enabling the client to signifi- cantly improve the project workflow, including productivity drivers such as the BIM2Field    use of the new Jaibot construction site robot as well as advanced logistic services to  schedule the job site deliveries. The result: Thanks to transparent planning, on-time  delivery of the installation systems and the time-saving use of Jaibot, the project was  completed twice as fast as if the customer had taken a conventional approach. BUILDING TWICE AS FAST WITH BIM 2020 Hilti Company Report 40–41',\n",
              "  'sentences': ['It took the Swiss retailer Migros Ostschweiz just one year to complete the  renovation of a shopping center in Schaffhausen.',\n",
              "   'The team finished the work  twice as fast as if it would have with a traditional approach.',\n",
              "   'This was possible because a  digital twin of the project, based on Building Information Modeling, or BIM, already  existed in 3D. All the project’s ideas, requirements and participants’ tasks are integrated  in the model and created the basis for the remodeling.',\n",
              "   'Through our BIM Design Services  the Hilti team offered a comprehensive solution package, enabling the client to signifi- cantly improve the project workflow, including productivity drivers such as the BIM2Field    use of the new Jaibot construction site robot as well as advanced logistic services to  schedule the job site deliveries.',\n",
              "   'The result: Thanks to transparent planning, on-time  delivery of the installation systems and the time-saving use of Jaibot, the project was  completed twice as fast as if the customer had taken a conventional approach.',\n",
              "   'BUILDING TWICE AS FAST WITH BIM 2020 Hilti Company Report 40–41'],\n",
              "  'page_sentence_count_spacy': 6}]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inspect an example\n",
        "random.sample(pages_and_texts, k=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSQ5uTAYl06z"
      },
      "source": [
        "Wonderful!\n",
        "\n",
        "Now let's turn out list of dictionaries into a DataFrame and get some stats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "DM4vLozil06z",
        "outputId": "f9d581ba-afec-4e2d-ca4b-8b35ec6da15b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_number</th>\n",
              "      <th>page_char_count</th>\n",
              "      <th>page_word_count</th>\n",
              "      <th>page_sentence_count_raw</th>\n",
              "      <th>page_token_count</th>\n",
              "      <th>page_sentence_count_spacy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>82.00</td>\n",
              "      <td>82.00</td>\n",
              "      <td>82.00</td>\n",
              "      <td>82.00</td>\n",
              "      <td>82.00</td>\n",
              "      <td>82.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>16.09</td>\n",
              "      <td>2346.77</td>\n",
              "      <td>409.88</td>\n",
              "      <td>12.72</td>\n",
              "      <td>586.69</td>\n",
              "      <td>12.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.84</td>\n",
              "      <td>1861.12</td>\n",
              "      <td>318.34</td>\n",
              "      <td>10.33</td>\n",
              "      <td>465.28</td>\n",
              "      <td>9.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.25</td>\n",
              "      <td>982.00</td>\n",
              "      <td>162.25</td>\n",
              "      <td>6.00</td>\n",
              "      <td>245.50</td>\n",
              "      <td>6.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>12.00</td>\n",
              "      <td>1802.50</td>\n",
              "      <td>301.50</td>\n",
              "      <td>9.00</td>\n",
              "      <td>450.62</td>\n",
              "      <td>9.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>24.75</td>\n",
              "      <td>3003.25</td>\n",
              "      <td>577.25</td>\n",
              "      <td>18.75</td>\n",
              "      <td>750.81</td>\n",
              "      <td>18.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>45.00</td>\n",
              "      <td>7394.00</td>\n",
              "      <td>1307.00</td>\n",
              "      <td>47.00</td>\n",
              "      <td>1848.50</td>\n",
              "      <td>45.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
              "count        82.00            82.00            82.00                    82.00   \n",
              "mean         16.09          2346.77           409.88                    12.72   \n",
              "std          12.84          1861.12           318.34                    10.33   \n",
              "min           1.00             0.00             1.00                     1.00   \n",
              "25%           5.25           982.00           162.25                     6.00   \n",
              "50%          12.00          1802.50           301.50                     9.00   \n",
              "75%          24.75          3003.25           577.25                    18.75   \n",
              "max          45.00          7394.00          1307.00                    47.00   \n",
              "\n",
              "       page_token_count  page_sentence_count_spacy  \n",
              "count             82.00                      82.00  \n",
              "mean             586.69                      12.43  \n",
              "std              465.28                       9.99  \n",
              "min                0.00                       0.00  \n",
              "25%              245.50                       6.00  \n",
              "50%              450.62                       9.00  \n",
              "75%              750.81                      18.75  \n",
              "max             1848.50                      45.00  "
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(pages_and_texts)\n",
        "df.describe().round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-gtBTyml06z"
      },
      "source": [
        "For our set of text, it looks like our raw sentence count (e.g. splitting on `\". \"`) is quite close to what spaCy came up with.\n",
        "\n",
        "Now we've got our text split into sentences, how about we gorup those sentences?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rlKmn80l06z"
      },
      "source": [
        "### Chunking our sentences together\n",
        "\n",
        "Let's take a step to break down our list of sentences/text into smaller chunks.\n",
        "\n",
        "As you might've guessed, this process is referred to as **chunking**.\n",
        "\n",
        "Why do we do this?\n",
        "\n",
        "1. Easier to manage similar sized chunks of text.\n",
        "2. Don't overload the embedding models capacity for tokens (e.g. if an embedding model has a capacity of 384 tokens, there could be information loss if you try to embed a sequence of 400+ tokens).\n",
        "3. Our LLM context window (the amount of tokens an LLM can take in) may be limited and requires compute power so we want to make sure we're using it as well as possible.\n",
        "\n",
        "Something to note is that there are many different ways emerging for creating chunks of information/text.\n",
        "\n",
        "For now, we're going to keep it simple and break our pages of sentences into groups of 10 (this number is arbitrary and can be changed, I just picked it because it seemed to line up well with our embedding model capacity of 384).\n",
        "\n",
        "On average each of our pages has 10 sentences.\n",
        "\n",
        "And an average total of 287 tokens per page.\n",
        "\n",
        "So our groups of 10 sentences will also be ~287 tokens long.\n",
        "\n",
        "This gives us plenty of room for the text to embedded by our `all-mpnet-base-v2` model (it has a capacity of 384 tokens).\n",
        "\n",
        "To split our groups of sentences into chunks of 10 or less, let's create a function which accepts a list as input and recursively breaks into down into sublists of a specified size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "d37ee16f5d1f4f46bb489856aaeaa677"
          ]
        },
        "id": "4iyR-CzNl06z",
        "outputId": "cb031f45-1db2-4b79-8553-49cc26b1b2bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 82/82 [00:00<?, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "# Define split size to turn groups of sentences into chunks\n",
        "num_sentence_chunk_size = 8\n",
        "\n",
        "# Create a function that recursively splits a list into desired sizes\n",
        "def split_list(input_list: list,\n",
        "               slice_size: int) -> list[list[str]]:\n",
        "    \"\"\"\n",
        "    Splits the input_list into sublists of size slice_size (or as close as possible).\n",
        "\n",
        "    For example, a list of 17 sentences would be split into two lists of [[10], [7]]\n",
        "    \"\"\"\n",
        "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
        "\n",
        "# Loop through pages and texts and split sentences into chunks\n",
        "for item in tqdm(pages_and_texts):\n",
        "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
        "                                         slice_size=num_sentence_chunk_size)\n",
        "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "iUnGrtuSl06z",
        "outputId": "9558eb0b-5d81-4011-d5ce-dc29ae67bfe9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'page_number': 39,\n",
              "  'pdf_name': 'Hilti_GB_2020_en_pdf.pdf',\n",
              "  'page_char_count': 2715,\n",
              "  'page_word_count': 493,\n",
              "  'page_sentence_count_raw': 8,\n",
              "  'page_token_count': 678.75,\n",
              "  'text': '15.7 481 521 546 13.3 13.0 12.9 21.0 21.1 20.6 604 681 728 245 248 325 280 311 355 591 531 19.8 16.4 303 459 13.3 13.7 367 358 783 728 5,659 5,113 4,633 5,900 5,332 29,004 24,619 26,881 30,006 29,549 515 1,031 474 1,114 1,140 595 55 272 18.4 53 53 243 264 20.1 19.3 334 289 289 1,029 1,080 1,114 1,333 0 51 53 294 412 345 18.6 * Includes lease liabilities starting from 2019 due to the adaption of IFRS 16 Leases.  2017 numbers have been restated due to the adoption of IFRS 9 Financial instruments and IFRS 15 Revenue from Contracts with Customers. Numbers  prior to 2017 have not been restated.  Please note The following pages contain extracts from the 2020 Financial Report of the Hilti Group. Because these pages do not contain the full consolidated financial  statements, they do not present complete information about the financial position, financial performance and cash flows of the Hilti Group for 2020.  Complete information, including the notes to the consolidated financial statements, is contained in the 2020 Financial Report, which will be available on  the Group’s website (www.hilti.group) from late March 2021. The full 2020 consolidated financial statements, which are included in the 2020 Financial  Report, have been prepared in accordance with International Financial Reporting Standards (IFRS). KEY FIGURES Total equity  in % total equity and liabilities Capital expenditures on intangible assets  and on property, plant and equipment  in CHF million Cash and cash equivalents  in CHF million Dividend in CHF million Return on equity (ROE)  in % net income Financial debts* in CHF million 1,200 1,000 800 600 400 200 1,400 1,300 1,200 1,100 1,000 900 60 57 54 51 48 45 320 290 260 230 200 170 21.0 19.0 17.0 15.0 13.0 11.0 500 400 300 200 100 0 2018 2016 2019 2017 2018 2016 2019 2017 2018 2016 2019 2017 2018 2016 2019 2017 2018 2016 2019 2017 2018 2016 2019 2017 2020 2020 2020 2020 2020 2020 Return on sales (ROS) in % Employees at December 31 Net income in CHF million Research and development expenditure  in CHF million Return on capital employed (ROCE) in % Net sales in CHF million Operating result in CHF million Free cash flow in CHF million (before acquisition and disposal of  subsidiaries, including lease payments) 600 550 500 450 400 350 2018 2016 2019 2017 14.0 13.0 12.0 11.0 10.0 10.0 2018 2016 2019 2017 22.0 18.0 14.0 10.0 6.0 2.0 2018 2016 2019 2017 800 700 600 500 400 300 2018 2016 2019 2017 500 400 300 200 100 0 2016 2018 2017 2018 400 350 300 250 200 150 2018 2016 2019 2017 2020 2020 2020 2020 2020 2020 2018 2016 2019 2017 6,000 5,500 5,000 4,500 4,000 3,500 2020 32,000 29,000 26,000 23,000 20,000 17,000 2018 2016 2019 2017 2020 2020 Hilti Company Report 72–73',\n",
              "  'sentences': ['15.7 481 521 546 13.3 13.0 12.9 21.0 21.1 20.6 604 681 728 245 248 325 280 311 355 591 531 19.8 16.4 303 459 13.3 13.7 367 358 783 728 5,659 5,113 4,633 5,900 5,332 29,004 24,619 26,881 30,006 29,549 515 1,031 474 1,114 1,140 595 55 272 18.4 53 53 243 264 20.1 19.3 334 289 289 1,029 1,080 1,114 1,333 0 51 53 294 412 345 18.6 * Includes lease liabilities starting from 2019 due to the adaption of IFRS 16 Leases.',\n",
              "   ' 2017 numbers have been restated due to the adoption of IFRS 9 Financial instruments and IFRS 15 Revenue from Contracts with Customers.',\n",
              "   'Numbers  prior to 2017 have not been restated.',\n",
              "   ' Please note The following pages contain extracts from the 2020 Financial Report of the Hilti Group.',\n",
              "   'Because these pages do not contain the full consolidated financial  statements, they do not present complete information about the financial position, financial performance and cash flows of the Hilti Group for 2020.',\n",
              "   ' Complete information, including the notes to the consolidated financial statements, is contained in the 2020 Financial Report, which will be available on  the Group’s website (www.hilti.group) from late March 2021.',\n",
              "   'The full 2020 consolidated financial statements, which are included in the 2020 Financial  Report, have been prepared in accordance with International Financial Reporting Standards (IFRS).',\n",
              "   'KEY FIGURES Total equity  in % total equity and liabilities Capital expenditures on intangible assets  and on property, plant and equipment  in CHF million Cash and cash equivalents  in CHF million Dividend in CHF million Return on equity (ROE)  in % net income Financial debts* in CHF million 1,200 1,000 800 600 400 200 1,400 1,300 1,200 1,100 1,000 900 60 57 54 51 48 45 320 290 260 230 200 170 21.0 19.0 17.0 15.0 13.0 11.0 500 400 300 200 100 0 2018 2016 2019 2017 2018 2016 2019 2017 2018 2016 2019 2017 2018 2016 2019 2017 2018 2016 2019 2017 2018 2016 2019 2017 2020 2020 2020 2020 2020 2020 Return on sales (ROS) in % Employees at December 31 Net income in CHF million Research and development expenditure  in CHF million Return on capital employed (ROCE) in % Net sales in CHF million Operating result in CHF million Free cash flow in CHF million (before acquisition and disposal of  subsidiaries, including lease payments) 600 550 500 450 400 350 2018 2016 2019 2017 14.0 13.0 12.0 11.0 10.0 10.0 2018 2016 2019 2017 22.0 18.0 14.0 10.0 6.0 2.0 2018 2016 2019 2017 800 700 600 500 400 300 2018 2016 2019 2017 500 400 300 200 100 0 2016 2018 2017 2018 400 350 300 250 200 150 2018 2016 2019 2017 2020 2020 2020 2020 2020 2020 2018 2016 2019 2017 6,000 5,500 5,000 4,500 4,000 3,500 2020 32,000 29,000 26,000 23,000 20,000 17,000 2018 2016 2019 2017 2020 2020 Hilti Company Report 72–73'],\n",
              "  'page_sentence_count_spacy': 8,\n",
              "  'sentence_chunks': [['15.7 481 521 546 13.3 13.0 12.9 21.0 21.1 20.6 604 681 728 245 248 325 280 311 355 591 531 19.8 16.4 303 459 13.3 13.7 367 358 783 728 5,659 5,113 4,633 5,900 5,332 29,004 24,619 26,881 30,006 29,549 515 1,031 474 1,114 1,140 595 55 272 18.4 53 53 243 264 20.1 19.3 334 289 289 1,029 1,080 1,114 1,333 0 51 53 294 412 345 18.6 * Includes lease liabilities starting from 2019 due to the adaption of IFRS 16 Leases.',\n",
              "    ' 2017 numbers have been restated due to the adoption of IFRS 9 Financial instruments and IFRS 15 Revenue from Contracts with Customers.',\n",
              "    'Numbers  prior to 2017 have not been restated.',\n",
              "    ' Please note The following pages contain extracts from the 2020 Financial Report of the Hilti Group.',\n",
              "    'Because these pages do not contain the full consolidated financial  statements, they do not present complete information about the financial position, financial performance and cash flows of the Hilti Group for 2020.',\n",
              "    ' Complete information, including the notes to the consolidated financial statements, is contained in the 2020 Financial Report, which will be available on  the Group’s website (www.hilti.group) from late March 2021.',\n",
              "    'The full 2020 consolidated financial statements, which are included in the 2020 Financial  Report, have been prepared in accordance with International Financial Reporting Standards (IFRS).',\n",
              "    'KEY FIGURES Total equity  in % total equity and liabilities Capital expenditures on intangible assets  and on property, plant and equipment  in CHF million Cash and cash equivalents  in CHF million Dividend in CHF million Return on equity (ROE)  in % net income Financial debts* in CHF million 1,200 1,000 800 600 400 200 1,400 1,300 1,200 1,100 1,000 900 60 57 54 51 48 45 320 290 260 230 200 170 21.0 19.0 17.0 15.0 13.0 11.0 500 400 300 200 100 0 2018 2016 2019 2017 2018 2016 2019 2017 2018 2016 2019 2017 2018 2016 2019 2017 2018 2016 2019 2017 2018 2016 2019 2017 2020 2020 2020 2020 2020 2020 Return on sales (ROS) in % Employees at December 31 Net income in CHF million Research and development expenditure  in CHF million Return on capital employed (ROCE) in % Net sales in CHF million Operating result in CHF million Free cash flow in CHF million (before acquisition and disposal of  subsidiaries, including lease payments) 600 550 500 450 400 350 2018 2016 2019 2017 14.0 13.0 12.0 11.0 10.0 10.0 2018 2016 2019 2017 22.0 18.0 14.0 10.0 6.0 2.0 2018 2016 2019 2017 800 700 600 500 400 300 2018 2016 2019 2017 500 400 300 200 100 0 2016 2018 2017 2018 400 350 300 250 200 150 2018 2016 2019 2017 2020 2020 2020 2020 2020 2020 2018 2016 2019 2017 6,000 5,500 5,000 4,500 4,000 3,500 2020 32,000 29,000 26,000 23,000 20,000 17,000 2018 2016 2019 2017 2020 2020 Hilti Company Report 72–73']],\n",
              "  'num_chunks': 1}]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sample an example from the group (note: many samples have only 1 chunk as they have <=10 sentences total)\n",
        "random.sample(pages_and_texts, k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "uUJfBxsCl06z",
        "outputId": "d54abd3b-6f66-4e2a-d906-930a2c2b648f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_number</th>\n",
              "      <th>page_char_count</th>\n",
              "      <th>page_word_count</th>\n",
              "      <th>page_sentence_count_raw</th>\n",
              "      <th>page_token_count</th>\n",
              "      <th>page_sentence_count_spacy</th>\n",
              "      <th>num_chunks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>82.00</td>\n",
              "      <td>82.00</td>\n",
              "      <td>82.00</td>\n",
              "      <td>82.00</td>\n",
              "      <td>82.00</td>\n",
              "      <td>82.00</td>\n",
              "      <td>82.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>16.09</td>\n",
              "      <td>2346.77</td>\n",
              "      <td>409.88</td>\n",
              "      <td>12.72</td>\n",
              "      <td>586.69</td>\n",
              "      <td>12.43</td>\n",
              "      <td>2.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.84</td>\n",
              "      <td>1861.12</td>\n",
              "      <td>318.34</td>\n",
              "      <td>10.33</td>\n",
              "      <td>465.28</td>\n",
              "      <td>9.99</td>\n",
              "      <td>1.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.25</td>\n",
              "      <td>982.00</td>\n",
              "      <td>162.25</td>\n",
              "      <td>6.00</td>\n",
              "      <td>245.50</td>\n",
              "      <td>6.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>12.00</td>\n",
              "      <td>1802.50</td>\n",
              "      <td>301.50</td>\n",
              "      <td>9.00</td>\n",
              "      <td>450.62</td>\n",
              "      <td>9.00</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>24.75</td>\n",
              "      <td>3003.25</td>\n",
              "      <td>577.25</td>\n",
              "      <td>18.75</td>\n",
              "      <td>750.81</td>\n",
              "      <td>18.75</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>45.00</td>\n",
              "      <td>7394.00</td>\n",
              "      <td>1307.00</td>\n",
              "      <td>47.00</td>\n",
              "      <td>1848.50</td>\n",
              "      <td>45.00</td>\n",
              "      <td>6.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
              "count        82.00            82.00            82.00                    82.00   \n",
              "mean         16.09          2346.77           409.88                    12.72   \n",
              "std          12.84          1861.12           318.34                    10.33   \n",
              "min           1.00             0.00             1.00                     1.00   \n",
              "25%           5.25           982.00           162.25                     6.00   \n",
              "50%          12.00          1802.50           301.50                     9.00   \n",
              "75%          24.75          3003.25           577.25                    18.75   \n",
              "max          45.00          7394.00          1307.00                    47.00   \n",
              "\n",
              "       page_token_count  page_sentence_count_spacy  num_chunks  \n",
              "count             82.00                      82.00       82.00  \n",
              "mean             586.69                      12.43        2.02  \n",
              "std              465.28                       9.99        1.22  \n",
              "min                0.00                       0.00        0.00  \n",
              "25%              245.50                       6.00        1.00  \n",
              "50%              450.62                       9.00        2.00  \n",
              "75%              750.81                      18.75        3.00  \n",
              "max             1848.50                      45.00        6.00  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a DataFrame to get stats\n",
        "df = pd.DataFrame(pages_and_texts)\n",
        "df.describe().round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2Ba1GK_l06z"
      },
      "source": [
        "Note how the average number of chunks is around 1.5, this is expected since many of our pages only contain an average of 10 sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_tMmt53l060"
      },
      "source": [
        "### Splitting each chunk into its own item\n",
        "\n",
        "We'd like to embed each chunk of sentences into its own numerical representation.\n",
        "\n",
        "So to keep things clean, let's create a new list of dictionaries each containing a single chunk of sentences with relative information such as page number as well statistics about each chunk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "94ccc5effc2e470d9c910dd607cbcaa9"
          ]
        },
        "id": "2rvkcj3cl060",
        "outputId": "113dd853-9ad0-407e-f97a-3287812d4ceb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 82/82 [00:00<00:00, 16510.63it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "166"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Split each chunk into its own item\n",
        "pages_and_chunks = []\n",
        "for item in tqdm(pages_and_texts):\n",
        "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
        "        chunk_dict = {}\n",
        "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
        "        chunk_dict[\"pdf_name\"] = item[\"pdf_name\"]\n",
        "\n",
        "        # Join the sentences together into a paragraph-like structure, aka a chunk (so they are a single string)\n",
        "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
        "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full-stop/capital letter combo\n",
        "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
        "\n",
        "        # Get stats about the chunk\n",
        "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
        "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
        "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n",
        "\n",
        "        pages_and_chunks.append(chunk_dict)\n",
        "\n",
        "# How many chunks do we have?\n",
        "len(pages_and_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ev-TlPkhl060",
        "outputId": "039e9445-4e02-43d1-8d36-b1c898a6a8b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'page_number': 6,\n",
              "  'pdf_name': 'Hilti_GB_2020_en_pdf.pdf',\n",
              "  'sentence_chunk': 'Optimized systems of innovative tools and fasteners provide additional speed on the construction site. Firestop Systems The correct installation of firestop sys- tems is decisive in helping prevent the spread of fire, smoke and toxic fumes. Hilti provides a comprehensive range of technical consulting services as well as efficient design and documen- tation software that deliver a higher level of safety from a single source. Diamond Systems Tools and cutting segments using Hilti diamond technology are built for high performance and low wear. Drilling, cutting, sawing and grinding concrete and other mineral building materials is easy and achieves maximum accura- cy and efficiency while keeping dust and vibration to a minimum. Measuring Systems Hilti’s robust laser, radar and optical tools cover all the requirements for measuring, leveling, aligning and de- tecting, from excavation through to renovation and maintenance tasks. The easy-to-use system solutions also serve to bring digital planning directly to the construction site. Tool Services Hilti services can enhance produc- tivity while minimizing administrative efforts.',\n",
              "  'chunk_char_count': 1138,\n",
              "  'chunk_word_count': 166,\n",
              "  'chunk_token_count': 284.5}]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View a random sample\n",
        "random.sample(pages_and_chunks, k=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9st3NR5l060"
      },
      "source": [
        "Excellent!\n",
        "\n",
        "Now we've broken our whole textbook into chunks of 10 sentences or less as well as the page number they came from.\n",
        "\n",
        "This means we could reference a chunk of text and know its source.\n",
        "\n",
        "Let's get some stats about our chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "0SMiTGfPl060",
        "outputId": "2115b1ee-d252-4b16-d95b-1f75a89cc2d4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_number</th>\n",
              "      <th>chunk_char_count</th>\n",
              "      <th>chunk_word_count</th>\n",
              "      <th>chunk_token_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>166.00</td>\n",
              "      <td>166.00</td>\n",
              "      <td>166.00</td>\n",
              "      <td>166.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>15.39</td>\n",
              "      <td>1140.33</td>\n",
              "      <td>184.05</td>\n",
              "      <td>285.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.28</td>\n",
              "      <td>807.72</td>\n",
              "      <td>129.68</td>\n",
              "      <td>201.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00</td>\n",
              "      <td>19.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.25</td>\n",
              "      <td>732.75</td>\n",
              "      <td>114.25</td>\n",
              "      <td>183.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11.00</td>\n",
              "      <td>1016.00</td>\n",
              "      <td>164.50</td>\n",
              "      <td>254.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>22.75</td>\n",
              "      <td>1415.25</td>\n",
              "      <td>228.00</td>\n",
              "      <td>353.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>44.00</td>\n",
              "      <td>4917.00</td>\n",
              "      <td>769.00</td>\n",
              "      <td>1229.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
              "count       166.00            166.00            166.00             166.00\n",
              "mean         15.39           1140.33            184.05             285.08\n",
              "std          12.28            807.72            129.68             201.93\n",
              "min           1.00             19.00              3.00               4.75\n",
              "25%           5.25            732.75            114.25             183.19\n",
              "50%          11.00           1016.00            164.50             254.00\n",
              "75%          22.75           1415.25            228.00             353.81\n",
              "max          44.00           4917.00            769.00            1229.25"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get stats about our chunks\n",
        "df = pd.DataFrame(pages_and_chunks)\n",
        "df.describe().round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPJvIqJil060"
      },
      "source": [
        "Hmm looks like some of our chunks have quite a low token count.\n",
        "\n",
        "How about we check for samples with less than 30 tokens (about the length of a sentence) and see if they are worth keeping?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "vg3CSkVtl064",
        "outputId": "7aeae3df-1739-4bb8-c64c-4ce693e70b4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunk token count: 12.25 | Text: www.hilti.group 1 BINDING CORPORATE RULES (“BCR”)\n",
            "Chunk token count: 20.0 | Text: Over to you, Jaibot!ADDED SAFETY WITH THE JAIBOT 2020 Hilti Company Report 20–21\n",
            "Chunk token count: 7.75 | Text: 2020 Hilti Company Report 30–31\n",
            "Chunk token count: 4.75 | Text: COMPANY REPORT 2020\n",
            "Chunk token count: 7.75 | Text: 2020 Hilti Company Report 02–03\n"
          ]
        }
      ],
      "source": [
        "# Show random chunks with under 30 tokens in length\n",
        "min_token_length = 30\n",
        "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(5).iterrows():\n",
        "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K_2hxMXl064"
      },
      "source": [
        "Looks like many of these are headers and footers of different pages.\n",
        "\n",
        "They don't seem to offer too much information.\n",
        "\n",
        "Let's filter our DataFrame/list of dictionaries to only include chunks with over 30 tokens in length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "gALsc54zl064",
        "outputId": "913a1319-0e1d-479d-89ca-f1bdf05bdd8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'page_number': 1,\n",
              "  'pdf_name': 'Hilti Malaysia - Terms and Conditions 2019.pdf',\n",
              "  'sentence_chunk': 'Hilti Malaysia Sdn. Bhd. (157721-A) F-5-A | Sime Darby Brunsfield Tower No.2 | Jalan PJU 1A/7A Oasis Square I Oasis Damansara 47301 Petaling Jaya I Selangor I Malaysia Toll Free 1800 880 985 | F +603 7848 7399 | www.hilti.com.my HILTI (MALAYSIA) SDN. BHD. TERMS AND CONDITIONS   1. GENERAL  1.1  In these conditions the following words have the meanings shown:   \"Buyer\"  means the person, firm or company purchasing Goods    \"Company\" means Hilti (Malaysia) Sdn Bhd or one of its associated or subsidiary companies as the case may be    \"Contract\" means the agreement between the Company and the Buyer for the purchase of Goods from the Company by the Buyer    \"Contracts\" includes all agreements between the Company and the Buyer for the purchase of Goods from the Company by the Buyer    \"Goods\" means the goods and services supplied by the Company and purchased by the Buyer on the terms of the Contract   “Saleable means those unused items in original packaging, Condition” defect-free and in unbroken quantities  1.2  Unless agreed otherwise, these conditions shall be incorporated in all Contracts of the Company to sell Goods and shall be the entire conditions under which the sale takes place. All other terms, conditions or other representations are excluded from the Contracts between the Buyer and the Company including any terms and conditions which the Buyer may purport to apply under any order for Goods.',\n",
              "  'chunk_char_count': 1420,\n",
              "  'chunk_word_count': 253,\n",
              "  'chunk_token_count': 355.0},\n",
              " {'page_number': 1,\n",
              "  'pdf_name': 'Hilti Malaysia - Terms and Conditions 2019.pdf',\n",
              "  'sentence_chunk': '1.3  These conditions shall prevail unless expressly varied in writing and signed by a Director on behalf of the Company.  1.4  No statement, description, information, warranty, condition or recommendation contained in any catalogue, price list, advertisement or communication or made verbally by any of the agents or employees of the Company shall be construed to vary in any way any of the conditions under this Contract unless otherwise agreed in accordance with Clause 1.3 above.  1.5  Any written quotation, estimate and/or advertised price for the Goods shall be an invitation to treat and no binding contract shall be created by placing an order on the Company’s website or otherwise until the Company has acknowledged the order to the Buyer either verbally or in writing as appropriate.',\n",
              "  'chunk_char_count': 794,\n",
              "  'chunk_word_count': 131,\n",
              "  'chunk_token_count': 198.5}]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
        "pages_and_chunks_over_min_token_len[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7cpvLexl065"
      },
      "source": [
        "Smaller chunks filtered!\n",
        "\n",
        "Time to embed our chunks of text!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2UiN3nll065"
      },
      "source": [
        "### Embedding our text chunks\n",
        "\n",
        "While humans understand text, machines understand numbers best.\n",
        "\n",
        "An [embedding](https://vickiboykis.com/what_are_embeddings/index.html) is a broad concept.\n",
        "\n",
        "But one of my favourite and simple definitions is \"a useful numerical representation\".\n",
        "\n",
        "The most powerful thing about modern embeddings is that they are *learned* representations.\n",
        "\n",
        "Meaning rather than directly mapping words/tokens/characters to numbers directly (e.g. `{\"a\": 0, \"b\": 1, \"c\": 3...}`), the numerical representation of tokens is learned by going through large corpuses of text and figuring out how different tokens relate to each other.\n",
        "\n",
        "Ideally, embeddings of text will mean that similar meaning texts have similar numerical representation.\n",
        "\n",
        "> **Note:** Most modern NLP models deal with \"tokens\" which can be considered as multiple different sizes and combinations of words and characters rather than always whole words or single characters. For example, the string `\"hello world!\"` gets mapped to the token values `{15339: b'hello', 1917: b' world', 0: b'!'}` using [Byte pair encoding](https://en.wikipedia.org/wiki/Byte_pair_encoding) (or BPE via OpenAI's [`tiktoken`](https://github.com/openai/tiktoken) library). Google has a tokenization library called [SentencePiece](https://github.com/google/sentencepiece).\n",
        "\n",
        "Our goal is to turn each of our chunks into a numerical representation (an embedding vector, where a vector is a sequence of numbers arranged in order).\n",
        "\n",
        "Once our text samples are in embedding vectors, us humans will no longer be able to understand them.\n",
        "\n",
        "However, we don't need to.\n",
        "\n",
        "The embedding vectors are for our computers to understand.\n",
        "\n",
        "We'll use our computers to find patterns in the embeddings and then we can use their text mappings to further our understanding.\n",
        "\n",
        "Enough talking, how about we import a text embedding model and see what an embedding looks like.\n",
        "\n",
        "To do so, we'll use the [`sentence-transformers`](https://www.sbert.net/docs/installation.html) library which contains many pre-trained embedding models.\n",
        "\n",
        "Specifically, we'll get the `all-mpnet-base-v2` model (you can see the model's intended use on the [Hugging Face model card](https://huggingface.co/sentence-transformers/all-mpnet-base-v2#intended-uses))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Qw8vlf4Dl065",
        "outputId": "e7801c76-ae38-458e-bde4-d89d99689911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: The Sentences Transformers library provides an easy and open-source way to create embeddings.\n",
            "Embedding: [-2.07981840e-02  3.03164609e-02 -2.01218035e-02  6.86483681e-02\n",
            " -2.55255606e-02 -8.47685710e-03 -2.07098550e-04 -6.32377341e-02\n",
            "  2.81606205e-02 -3.33353132e-02  3.02635003e-02  5.30720502e-02\n",
            " -5.03526330e-02  2.62288097e-02  3.33314240e-02 -4.51578312e-02\n",
            "  3.63044441e-02 -1.37111905e-03 -1.20171579e-02  1.14946403e-02\n",
            "  5.04510738e-02  4.70856875e-02  2.11913176e-02  5.14607020e-02\n",
            " -2.03746278e-02 -3.58889289e-02 -6.67838729e-04 -2.94393227e-02\n",
            "  4.95859161e-02 -1.05639659e-02 -1.52014159e-02 -1.31756265e-03\n",
            "  4.48197350e-02  1.56023391e-02  8.60379885e-07 -1.21393730e-03\n",
            " -2.37978660e-02 -9.09396331e-04  7.34482659e-03 -2.53930246e-03\n",
            "  5.23370430e-02 -4.68043163e-02  1.66214686e-02  4.71579209e-02\n",
            " -4.15599309e-02  9.01952910e-04  3.60278748e-02  3.42214517e-02\n",
            "  9.68227386e-02  5.94828427e-02 -1.64984632e-02 -3.51249576e-02\n",
            "  5.92517946e-03 -7.07972853e-04 -2.41031181e-02  3.49740833e-02\n",
            " -2.94746663e-02  6.04267884e-03 -9.80643556e-03  2.83217859e-02\n",
            " -1.85376145e-02  3.63213420e-02  1.30293015e-02 -3.71233188e-02\n",
            "  5.27256615e-02 -1.19706523e-02 -7.18082413e-02  1.24431355e-02\n",
            " -6.70565711e-03  7.42154568e-02  1.16357198e-02 -1.74533334e-02\n",
            " -1.82406195e-02 -1.88930407e-02  2.82414667e-02  1.32828988e-02\n",
            " -3.51909660e-02  8.87300353e-04  5.79572432e-02  3.22093219e-02\n",
            " -3.48586636e-03  4.13768701e-02  1.44357840e-02 -3.28044556e-02\n",
            " -9.79081634e-03 -3.16493325e-02  4.23871167e-02 -4.70847189e-02\n",
            " -2.08936967e-02 -1.91249214e-02 -1.22627066e-02  1.01605328e-02\n",
            "  3.91921960e-02 -2.61895861e-02  1.09028351e-02  1.35722952e-02\n",
            " -5.79267070e-02 -3.21500041e-02 -5.75723173e-03 -2.43516378e-02\n",
            "  5.23417220e-02  5.46125602e-03 -2.30995845e-02  2.57176068e-03\n",
            " -6.63346201e-02  3.54126357e-02 -1.03907408e-02  2.25409605e-02\n",
            " -1.84574258e-02 -2.42006201e-02 -4.78365012e-02 -4.79236245e-03\n",
            " -5.34138307e-02  3.01790778e-02 -1.56130847e-02 -5.51476218e-02\n",
            " -3.91874723e-02  5.92152812e-02 -3.47646512e-02  9.68121085e-03\n",
            "  2.13415232e-02  2.30417494e-02  1.91712752e-02  2.77378634e-02\n",
            " -7.73510523e-03  1.04445638e-02 -2.67719887e-02 -2.40199678e-02\n",
            " -1.92289595e-02  3.91499978e-03 -2.54714936e-02  3.61942910e-02\n",
            "  5.12866899e-02 -8.41696188e-03 -3.13829705e-02  1.47483991e-02\n",
            "  2.13939510e-02 -3.84901352e-02  2.01946255e-02  1.20766135e-02\n",
            " -3.12081375e-03  7.84031488e-03  3.30334250e-03 -4.94357236e-02\n",
            "  5.83886877e-02  3.26131145e-03  4.84485971e-03 -4.50681858e-02\n",
            "  2.45682690e-02  3.55428122e-02 -5.32505885e-02  9.21152756e-02\n",
            "  2.04395410e-02 -3.36952135e-02 -6.19803891e-02 -2.11038925e-02\n",
            "  7.82359913e-02  5.11908270e-02  5.93170859e-02 -1.25080012e-04\n",
            "  4.96349074e-02 -1.55722704e-02 -3.35677760e-03  1.82016082e-02\n",
            " -2.73444280e-02 -1.08772079e-02  1.41475983e-02  1.09877335e-02\n",
            "  4.32553468e-03  8.23311657e-02 -9.85385966e-04  7.58791193e-02\n",
            "  9.44997743e-03  2.37687565e-02  1.61928907e-02  6.24994226e-02\n",
            "  4.75921519e-02 -3.92628461e-03  9.07524675e-02  4.49874029e-02\n",
            " -3.47131267e-02  2.14077216e-02 -3.35604474e-02  4.93849814e-02\n",
            "  1.08670639e-02  2.63447277e-02 -3.26089077e-02  8.00303817e-02\n",
            "  9.29763727e-03  7.16573745e-03 -2.79171988e-02 -3.06820981e-02\n",
            "  4.01061308e-03 -4.93906699e-02 -3.13780084e-03  4.00537476e-02\n",
            " -3.97855155e-02  5.48014082e-02  1.36133485e-05 -8.38373527e-02\n",
            " -1.21547431e-02  3.40950638e-02  3.22400429e-03  6.11846671e-02\n",
            "  5.60066774e-02  9.62877832e-03  2.54615992e-02 -4.64168973e-02\n",
            " -3.98900211e-02  7.68132657e-02  2.28408594e-02 -2.26567611e-02\n",
            " -1.91192981e-02 -6.53028190e-02  4.56780829e-02 -4.43653576e-03\n",
            "  1.49631761e-02 -2.15078238e-02  2.74242368e-03  1.90358777e-02\n",
            "  5.91888539e-02 -2.47569326e-02  3.66144963e-02  5.63083738e-02\n",
            " -8.86450429e-03 -1.74324736e-02 -1.03287213e-03  2.47667059e-02\n",
            "  1.30763259e-02  5.04633151e-02 -5.28498506e-03  5.92396967e-02\n",
            "  6.29906952e-02 -4.36783396e-02 -4.97831143e-02  5.56297190e-02\n",
            " -2.44854484e-02 -8.26755166e-02  2.04911027e-02 -1.06446326e-01\n",
            "  6.64841151e-03  2.97303740e-02 -2.36440469e-02 -8.84612091e-03\n",
            "  2.45553791e-03 -3.35234664e-02  7.52212405e-02 -5.89879937e-02\n",
            " -3.67807671e-02  3.41542438e-02  5.41131087e-02 -1.74904522e-02\n",
            "  1.33919986e-02  4.71681915e-02  1.46116996e-02 -2.12310757e-02\n",
            " -6.55338913e-02  1.23857576e-02  2.76074670e-02 -8.02161451e-03\n",
            " -4.59636562e-02 -8.22443329e-03  9.16954037e-03 -1.56398732e-02\n",
            "  7.54615152e-03  1.58314302e-03 -3.03958859e-02 -5.10671102e-02\n",
            "  1.96313486e-02  1.26263257e-02 -1.51736662e-03  2.02890653e-02\n",
            "  1.37817478e-02  1.49110472e-02  2.50766631e-02 -3.62870470e-02\n",
            "  1.08084809e-02  2.74136220e-03  1.81510597e-02  5.39872274e-02\n",
            " -4.74541970e-02 -4.28731181e-02 -2.89914515e-02  2.13234928e-02\n",
            " -3.85161154e-02  6.31922483e-02 -5.77975810e-02  3.77894845e-03\n",
            " -2.54394431e-02 -1.77206981e-04  9.08245239e-03  1.59095209e-02\n",
            "  4.11799178e-02 -3.94368917e-02 -9.64433886e-03  1.30792521e-02\n",
            "  6.87962249e-02  4.32193130e-02  7.54065986e-04  6.77741244e-02\n",
            "  4.93705831e-02 -3.47819761e-03 -1.06054693e-02  6.72493130e-03\n",
            " -1.39062256e-02  4.88276556e-02 -1.05736302e-02  3.50230536e-03\n",
            "  2.90220580e-03  2.40044203e-02  1.20272087e-02 -2.09796689e-02\n",
            " -2.39112377e-02  3.26579511e-02 -1.01323961e-03 -5.92756132e-03\n",
            " -7.40534207e-03  3.63140530e-03 -2.26698723e-02 -2.21242718e-02\n",
            "  3.86995524e-02  1.72321964e-02  3.85921337e-02 -5.04711494e-02\n",
            " -3.42145041e-02 -4.00443226e-02 -3.57910767e-02 -4.62560691e-02\n",
            "  6.70231730e-02 -4.61645983e-03 -3.29679856e-03  2.08444223e-02\n",
            " -5.14252717e-03 -5.00850193e-02  2.22504456e-02  4.66933176e-02\n",
            "  1.36208320e-02  1.77530497e-02  4.28084843e-03 -2.79332325e-02\n",
            " -1.93420909e-02 -3.87860462e-02 -3.09555437e-02 -6.64134100e-02\n",
            " -1.13434084e-02  1.64267365e-02  1.77629720e-02 -2.28224392e-03\n",
            " -3.30088437e-02 -1.36267603e-03 -2.17934120e-02 -2.67508682e-02\n",
            " -1.26375863e-02  1.61867391e-03 -4.95673046e-02  7.85444975e-02\n",
            "  4.10962477e-02  9.65921767e-03 -1.14642996e-02  1.68853870e-03\n",
            "  5.37663847e-02  2.05536513e-03 -4.11201157e-02  1.46329971e-02\n",
            " -3.75564247e-02 -3.35689262e-02  5.19254431e-03 -6.33089021e-02\n",
            "  3.32963765e-02  8.76122527e-03  1.33858388e-03 -3.95748625e-03\n",
            " -1.61677916e-02  8.26746821e-02  4.75944541e-02 -3.43055427e-02\n",
            "  2.50881668e-02 -3.50976139e-02  3.68657745e-02  4.12656739e-03\n",
            "  4.16018069e-02 -1.35181725e-01 -4.76337373e-02 -1.20025529e-02\n",
            " -3.48891877e-02  3.25454623e-02 -2.93574249e-03 -4.85056126e-03\n",
            " -1.04223773e-01  2.78610718e-02  1.41570419e-02  3.94396149e-02\n",
            " -3.88806053e-02 -1.42463734e-02 -5.19984290e-02  8.92738625e-03\n",
            " -1.99771170e-02 -2.51724999e-02 -3.41300145e-02  1.93041172e-02\n",
            " -5.20207547e-02 -6.71999827e-02 -9.46365017e-03 -1.25587336e-03\n",
            " -5.66048436e-02  2.62098219e-02  9.91585571e-03  4.38286774e-02\n",
            "  2.26639677e-03 -3.11896168e-02 -6.25468194e-02 -3.87793034e-02\n",
            " -6.83938935e-02  4.93722409e-02  5.85507751e-02 -4.08730060e-02\n",
            " -1.98638346e-02 -2.12634597e-02  4.98037040e-02 -4.51748073e-02\n",
            " -2.37141475e-02  2.32674684e-02  1.00594819e-01  9.87114850e-03\n",
            " -1.38014387e-02 -5.21041192e-02  9.08209290e-03  1.72427669e-02\n",
            "  5.91432340e-02  2.62336917e-02 -7.04641547e-03 -1.50032062e-02\n",
            " -3.76657792e-03  6.28261594e-03 -5.23982085e-02 -4.96638492e-02\n",
            "  3.06610782e-02 -3.33646848e-03  2.34911554e-02 -8.58830065e-02\n",
            " -4.62449454e-02  5.59701212e-02  3.09052673e-04  2.01728828e-02\n",
            " -2.98060663e-03  1.76645238e-02  1.54669266e-02 -7.41718337e-02\n",
            "  7.34986505e-03 -1.05014602e-02  2.45247278e-02  1.36878826e-02\n",
            " -1.17803421e-02  4.51544002e-02  3.29039432e-02 -3.50394868e-03\n",
            " -2.71315444e-02 -5.27364761e-02 -4.60164584e-02  2.22849883e-02\n",
            "  2.62272116e-02  5.56150032e-03  1.45788854e-02 -2.97145210e-02\n",
            "  3.57042514e-02  2.22534835e-02  3.89617644e-02 -7.92634636e-02\n",
            " -9.01090261e-03  2.19012760e-02 -5.49062761e-03  8.69959779e-03\n",
            "  4.33030613e-02 -2.12631226e-02  1.13292122e-02 -6.33699149e-02\n",
            "  3.63722965e-02  2.67442819e-02 -6.64251521e-02  1.70499533e-02\n",
            " -2.79691909e-02  2.36354652e-03 -1.81953423e-02  1.52955279e-02\n",
            " -8.50431342e-03  1.16648432e-02 -9.75922048e-02 -2.92093270e-02\n",
            " -5.42547293e-02  3.61234695e-02  3.25116403e-02  8.26973747e-03\n",
            " -2.96499929e-04  1.11555904e-02 -3.85188311e-02  2.36161519e-02\n",
            "  9.85922292e-03  5.73998503e-02  4.86060306e-02 -1.37579953e-02\n",
            " -6.19217288e-03  1.11973099e-02 -3.37174796e-02 -1.10515542e-02\n",
            " -7.08333403e-02 -1.01816338e-02 -3.66010927e-02 -1.55561119e-02\n",
            " -2.13109907e-02 -1.02760158e-02 -4.35733683e-02  5.55186495e-02\n",
            " -3.76547985e-02  5.29252365e-02 -3.45224179e-02 -2.43009068e-03\n",
            "  7.25553632e-02  4.45068441e-03  4.71416563e-02 -9.43878666e-03\n",
            " -1.98978242e-02  5.71899489e-02  8.60540196e-02 -5.25058135e-02\n",
            " -1.39550343e-02  1.17373392e-02  1.33974385e-02 -4.73052599e-02\n",
            " -5.41673377e-02  4.62725312e-02 -2.58970633e-02  1.51415495e-02\n",
            "  3.38944606e-02 -3.78255825e-03 -5.76043092e-02 -1.60082299e-02\n",
            "  2.42738444e-02  3.37360166e-02 -1.96821149e-02 -2.53464077e-02\n",
            " -4.75617275e-02 -5.68755828e-02 -2.28193719e-02  3.83186601e-02\n",
            " -1.78331062e-02  1.35963699e-02  7.86014949e-04  9.74011980e-03\n",
            "  3.34298573e-02 -2.60133930e-02 -7.38569582e-03  3.56451087e-02\n",
            " -2.68532522e-02 -7.53624290e-02 -2.66984086e-02 -4.46457603e-33\n",
            " -3.31645943e-02  1.41704325e-02 -3.92909199e-02 -3.46318744e-02\n",
            " -5.88677870e-03 -1.18212290e-02  1.53951310e-02  1.18473852e-02\n",
            "  1.07757663e-02  3.62141132e-02  7.87953008e-03 -2.31845155e-02\n",
            "  1.07623199e-02  1.72346160e-02  9.54187999e-04  2.83640381e-02\n",
            "  2.37420145e-02 -1.48057519e-02  1.24194997e-03  3.52355326e-03\n",
            "  2.33735386e-02  5.58307953e-02  5.38328066e-02 -3.74078713e-02\n",
            " -2.11805273e-02  1.52731925e-04 -7.27785146e-03  5.50558884e-03\n",
            "  3.05824243e-02  4.54633608e-02 -3.35786864e-02  3.16142477e-02\n",
            " -2.56392965e-03  3.96354981e-02 -1.47573240e-02  5.67167252e-02\n",
            " -5.62787652e-02 -5.04599325e-03  3.56154665e-02 -2.76198797e-02\n",
            " -2.32292023e-02 -4.63292748e-02 -3.70919220e-02 -4.23189476e-02\n",
            "  3.70305777e-02  7.88717996e-03  3.85176279e-02  1.74772495e-03\n",
            "  5.62760187e-03  6.18104404e-03 -6.90268874e-02 -9.42969881e-03\n",
            " -7.74677796e-03  1.68349985e-02  1.22767081e-02  2.26406436e-02\n",
            "  1.21009108e-02  1.11743584e-02  1.21538835e-02 -1.16862003e-02\n",
            " -4.41612527e-02  2.30047926e-02  2.20671743e-02 -5.87504953e-02\n",
            " -3.96428443e-02  6.83135390e-02 -3.29947844e-02 -3.66774090e-02\n",
            " -3.53654958e-02  1.76185351e-02  6.95640733e-03  5.92691973e-02\n",
            "  4.12156358e-02  7.98109546e-02 -5.36567299e-03  1.14238337e-02\n",
            " -2.96388622e-02 -1.15411496e-02  2.22811978e-02  7.93186016e-03\n",
            "  2.60356572e-02  1.28211658e-02  1.71346013e-02 -6.90192636e-03\n",
            " -1.07603688e-02  1.35715539e-02 -9.90709756e-04 -6.16075434e-02\n",
            "  4.40513380e-02 -8.26579169e-04 -2.78340969e-02 -1.23619679e-02\n",
            "  1.34629719e-02 -3.85745168e-02  1.08702248e-03  2.18712874e-02\n",
            " -3.32398340e-02  1.84615478e-02 -5.10102604e-03  3.74665074e-02\n",
            " -3.67544964e-03 -2.19246037e-02 -4.96480847e-03 -9.59828775e-03\n",
            "  2.33591199e-02  1.04876449e-02  4.38721851e-02 -1.51424306e-02\n",
            " -6.30309656e-02  8.23258515e-03 -1.09130759e-02 -4.06409539e-02\n",
            " -6.21690750e-02  2.21326146e-02 -2.71434169e-02  4.05539609e-02\n",
            " -8.09452776e-03 -1.76406628e-03  3.01526170e-02 -5.42265410e-03\n",
            " -4.69821393e-02 -1.73768401e-02  4.11631204e-02  3.20635848e-02\n",
            " -2.22943760e-02 -1.58161670e-02 -4.50720899e-02  5.69486916e-02\n",
            "  4.71596271e-02 -5.78058846e-02  1.32475020e-02 -4.71287593e-03\n",
            "  1.66824520e-07  4.81090769e-02  5.03628105e-02  5.45263812e-02\n",
            "  2.07568165e-02 -1.19080720e-02 -6.37493748e-03  5.26369317e-03\n",
            "  7.21948594e-02 -2.21763197e-02  2.20103078e-02 -9.90448403e-04\n",
            " -1.37163131e-02  6.89209998e-03  2.46912483e-02 -1.39462054e-01\n",
            "  2.56978767e-03 -4.64827679e-02 -4.04967554e-02 -6.08555935e-02\n",
            " -1.53212892e-02  1.36129901e-01  9.45035070e-02  4.25741300e-02\n",
            "  4.67131063e-02 -2.30677929e-02 -1.20965950e-02  3.86673324e-02\n",
            "  2.11655442e-03 -2.51473375e-02 -1.15076471e-02 -3.46506387e-02\n",
            " -2.29533762e-02 -6.33849204e-03 -3.05175893e-02 -1.56236673e-02\n",
            "  1.39514348e-02  3.27456451e-04  2.00327300e-03  4.15106211e-03\n",
            " -2.22924836e-02 -3.62589955e-02 -2.36579124e-02 -1.87817775e-02\n",
            " -1.96288936e-02  4.52126078e-02 -8.12568963e-02 -2.14569494e-02\n",
            " -4.41542715e-02 -2.68476363e-02  2.01974325e-02  2.82995310e-03\n",
            " -1.95011161e-02 -3.45331430e-02  2.26913411e-02  3.78325656e-02\n",
            " -1.02543971e-02 -2.19750847e-03 -8.96744579e-02 -4.50030826e-02\n",
            "  8.09701998e-03 -2.05805898e-02 -2.02998295e-02 -2.09922194e-02\n",
            " -1.79405101e-02  5.81897683e-02 -7.63652148e-03  1.50847267e-02\n",
            "  1.78279812e-34  4.86179441e-02  4.22228239e-02  4.71596345e-02\n",
            "  5.89047372e-02  3.99784744e-02 -5.27070910e-02  1.56905893e-02\n",
            " -5.25129260e-04  1.13652255e-02 -6.56410754e-02 -2.20849011e-02]\n",
            "\n",
            "Sentence: Sentences can be embedded one by one or as a list of strings.\n",
            "Embedding: [ 4.31718007e-02 -5.38701080e-02 -3.78044434e-02  4.27235700e-02\n",
            " -2.35409234e-02  3.44861411e-02  2.89587080e-02  1.92817417e-03\n",
            "  2.41732579e-02 -3.17012109e-02  7.32856095e-02  1.25589613e-02\n",
            "  3.64620946e-02 -2.05251761e-02  2.81973928e-02 -6.87329620e-02\n",
            "  4.22230773e-02  9.31726652e-04  3.54035571e-02  1.41787175e-02\n",
            "  7.83995166e-03  2.31179539e-02 -4.84742876e-03  1.07173854e-02\n",
            "  4.39491682e-03  5.47802867e-03 -3.80338691e-02 -3.05487006e-03\n",
            "  5.72234439e-03 -6.78213835e-02 -4.88008037e-02 -1.45032331e-02\n",
            "  6.68006251e-03 -7.17479810e-02  1.64644871e-06  1.07564069e-02\n",
            " -3.60922106e-02 -2.37057209e-02 -5.22791892e-02  3.46110798e-02\n",
            " -5.42172417e-03  1.62611157e-02  1.96564663e-02  2.25395579e-02\n",
            " -2.25997111e-03  4.06342670e-02  8.17157999e-02  2.48179417e-02\n",
            "  5.31884544e-02  7.82715529e-02 -1.91813335e-02 -1.94087438e-02\n",
            " -2.62805410e-02 -2.44083870e-02  5.49405701e-02  1.90319009e-02\n",
            "  1.60811059e-02 -2.68895905e-02 -8.24690517e-03  7.33444020e-02\n",
            "  1.00122979e-02  2.93315668e-02  3.42863565e-03 -2.13270038e-02\n",
            " -1.62446895e-03 -5.56257041e-03 -7.64880106e-02 -5.85450195e-02\n",
            " -2.82272156e-02  7.51851266e-03  7.11226016e-02  1.95453153e-03\n",
            "  5.45926578e-03  3.22314189e-03  5.12800291e-02 -3.54106054e-02\n",
            " -5.03608659e-02  4.70519513e-02  5.15475357e-03  1.52287260e-02\n",
            " -1.06680905e-02  3.16298902e-02 -9.09037888e-03 -4.01326977e-02\n",
            " -4.35236059e-02 -1.94969382e-02  1.65604949e-02 -4.71168682e-02\n",
            " -3.92091498e-02 -3.07756905e-02 -2.94167176e-02 -4.20826226e-02\n",
            "  2.27070227e-03 -2.78329439e-02  1.69421677e-02  7.74499029e-03\n",
            " -5.23741469e-02 -4.50039506e-02  3.83606218e-02 -4.90786880e-02\n",
            "  5.06618768e-02  1.01615218e-02 -1.25022121e-02 -4.64554224e-03\n",
            " -1.54539719e-02  1.58862602e-02  1.18369777e-02 -3.59232761e-02\n",
            " -7.76226074e-02  3.43358591e-02 -2.14709938e-02 -6.86098784e-02\n",
            " -5.46235852e-02  7.83901364e-02 -3.00703067e-02 -3.37550007e-02\n",
            " -4.04999144e-02  4.80514988e-02  9.53904167e-03  2.31399015e-02\n",
            " -8.16115290e-02 -6.51690876e-03  1.54213039e-02  7.04257339e-02\n",
            " -1.25069013e-02 -2.48266533e-02 -1.71329137e-02  6.13109209e-03\n",
            "  5.44412844e-02 -1.40566202e-02 -6.24515954e-03  3.65787558e-02\n",
            "  7.36230165e-02 -6.05683867e-03 -3.61630172e-02 -1.42202561e-03\n",
            "  4.43165563e-02 -3.14516271e-03  3.18768024e-02 -1.30947744e-02\n",
            " -3.69525142e-02 -4.98030614e-03  1.30016624e-03 -2.05213483e-02\n",
            "  2.06277724e-02  5.93871716e-03 -3.07157612e-03 -3.97512913e-02\n",
            "  4.29889672e-02  6.49802238e-02 -6.76022395e-02  5.41655235e-02\n",
            "  1.52560486e-03 -3.72908525e-02 -4.02427129e-02 -2.28771903e-02\n",
            "  1.31769806e-01  4.87875659e-03  1.39470780e-02  4.92435992e-02\n",
            "  2.49219257e-02 -8.76089465e-03 -5.38766291e-03 -2.65595466e-02\n",
            " -1.19766686e-02 -2.32006628e-02 -2.67434102e-02  5.66913281e-03\n",
            "  2.21721679e-02  4.67294343e-02 -5.78486882e-02  8.22120458e-02\n",
            " -3.36836278e-03  8.09646770e-02  1.41423289e-02  1.02393053e-01\n",
            " -5.76835638e-03 -1.15876896e-02  4.90585007e-02  5.87830134e-02\n",
            "  6.50030822e-02  4.74621654e-02 -2.89464146e-02 -1.76582136e-03\n",
            "  3.32561210e-02  2.91198269e-02  6.03811592e-02  3.73523799e-04\n",
            "  1.06575862e-02 -5.96284494e-02 -7.28600994e-02  2.95080412e-02\n",
            "  9.54460911e-03 -2.71541681e-02 -5.63305244e-02  9.66696767e-04\n",
            " -4.77728806e-02  4.67576683e-02  4.87260381e-03 -6.57520071e-02\n",
            " -1.42248748e-02  3.99872735e-02 -1.09798182e-02  7.68942907e-02\n",
            " -4.00003791e-02  2.96826568e-02  2.81303450e-02 -5.55424541e-02\n",
            "  6.31275866e-03  5.00450321e-02  1.89884380e-02  5.38684018e-02\n",
            " -1.95981320e-02  1.08600976e-02  1.64150707e-02  1.44135151e-02\n",
            "  1.71448886e-02  2.17624847e-02 -4.98863384e-02  1.56105757e-02\n",
            "  4.83735558e-03  1.87053774e-02 -3.18550761e-03  2.66863145e-02\n",
            "  5.55552952e-02 -4.88005616e-02 -3.02929040e-02  2.52110418e-02\n",
            "  1.07264603e-02  1.88270379e-02 -1.50688356e-02  3.43831964e-02\n",
            "  4.15124670e-02  1.37788821e-02 -5.54848090e-02  1.43847931e-02\n",
            " -5.88139966e-02 -6.01676144e-02  2.69856136e-02 -5.46130240e-02\n",
            "  8.14634655e-03 -1.17758662e-02  1.57442074e-02  1.43903110e-03\n",
            " -2.64554657e-02 -4.48877178e-02  4.39732783e-02 -1.06166066e-04\n",
            " -2.25905515e-02  3.00296266e-02  1.97440684e-02  7.44073745e-03\n",
            " -1.93790104e-02  8.09795409e-03  4.34860066e-02 -1.08542612e-04\n",
            " -3.77225690e-02  2.67195869e-02 -4.63157631e-02 -1.53403473e-03\n",
            "  8.05308484e-03 -4.30901535e-02 -2.13848688e-02  1.20185306e-02\n",
            "  8.41403008e-03  2.48270016e-03 -3.09566334e-02 -9.05277878e-02\n",
            " -4.76694070e-02  1.22606382e-02 -1.36466958e-02 -2.63654906e-02\n",
            " -7.65549112e-03  8.72373767e-03  2.65724678e-02  8.40078399e-04\n",
            " -5.55932010e-03 -9.29540675e-03  3.19337472e-02  5.94646558e-02\n",
            "  1.83205921e-02 -7.56547004e-02 -5.59389368e-02 -1.20871151e-02\n",
            " -3.16260867e-02  3.62186879e-02  7.53609417e-03 -6.15654252e-02\n",
            " -2.30458863e-02 -3.51674133e-03  1.23332124e-02 -9.67644528e-03\n",
            "  4.96861115e-02 -8.42256844e-02  1.52396271e-02 -1.82445198e-02\n",
            "  7.70462081e-02  9.28718597e-02  4.03726101e-02  1.11732610e-01\n",
            " -1.03270523e-02 -2.54558548e-02  2.13153698e-02 -1.16184074e-03\n",
            "  2.82596983e-03  5.06967008e-02 -3.13697569e-02 -8.14277586e-03\n",
            "  1.38387289e-02  4.66889441e-02  5.09671047e-02  3.77154201e-02\n",
            " -2.94988789e-02  3.60631943e-02 -2.61162082e-03  2.72223901e-04\n",
            " -6.71807155e-02 -6.54026195e-02 -3.43590714e-02  1.91067494e-02\n",
            "  4.13293950e-02 -1.10970549e-02  4.51952629e-02 -5.93564920e-02\n",
            "  1.06963497e-02 -1.82229523e-02 -5.65814339e-02  1.20387254e-02\n",
            "  4.44774888e-02  1.87049452e-02  1.63810030e-02  5.51151186e-02\n",
            " -2.23332327e-02  2.12861858e-02 -1.20339859e-02  3.26752737e-02\n",
            "  1.47003997e-02 -8.16682260e-03  1.12904413e-02 -3.00620552e-02\n",
            " -2.34345235e-02 -2.68646274e-02 -1.28718663e-03 -7.67190158e-02\n",
            "  2.22606980e-03 -5.89483837e-03  2.63103582e-02  2.07129377e-03\n",
            " -6.91151991e-02 -1.43792639e-02  2.68788524e-02 -3.51540148e-02\n",
            " -2.69612353e-02  2.54717050e-03 -6.48881197e-02  3.18727754e-02\n",
            "  1.70126799e-02 -4.54004630e-02 -1.80616081e-02 -1.61116440e-02\n",
            "  5.70773557e-02 -2.78269593e-03 -6.45586029e-02  7.86598250e-02\n",
            "  2.29075700e-02  6.81841653e-03 -9.11741145e-03 -2.27726232e-02\n",
            " -4.76526171e-02  4.88431044e-02 -2.09891368e-02 -2.43693944e-02\n",
            " -5.01211314e-03  6.70254081e-02  6.91367406e-03  2.25843024e-02\n",
            "  2.51125339e-02 -6.92502782e-03  8.59402772e-03  2.38977484e-02\n",
            "  3.29738222e-02 -1.05310559e-01  1.22094331e-02 -1.22263823e-02\n",
            " -5.73768765e-02  1.84311401e-02  2.97158007e-02 -6.09429218e-02\n",
            " -6.55256137e-02  3.55712734e-02  5.64320758e-03  3.34643037e-03\n",
            " -3.59686390e-02 -8.83415621e-03 -6.97895065e-02  6.89779446e-02\n",
            " -4.88215871e-03  2.23995168e-02 -3.16054001e-02 -7.41182221e-03\n",
            "  3.19351442e-02 -5.18788360e-02  2.11601797e-02 -5.03340103e-02\n",
            "  9.10578482e-03  2.13354584e-02  1.66838467e-02  3.49020325e-02\n",
            " -6.38500452e-02 -6.75629638e-03 -1.27405412e-02 -4.63366620e-02\n",
            " -1.14779398e-02  2.08778717e-02  2.44822539e-02  3.66464420e-03\n",
            " -2.86098244e-03  2.29389761e-02  2.13745739e-02 -3.48900519e-02\n",
            " -3.00388020e-02  4.78870533e-02  5.83370402e-02 -9.70497634e-03\n",
            "  1.38234077e-02 -3.27485651e-02 -8.11426376e-04  9.54228174e-03\n",
            "  1.20401615e-02  1.97230522e-02 -4.74872650e-04 -1.39226140e-02\n",
            " -5.21070100e-02 -1.75592508e-02 -5.41698970e-02 -1.17970295e-02\n",
            " -1.71030331e-02 -3.50194871e-02  3.38661484e-02 -6.76587075e-02\n",
            " -2.27606595e-02  1.95606705e-02  5.50249368e-02  1.22029148e-02\n",
            " -1.75167376e-03  7.22444942e-03  1.16349785e-02 -1.61908511e-02\n",
            " -3.37755010e-02  3.22626531e-02 -2.03813817e-02 -2.33859457e-02\n",
            " -1.29992142e-02 -1.66798979e-02  1.03070438e-02 -1.46030132e-02\n",
            " -7.79070333e-02 -8.25812370e-02 -3.38809639e-02  3.81114520e-02\n",
            "  7.86006916e-03  2.41455007e-02 -2.75715161e-02  1.30867511e-02\n",
            " -7.88596645e-03  1.78651251e-02  5.37323393e-02 -3.01823262e-02\n",
            "  1.69455800e-02  1.19571323e-02  3.52573872e-04  4.90208901e-02\n",
            " -8.57214630e-03  1.71267311e-03  4.83875768e-03 -4.10080813e-02\n",
            " -4.68120314e-02 -2.32559722e-03 -5.16776554e-02  3.10030729e-02\n",
            "  1.60961058e-02 -1.00803655e-02 -3.72485816e-03 -3.53387929e-02\n",
            "  2.95961481e-02  2.89097186e-02 -7.59911388e-02 -5.02980761e-02\n",
            " -2.11783517e-02  3.20462845e-02 -3.84538248e-02  2.45102607e-02\n",
            " -2.04188433e-02  6.02110662e-03 -9.81937349e-03  3.74778137e-02\n",
            "  3.40838432e-02  1.28863677e-02  5.67342043e-02 -8.09703618e-02\n",
            " -8.93603172e-03  1.33352671e-02 -2.51565613e-02  2.58413539e-03\n",
            " -6.51802719e-02  1.34400371e-02 -2.04681773e-02  6.53378246e-03\n",
            "  4.56974003e-03  1.99271012e-02 -6.07340224e-02  1.40691986e-02\n",
            " -5.75334318e-02  9.79797449e-03  3.55392806e-02 -2.45283525e-02\n",
            " -4.73311776e-03 -2.77492944e-02  2.34282911e-02 -8.76331324e-05\n",
            "  7.30442116e-03  1.42028760e-02  4.92807142e-02 -3.16540338e-02\n",
            " -1.34902131e-02  3.08487378e-02  2.80402005e-02 -4.33069021e-02\n",
            " -4.42284457e-02  3.80738862e-02  9.47457811e-05 -4.34895977e-02\n",
            "  1.43868113e-02  2.44333060e-03 -4.84072939e-02  1.08955177e-02\n",
            " -9.87488776e-03  4.59295623e-02  3.96379307e-02 -2.60117166e-02\n",
            "  2.48134229e-02 -5.37149012e-02  5.62824607e-02  8.81360471e-03\n",
            "  5.25077134e-02 -1.47371152e-02 -1.74380839e-02  3.45084667e-02\n",
            "  3.75523269e-02 -4.70167249e-02 -1.94911323e-02  3.82631756e-02\n",
            " -5.67595735e-02 -1.78613467e-03  2.33404227e-02 -5.88216455e-33\n",
            " -4.87187840e-02 -2.76265237e-02 -3.38240787e-02  2.66188253e-02\n",
            " -3.39277238e-02 -8.49197060e-03 -1.91250294e-02  3.00252270e-02\n",
            "  3.40781994e-02  5.11157773e-02 -1.92480199e-02  2.85642501e-02\n",
            "  3.66040282e-02  1.68858338e-02  4.77258638e-02  1.23802377e-02\n",
            "  2.14844178e-02  4.93656378e-04  1.21273603e-02 -5.82143702e-02\n",
            "  1.62954442e-02 -7.14259734e-03  4.80092280e-02  2.51190551e-02\n",
            "  4.60097864e-02 -2.29839664e-02 -2.05696691e-02 -3.22231976e-03\n",
            "  4.00091670e-02  3.52309905e-02 -3.43153812e-02  2.75633764e-03\n",
            " -1.25138173e-02  1.97685659e-02  5.53493388e-03  1.03744522e-01\n",
            "  5.77611523e-03 -5.65426387e-02  4.19558994e-02 -3.78831066e-02\n",
            " -3.93443331e-02 -6.24309704e-02 -2.24396167e-03 -5.46548367e-02\n",
            "  4.56134193e-02 -5.69243124e-03  3.38917114e-02 -1.44448057e-02\n",
            "  2.72110710e-03  1.11190863e-02 -5.00661097e-02 -1.61127187e-02\n",
            "  1.72818103e-03  6.88877255e-02  1.16492454e-02  2.83171274e-02\n",
            "  6.97190594e-03  2.68371888e-02 -7.72084948e-03  2.16828585e-02\n",
            "  1.15182875e-02  8.72832760e-02 -6.27275184e-03 -6.44473583e-02\n",
            " -1.58233736e-02  4.03268486e-02 -1.69728268e-02 -1.61188953e-02\n",
            " -3.75576727e-02  7.02938959e-02 -3.30486335e-02  4.66324203e-02\n",
            "  1.18027637e-02  6.51075691e-02 -1.16979582e-02 -8.28349032e-03\n",
            " -5.46905287e-02 -2.00227052e-02  8.42678361e-04 -8.19525495e-03\n",
            "  2.08357219e-02  1.37454011e-02 -1.29924587e-03 -3.94575261e-02\n",
            " -2.00184733e-02 -1.53721645e-02  1.17271869e-02 -4.40110825e-02\n",
            "  5.39267398e-02 -2.33010426e-02 -2.24211439e-02 -3.65216937e-03\n",
            "  2.92212721e-02  7.56442407e-03 -2.90923528e-02  4.01518010e-02\n",
            " -2.00854093e-02 -1.79865176e-03 -1.26235951e-02  2.51077097e-02\n",
            " -4.69285809e-02 -3.08554042e-02 -3.63357132e-04  6.01791218e-03\n",
            "  3.97508964e-02  1.38547439e-02  2.49774661e-02  1.76975690e-02\n",
            " -9.31573138e-02 -9.83686280e-03  8.44927225e-03 -1.95390526e-02\n",
            " -3.26569006e-02  5.13733970e-03  5.80926565e-03  2.08536796e-02\n",
            " -5.97835332e-03  5.86811639e-02 -1.49496775e-02 -5.72965927e-02\n",
            " -5.98239852e-03  1.95201044e-03  2.72976537e-03  6.07001688e-03\n",
            " -2.00525634e-02 -1.31687485e-02 -4.06228565e-02  5.68997152e-02\n",
            "  4.44969125e-02 -1.24308253e-02  1.96967348e-02  3.80979776e-02\n",
            "  2.30237646e-07  1.10574979e-02  4.79513034e-02  6.18299246e-02\n",
            "  4.40278798e-02  6.17667055e-03  2.58291303e-03  3.38913538e-02\n",
            " -5.32937422e-03 -2.59283856e-02 -1.26144290e-02  2.46495400e-02\n",
            " -1.68767944e-03  1.17907661e-03  2.40442809e-02 -9.77309495e-02\n",
            "  1.97368190e-02 -5.52921519e-02 -6.17424995e-02 -4.87152040e-02\n",
            "  1.11080939e-03  1.18732080e-01  8.13258141e-02  3.32448967e-02\n",
            "  4.38326895e-02 -2.49559190e-02 -3.59626487e-02  1.66319273e-02\n",
            "  5.93768805e-03 -1.43971872e-02  4.46712645e-03 -6.01986647e-02\n",
            " -5.65912202e-02 -8.21541902e-03  5.83057664e-03 -1.69481970e-02\n",
            "  9.58633143e-03  1.46733308e-02  5.05845435e-02  3.06891724e-02\n",
            "  6.60468116e-02 -2.56551877e-02 -2.78858151e-02 -3.19173411e-02\n",
            " -3.39236781e-02  1.49903111e-02 -3.03335823e-02 -6.06490020e-03\n",
            " -4.81769722e-03  1.72137488e-02 -8.23371485e-03  1.55548435e-02\n",
            "  2.69106589e-02  5.44308126e-03 -1.06899384e-02 -7.82138109e-03\n",
            " -4.44506705e-02  2.55874358e-02 -5.74760661e-02 -2.05442496e-02\n",
            " -3.07850186e-02 -1.57855190e-02 -7.07542151e-03 -4.21312526e-02\n",
            "  3.79934758e-02  6.27764687e-02 -7.67792249e-03 -3.18353064e-02\n",
            "  1.99277723e-34  1.04834316e-02 -3.39326151e-02  3.93821523e-02\n",
            "  5.53065315e-02  9.42169223e-03  1.09728128e-02 -4.91939969e-02\n",
            "  2.95024104e-02 -8.85376707e-03 -5.96248172e-02 -2.37825662e-02]\n",
            "\n",
            "Sentence: Embeddings are one of the most powerful concepts in machine learning!\n",
            "Embedding: [-2.98611335e-02 -1.37522332e-02 -4.75402065e-02  2.72126496e-02\n",
            "  3.40054557e-02  3.16465721e-02  4.26963754e-02  3.29794036e-03\n",
            "  4.35717851e-02  2.53837258e-02  3.02529093e-02  3.21131088e-02\n",
            " -3.99913155e-02  1.28761074e-02  6.70220107e-02 -7.92899802e-02\n",
            "  4.68772240e-02  2.40266230e-02 -2.07997561e-02 -1.07433032e-02\n",
            " -1.19410567e-02 -5.39290570e-02  4.21055667e-02  2.23588645e-02\n",
            " -2.98949406e-02  8.35978519e-03  1.58385076e-02 -4.80235554e-02\n",
            "  1.88435987e-03 -1.67521499e-02 -2.15628967e-02 -3.88487950e-02\n",
            "  3.06274630e-02  4.20525968e-02  1.69483383e-06 -1.86928920e-02\n",
            " -1.24558602e-02  1.32128661e-02 -4.89040054e-02  1.34746497e-02\n",
            "  2.28873454e-02  8.81781150e-03  8.64926632e-03 -2.00949535e-02\n",
            " -3.15217786e-02 -2.53432989e-02  7.57318884e-02  3.62445787e-02\n",
            "  1.25289764e-02  3.09694838e-02  4.50759893e-03 -3.50041837e-02\n",
            " -4.42523800e-04 -9.76646598e-03  6.04545437e-02  4.03472260e-02\n",
            "  1.10734627e-02  6.56203832e-03 -5.84599841e-03  3.79781798e-03\n",
            " -4.46915329e-02  1.76404957e-02  2.45916937e-02 -3.60040320e-03\n",
            "  1.02473386e-01  3.73759046e-02  6.13311585e-03 -2.24676393e-02\n",
            "  1.46482149e-02  5.00536971e-02 -2.29907800e-02  1.12924501e-02\n",
            " -3.10552493e-02 -1.49509497e-02 -2.53127958e-03  3.20944525e-02\n",
            " -4.67056111e-02 -4.85887229e-02  2.98306085e-02  6.44215718e-02\n",
            " -3.12613621e-02  3.57407108e-02  4.16527279e-02 -5.52517101e-02\n",
            " -8.74630455e-03 -2.18630452e-02 -1.12744365e-02 -2.14436054e-02\n",
            " -1.32824089e-02 -2.04866175e-02 -1.00575835e-02  3.54763754e-02\n",
            " -7.47605041e-03 -3.70188542e-02  5.77893443e-02 -2.18168851e-02\n",
            "  4.36226744e-03  2.04380676e-02  3.36814895e-02 -4.92800623e-02\n",
            "  4.82793637e-02 -1.81003916e-03 -1.05118714e-02  4.13323008e-02\n",
            " -6.79833218e-02  1.75716002e-02 -4.43412997e-02  9.90839209e-03\n",
            " -3.81809883e-02  1.10827247e-02 -5.07279299e-02 -2.17451062e-02\n",
            " -1.03836004e-02  4.60332148e-02  1.55862756e-02 -4.21366543e-02\n",
            " -2.72146463e-02  3.22818719e-02 -4.24739346e-02  2.71207262e-02\n",
            " -7.41061494e-02  4.20107022e-02  2.02437416e-02  7.31810853e-02\n",
            " -8.97695776e-03 -2.31159981e-02 -3.93559597e-02 -1.46008581e-02\n",
            " -3.30910087e-02  1.12239840e-02  2.58564088e-03 -4.36856225e-03\n",
            "  1.85855757e-02  2.69934963e-02 -1.67214964e-02  3.69569622e-02\n",
            "  4.44489233e-02 -2.21723747e-02  6.72968617e-03  1.22935865e-02\n",
            "  1.71758439e-02 -2.36473209e-03  3.72263864e-02 -2.22870894e-02\n",
            "  2.94603743e-02 -2.33691130e-02  5.38467802e-03 -3.06581371e-02\n",
            " -2.38919947e-02 -2.63614431e-02 -2.01789066e-02  1.11245625e-01\n",
            " -1.99836884e-02 -3.54029946e-02  3.84143293e-02  2.53069103e-02\n",
            "  1.99550800e-02  5.53518161e-02 -1.99332666e-02 -2.16716342e-03\n",
            "  4.91093025e-02 -4.03530821e-02 -1.16976965e-02 -5.33113368e-02\n",
            "  8.29583779e-03 -5.08251674e-02 -2.65503787e-02 -1.53242508e-02\n",
            "  5.78812324e-03  2.46574567e-03 -3.44449542e-02 -1.85132422e-03\n",
            " -3.95730175e-02 -2.71690600e-02  4.93568070e-02  8.38368833e-02\n",
            "  5.43491282e-02  8.22261199e-02  1.23894876e-02 -4.79795039e-03\n",
            "  7.77337700e-04  2.98485924e-02 -1.85584724e-02  5.98795563e-02\n",
            " -6.82792254e-03  9.78193595e-04  2.85485983e-02 -7.64618209e-03\n",
            " -1.86619982e-02 -2.69287508e-02 -2.90332809e-02 -1.37871560e-02\n",
            " -2.57598585e-03 -2.20173486e-02 -1.70821641e-02 -3.81843299e-02\n",
            "  2.21505221e-02 -3.59234400e-02 -1.19439512e-02 -3.18307765e-02\n",
            " -4.80801538e-02  9.77633987e-03 -1.04864908e-03  4.15371843e-02\n",
            " -1.10974172e-02 -4.72830050e-02  1.90984886e-02 -5.31177521e-02\n",
            "  2.11326387e-02 -2.53063673e-03  5.61055206e-02 -1.33795263e-02\n",
            " -5.95856085e-03 -1.20307952e-02  4.63929884e-02 -2.81908866e-02\n",
            "  2.25355066e-02 -2.50472594e-03 -3.52453031e-02  2.55494714e-02\n",
            "  9.10396036e-03  3.25213326e-03  2.55968911e-03 -1.25623923e-02\n",
            " -3.51496413e-02 -4.28946316e-02 -2.32332991e-03  2.41020992e-02\n",
            " -5.16841607e-03  1.68739930e-02  5.52647049e-03  2.36791950e-02\n",
            "  5.65164275e-02 -3.47868837e-02 -6.34517744e-02 -7.45629286e-03\n",
            " -1.78447943e-02  5.35898432e-02  2.67291348e-02 -8.74199420e-02\n",
            "  1.04195531e-02 -4.13963513e-04 -3.04448605e-03  9.14251152e-03\n",
            "  2.91529465e-02 -5.81831746e-02  6.83463514e-02 -4.08618040e-02\n",
            " -9.09787416e-03 -3.40769850e-02  3.52410935e-02 -1.02627790e-02\n",
            " -5.72505931e-04 -2.73455400e-03  1.59635786e-02  4.49070940e-03\n",
            " -2.09051464e-02  3.02769598e-02  2.46119704e-02 -1.44067183e-02\n",
            "  1.73268840e-02  1.99031946e-03  4.23051231e-02 -2.39176955e-02\n",
            " -3.25547867e-02 -1.45939533e-02  3.95101011e-02 -6.04649819e-02\n",
            " -3.02065536e-02  1.67189408e-02 -2.26817783e-02 -2.61955224e-02\n",
            " -5.51320054e-02  1.44908521e-02 -1.99246891e-02  3.99750890e-03\n",
            "  3.12610231e-02 -4.90727909e-02 -9.49712179e-04  5.39497100e-02\n",
            " -9.10081714e-03 -2.69486792e-02 -3.63159440e-02 -1.38437068e-02\n",
            " -4.45622206e-02  5.49358986e-02  2.17594160e-03  2.23447313e-03\n",
            " -5.23019116e-03 -1.47894444e-02  3.60591859e-02  1.45263001e-02\n",
            "  8.39191303e-03 -6.10361174e-02 -7.89950695e-03 -2.98297661e-03\n",
            "  3.56560806e-03  8.33992511e-02 -2.61215121e-02  8.06722045e-02\n",
            "  3.63060110e-03  1.69974733e-02  2.58604512e-02  1.09443406e-03\n",
            " -4.57063057e-02  5.55678457e-02  2.00643502e-02  4.76660691e-02\n",
            " -4.91053909e-02 -1.86081212e-02  3.34404521e-02 -2.57310402e-02\n",
            " -3.16369929e-03  7.21444339e-02 -1.61519032e-02 -1.33933937e-02\n",
            " -6.06293827e-02 -2.82187313e-02 -8.91925395e-03 -2.71172193e-03\n",
            "  8.04915838e-03 -4.95209955e-02  7.89434165e-02  2.76428238e-02\n",
            " -5.42582199e-03 -3.06719914e-03 -4.11826894e-02  1.39172487e-02\n",
            "  3.04253194e-02  1.02856588e-02  1.06679145e-02 -5.56554385e-02\n",
            " -1.75082888e-02  2.03868337e-02  8.43307376e-03  3.82471234e-02\n",
            " -3.89099903e-02 -1.61303710e-02  3.18059400e-02 -7.32970312e-02\n",
            " -1.76502261e-02 -4.79874723e-02 -5.55042140e-02 -5.00752172e-03\n",
            "  4.46791149e-04  3.57333384e-02 -8.24653835e-04 -3.34324278e-02\n",
            " -3.32417116e-02 -2.46460568e-02  2.15331931e-02  3.90855176e-03\n",
            "  2.53471583e-02  6.02990715e-03 -7.81610049e-03  1.23765133e-02\n",
            " -1.71039309e-02  2.68103369e-02  2.83679063e-03 -1.27643654e-02\n",
            "  1.00510910e-01  1.03580886e-02 -3.55143137e-02  1.56616382e-02\n",
            " -9.85949785e-02  4.58441637e-02 -3.15230452e-02 -2.35781241e-02\n",
            " -2.78350357e-02 -7.75307053e-05 -2.82363016e-02 -1.92918424e-02\n",
            "  1.87389627e-02  5.71941175e-02  2.56911945e-02 -3.20030302e-02\n",
            "  1.99074652e-02 -3.15819643e-02 -4.02061380e-02  5.77630550e-02\n",
            "  1.72974467e-02 -5.37013412e-02 -1.25325620e-02 -1.45484125e-02\n",
            " -5.76174706e-02  1.09727560e-02 -2.04727892e-02  2.85540763e-02\n",
            " -5.04399873e-02  4.36991155e-02  1.75711196e-02 -1.02343690e-02\n",
            " -9.69771966e-02 -2.99995504e-02 -2.86679417e-02  2.24936940e-02\n",
            " -1.68121196e-02 -1.43673839e-02 -8.79590493e-03 -1.69044118e-02\n",
            "  2.41557825e-02 -6.53192475e-02 -4.10800055e-02 -2.34058369e-02\n",
            " -6.76065087e-02 -1.55690126e-02  3.62358131e-02  7.83159807e-02\n",
            " -4.97516915e-02 -7.08547756e-02 -5.01179770e-02 -8.56404135e-04\n",
            "  5.44897746e-03  4.34703613e-03  9.88053083e-02 -2.16415580e-02\n",
            " -1.87750813e-02  1.15069589e-02  2.63996385e-02  1.65235661e-02\n",
            " -2.24058032e-02 -4.31826673e-02  1.31803885e-01 -2.97034122e-02\n",
            "  2.65934132e-02 -1.38888787e-02 -1.67003851e-02  3.44145522e-02\n",
            " -8.94354936e-03  6.16001487e-02 -3.42303105e-02  2.46421131e-03\n",
            " -8.14095326e-03  5.80325164e-02  5.24208285e-02 -1.53281046e-02\n",
            "  4.01382335e-02  1.51407188e-02 -3.01462715e-03 -4.97021228e-02\n",
            " -4.24302788e-03  5.77289090e-02  3.17873806e-02  4.74008322e-02\n",
            "  2.95218211e-02 -1.50123015e-02 -2.47945394e-02 -7.11501837e-02\n",
            "  2.06847955e-02  3.11488193e-02 -5.86067978e-03  1.62786860e-02\n",
            " -3.93682979e-02  5.46505675e-02  3.26595455e-02 -1.87021624e-02\n",
            " -9.79863182e-02  4.33778483e-03 -5.58157302e-02 -1.34620788e-02\n",
            "  2.88454238e-02  1.58748217e-02 -3.32564376e-02  1.44418271e-03\n",
            " -5.51108047e-02  8.24674964e-02  2.38845963e-02 -2.04838086e-02\n",
            " -4.78587579e-03  3.78722958e-02 -4.87563051e-02  3.44647244e-02\n",
            "  1.10358596e-02  1.12450458e-02  1.33262808e-02 -3.46375220e-02\n",
            " -6.92220703e-02  7.30120856e-03 -6.57011755e-03  1.73203778e-02\n",
            "  5.23055485e-03  4.48132083e-02  3.89852785e-02 -1.99274719e-02\n",
            " -1.80920269e-02  3.25938128e-02 -2.02027205e-02  4.86271136e-04\n",
            " -8.88757221e-03 -1.91347934e-02  2.50685941e-02  4.74019684e-02\n",
            "  2.18653562e-03 -1.69988237e-02  3.62670906e-02  3.46248061e-03\n",
            "  4.21927962e-03  8.04170966e-02  3.10627073e-02 -1.04945619e-03\n",
            " -3.55466567e-02  4.34836857e-02 -3.06218714e-02 -3.03191822e-02\n",
            " -4.13175374e-02 -1.05258077e-02 -2.35242154e-02 -1.86772346e-02\n",
            "  4.42934828e-03  5.45056500e-02 -6.05017543e-02  2.48421840e-02\n",
            " -3.36967446e-02 -4.54169177e-02 -2.63173152e-02  6.98053418e-03\n",
            "  6.92871362e-02 -2.04491597e-02 -1.96812954e-02 -9.72559676e-03\n",
            " -1.21564763e-02  7.89341703e-03  1.84749323e-03 -6.93651065e-02\n",
            "  2.43357364e-02  4.00609449e-02  3.44013311e-02 -2.84281969e-02\n",
            " -1.09431576e-02  1.38742989e-02 -4.40584915e-03  1.19345926e-03\n",
            " -8.81165117e-02  1.15931612e-02 -2.56350879e-02  5.57525307e-02\n",
            "  1.26946196e-01  5.39565906e-02 -1.41436839e-02  1.27196591e-02\n",
            " -1.32235829e-02 -5.94484620e-02  2.86704022e-02  2.57284474e-02\n",
            " -8.33778083e-03  8.17355118e-04  5.93052525e-03  3.29110399e-02\n",
            "  4.12752070e-02 -5.77966031e-03 -1.71124283e-02  1.06227677e-02\n",
            " -2.19601914e-02 -4.97207269e-02  2.53766086e-02 -5.60257652e-33\n",
            " -1.35397380e-02 -3.77958678e-02 -2.67923321e-03 -3.69707705e-04\n",
            " -1.98267438e-02  5.47052128e-03  6.02688221e-03  1.93069018e-02\n",
            "  3.87977972e-03  2.97698993e-02 -1.88229028e-02  2.20039487e-03\n",
            "  8.17020144e-03  1.61964949e-02  3.17529403e-02 -6.83415076e-03\n",
            "  2.19252128e-02  4.37736977e-04  2.96859108e-02 -2.62557138e-02\n",
            "  6.49377238e-03  3.56025323e-02  1.58605922e-03 -4.76584062e-02\n",
            " -5.26238717e-02  3.78274284e-02  3.54341976e-02 -3.10347639e-02\n",
            "  7.96405692e-03  5.48469909e-02 -3.56443375e-02  9.10137035e-03\n",
            " -9.45986249e-03 -4.63287272e-02 -1.63906552e-02  6.32453188e-02\n",
            " -1.38588166e-02 -5.95724620e-02 -1.57990996e-02  2.01886967e-02\n",
            " -1.98292602e-02 -3.49211581e-02  2.27937549e-02 -5.91621958e-02\n",
            "  4.18854654e-02  1.20739406e-03  5.19158877e-02 -1.88436080e-02\n",
            " -3.12102139e-02  2.34932862e-02 -7.41029978e-02 -2.76594743e-04\n",
            " -1.51719945e-02  6.11713789e-02  1.25065088e-01 -1.28459092e-02\n",
            " -1.12671144e-02  1.51753495e-03 -8.09153542e-02  1.12689203e-02\n",
            " -1.97573546e-02  2.74268426e-02  9.40993428e-03 -9.58756730e-03\n",
            "  2.54850034e-02  6.81658909e-02 -1.83453206e-02 -1.00963950e-01\n",
            " -9.45242029e-03 -5.27015422e-03  1.98684055e-02  9.80847999e-02\n",
            "  3.15633416e-02  5.30422814e-02  3.75123210e-02 -6.64208531e-02\n",
            " -5.92880286e-02 -1.57073885e-02  1.76609289e-02 -5.81073239e-02\n",
            "  2.23230571e-02  1.29869413e-02 -3.30261216e-02  9.96896648e-04\n",
            " -9.87089984e-03 -3.12955193e-02  2.28528515e-03 -4.91250455e-02\n",
            "  1.47693781e-02 -1.83367264e-02 -4.16306220e-02  3.76897119e-02\n",
            "  3.35410275e-02 -7.97111690e-02  4.01299335e-02  1.59071758e-02\n",
            "  5.06082084e-03  4.28808108e-02  2.29760315e-02 -4.13350910e-02\n",
            " -3.10503747e-02 -5.26405051e-02 -4.95404862e-02 -2.94256434e-02\n",
            "  5.94924316e-02 -2.59802695e-02  3.02497260e-02  8.80406424e-03\n",
            " -4.84467149e-02 -2.00851578e-02  9.82179027e-03 -7.89194182e-02\n",
            "  4.52878466e-03 -9.34896991e-03  9.23313852e-03 -3.17361802e-02\n",
            "  2.10833270e-02  6.37117773e-03  3.36348005e-02  3.83613929e-02\n",
            " -4.55527529e-02  1.08120276e-03 -9.83326603e-03  7.70196225e-03\n",
            " -2.87617892e-02 -1.74959507e-02 -4.27815085e-03  2.81287059e-02\n",
            "  4.97339852e-02 -7.45570734e-02 -1.07009150e-02 -7.66055705e-03\n",
            "  2.33968862e-07  1.52483368e-02  8.39613900e-02  3.67242694e-02\n",
            " -3.69248651e-02  3.64751816e-02  4.26422209e-02 -4.39828215e-03\n",
            "  1.78133883e-02 -2.67076623e-02 -7.13901129e-03  5.59975468e-02\n",
            "  3.13966535e-02  2.13443302e-03  3.90371308e-02 -8.78528282e-02\n",
            " -2.21659765e-02 -2.47735474e-02 -1.18189696e-02 -7.89708644e-03\n",
            " -2.08857581e-02  4.30555828e-02  1.07643545e-01  4.40618545e-02\n",
            "  1.47962738e-02  2.44862996e-02 -3.86268236e-02  1.80743653e-02\n",
            " -1.47839868e-03  7.74167031e-02 -4.19565700e-02 -3.80529128e-02\n",
            "  3.61257493e-02  1.59031036e-03  1.95324030e-02 -2.00080797e-02\n",
            "  4.22538295e-02  3.06110885e-02 -3.53689468e-03  5.93103329e-03\n",
            " -2.23223493e-02 -2.07131468e-02 -3.62911192e-03  1.74653828e-02\n",
            " -4.08759005e-02  5.91595173e-02 -5.89099862e-02 -3.96753885e-02\n",
            " -3.33528854e-02  1.02161821e-02  6.97292062e-03  7.70389810e-02\n",
            " -1.86911710e-02 -1.82568543e-02 -2.42319237e-02 -3.40699940e-03\n",
            " -3.60555351e-02  4.33389656e-02 -3.48602235e-02  5.27768470e-02\n",
            "  2.89709717e-02 -4.98462208e-02 -1.94749329e-02  1.16397832e-02\n",
            " -3.04614641e-02  8.04637671e-02  6.56248033e-02 -2.84532979e-02\n",
            "  1.81615312e-34 -4.19157417e-03 -2.57882606e-02  5.17320596e-02\n",
            "  4.94420975e-02  1.32476604e-02 -4.21994254e-02 -1.12458579e-02\n",
            " -2.61519644e-02  5.51130585e-02  2.20024865e-02 -2.51170285e-02]\n",
            "\n",
            "Sentence: Learn to use embeddings well and you'll be well on your way to being an AI engineer.\n",
            "Embedding: [-2.20730789e-02  2.08950378e-02 -6.03005365e-02  8.43946729e-03\n",
            "  4.37650904e-02  1.55070378e-02  4.99907732e-02 -3.03232390e-02\n",
            "  4.94784154e-02  2.35512313e-02  3.29350717e-02  1.53877577e-02\n",
            " -6.68355152e-02  1.11002848e-01  6.92677274e-02 -2.31888648e-02\n",
            "  3.79102752e-02 -4.94146999e-03 -1.57800354e-02 -3.45476493e-02\n",
            " -2.65052747e-02 -2.47879494e-02 -1.86141469e-02  3.00361924e-02\n",
            " -2.81186271e-02 -8.75130203e-03 -3.30773089e-03 -2.06115842e-02\n",
            "  1.03315581e-02 -1.51483119e-02 -3.48330885e-02 -2.63248291e-02\n",
            "  2.06908081e-02  3.79109047e-02  1.81912878e-06 -2.44284887e-03\n",
            " -1.80562399e-03  5.61762601e-03 -2.79870108e-02  1.54703064e-02\n",
            "  3.06456368e-02  3.72600965e-02 -1.55611457e-02  2.54414566e-02\n",
            " -6.42072335e-02  3.16353291e-02  6.63442165e-02  3.80970277e-02\n",
            "  5.57844900e-02  5.31659871e-02 -9.69289709e-03 -3.61423865e-02\n",
            "  3.72434966e-02 -4.67828615e-03  5.14574982e-02  1.00057852e-02\n",
            "  4.90289647e-03  1.41562494e-02  4.95099947e-02  3.32949543e-03\n",
            " -3.21100689e-02  4.42388132e-02  3.27416360e-02 -7.90620223e-03\n",
            "  1.07809782e-01  7.32945055e-02  3.36702541e-02 -4.28345799e-02\n",
            "  1.05966348e-02  2.05653869e-02 -2.02670060e-02  1.04964329e-02\n",
            " -1.97615847e-02 -2.89400868e-05 -2.61862557e-02 -1.85173880e-02\n",
            " -3.44269499e-02 -4.08621430e-02  2.32571661e-02  2.14195754e-02\n",
            "  1.31321000e-02 -3.27211320e-02 -1.91425607e-02 -2.86572073e-02\n",
            " -1.16859321e-02  1.21910684e-02  1.05248326e-02 -3.39584984e-02\n",
            "  3.08906357e-03 -4.44888361e-02  2.65105050e-02  1.09536275e-02\n",
            "  2.51450744e-02 -6.48836140e-03  4.54370398e-03 -2.02785153e-02\n",
            " -1.03216311e-02  2.06590239e-02 -1.65314153e-02 -2.45611984e-02\n",
            "  5.47549464e-02  2.68261284e-02  2.95510739e-02  3.86754386e-02\n",
            " -7.76720047e-02  3.80055718e-02 -2.98364609e-02  7.96886235e-02\n",
            " -3.00943386e-02  7.57847680e-03 -6.89826533e-02 -2.92666741e-02\n",
            " -2.35580001e-02  3.48198116e-02  2.52938196e-02 -4.53817137e-02\n",
            " -1.57938581e-02  4.39031161e-02 -4.04335782e-02  8.32527410e-03\n",
            " -2.84665246e-02  4.94934060e-02  2.41276734e-02  3.02191935e-02\n",
            " -4.99590747e-02 -5.94533049e-02 -3.70175764e-02  1.30330836e-02\n",
            " -3.36468704e-02  3.45589668e-02 -1.44523168e-02  2.57640034e-02\n",
            "  4.61182604e-03  2.21551936e-02 -4.93460149e-03  9.66005027e-02\n",
            " -2.72451574e-03  5.65355062e-04 -3.24248001e-02  1.31681822e-02\n",
            "  4.41607349e-02 -7.03053037e-03  6.84261173e-02 -2.28166487e-02\n",
            " -2.81031011e-03 -4.23883386e-02 -1.33632068e-02 -5.96738867e-02\n",
            " -6.96124090e-03 -2.31901389e-02 -3.78851332e-02  9.80186462e-02\n",
            " -2.21728832e-02 -2.30062660e-02  3.22815180e-02  8.21805652e-03\n",
            " -7.04122894e-03  4.84079421e-02  4.23291177e-02 -2.59713549e-03\n",
            "  1.20481083e-04  1.67414229e-02  2.91198026e-02 -1.28740566e-02\n",
            " -2.41077766e-02 -3.29319388e-02 -3.50287976e-03 -3.19321975e-02\n",
            " -2.64171790e-02  2.30404399e-02  1.11637358e-02 -9.96002089e-03\n",
            " -1.75901111e-02 -2.00277125e-03  1.21594928e-02  4.67823222e-02\n",
            "  5.20882010e-02  7.21171871e-02  1.94978509e-02  1.15072737e-02\n",
            "  5.94164943e-03 -1.47833200e-02 -2.87724324e-02  6.72665983e-02\n",
            " -1.68758631e-02  5.25874132e-03 -3.39737348e-02  5.24596199e-02\n",
            " -2.59793345e-02 -4.41379882e-02  1.47451949e-03 -1.06598893e-02\n",
            " -1.51859261e-02 -1.55875913e-03  1.81505233e-02 -4.85411249e-02\n",
            "  3.67908622e-03 -6.59313798e-02 -1.49418339e-02 -3.23528983e-02\n",
            " -2.79949382e-02  1.71856657e-02 -7.87090510e-03  4.65692319e-02\n",
            "  1.47123458e-02 -7.40438700e-02 -6.52104393e-02 -5.22734933e-02\n",
            " -1.82343386e-02  5.20859174e-02  3.06304563e-02 -2.36037280e-02\n",
            "  2.42384523e-02 -1.83939468e-02 -4.83017601e-03 -2.13386659e-02\n",
            "  1.56583507e-02  9.87340882e-03 -4.25561778e-02  6.00462733e-03\n",
            " -3.14500323e-03  4.51512169e-03 -1.52779440e-03  1.13731585e-02\n",
            " -6.96354210e-02 -3.37257385e-02  1.33406678e-02  4.87288972e-03\n",
            " -7.81492889e-03  4.78049628e-02 -1.59711950e-02  3.14606354e-02\n",
            "  5.15920632e-02 -4.05122526e-02 -5.06461151e-02  9.99931712e-03\n",
            " -2.00729389e-02  4.21552695e-02  3.03182583e-02 -1.00431308e-01\n",
            " -4.12019938e-02  3.43990549e-02  3.29209156e-02  1.07408373e-03\n",
            "  3.70961837e-02 -6.94237277e-02  6.52394071e-02  8.31665471e-03\n",
            "  1.68036297e-02 -2.60705985e-02  8.14495515e-03 -1.48009406e-02\n",
            " -2.65671238e-02  3.29321325e-02 -7.37512484e-03  7.23977387e-03\n",
            " -2.69329324e-02  1.71754733e-02 -2.28083096e-02 -4.75339359e-03\n",
            "  2.88568828e-02  1.30800778e-04  5.44128604e-02 -1.43378610e-02\n",
            "  1.89891569e-02 -1.32732224e-02  4.01177295e-02 -7.29275271e-02\n",
            " -2.41211001e-02  3.16216908e-02 -1.68014541e-02  8.47543124e-03\n",
            " -5.23940548e-02 -1.43882707e-02 -1.46156475e-02  6.39906013e-03\n",
            "  2.15113629e-02 -5.18960319e-02 -4.30576280e-02  2.34075896e-02\n",
            "  2.30273814e-03 -2.48434208e-02 -4.38243262e-02 -2.16570701e-02\n",
            " -6.91595599e-02  1.76769812e-02  2.12067924e-02 -2.20293514e-02\n",
            " -1.06773637e-02  9.57427733e-03  2.21988559e-02  5.51470779e-02\n",
            "  1.03682876e-02 -8.14825371e-02 -7.94705097e-03 -1.85866151e-02\n",
            "  1.20494235e-02  7.51403496e-02 -1.41215865e-02  8.83924663e-02\n",
            "  3.12628560e-02  8.12263787e-03 -2.29444783e-02  3.96010391e-02\n",
            " -2.00167950e-02  9.16027650e-02 -2.06839554e-02  5.84990866e-02\n",
            " -4.32368554e-02 -4.74750809e-03 -9.51891951e-03  5.42950863e-03\n",
            "  1.19126387e-04  6.15377091e-02 -1.68787281e-03 -4.66321409e-02\n",
            " -2.01405138e-02  1.32406233e-02  9.70686972e-03  2.73847468e-02\n",
            "  3.06639802e-02  6.71580108e-03  8.71220902e-02 -1.97375263e-03\n",
            "  8.18298385e-03  5.44363260e-03 -5.76205924e-02  1.34821245e-02\n",
            "  5.06281527e-03 -2.10568774e-02  1.25937080e-02 -5.49777178e-03\n",
            " -1.44645032e-02 -2.92567443e-02  5.53299263e-02 -2.60099564e-02\n",
            " -2.82450509e-03 -2.30902229e-02  8.89710709e-03 -2.61565186e-02\n",
            "  9.08613089e-04 -6.16204254e-02 -7.56418929e-02 -1.05932355e-02\n",
            " -1.19563723e-02  6.71458542e-02 -1.96234621e-02 -5.00934310e-02\n",
            " -3.91229242e-02 -3.07008494e-02  7.18906447e-02  9.29245353e-03\n",
            " -6.34388346e-03  7.86940742e-04 -1.36484224e-02  2.87188552e-02\n",
            "  4.01224680e-02  1.28037268e-02  1.77381393e-02 -4.75977454e-03\n",
            "  5.47173657e-02  1.10810972e-03 -2.25790367e-02 -2.80290749e-03\n",
            " -1.13696076e-01  2.55904589e-02  4.00445570e-04 -4.39810567e-02\n",
            "  1.36319092e-02 -1.54137574e-02 -4.99015115e-02 -2.32889634e-02\n",
            " -1.62987469e-03  3.95835154e-02  1.89040210e-02 -3.02703064e-02\n",
            "  2.71438062e-02  1.05685764e-03 -4.21068780e-02  3.71961370e-02\n",
            "  3.54258530e-02 -6.98274672e-02 -2.20937636e-02 -4.01495770e-02\n",
            " -1.90164130e-02 -2.69835424e-02 -1.51212923e-02  3.33365463e-02\n",
            " -9.74889472e-02  1.73102580e-02  6.21013576e-03 -2.59423093e-03\n",
            " -1.10152960e-01 -6.10186458e-02 -1.36549752e-02 -1.35034993e-02\n",
            " -6.72574267e-02 -4.05119825e-03 -6.64984901e-03  3.86568811e-03\n",
            "  9.43471678e-03 -3.86636667e-02 -1.93593167e-02  1.34933861e-02\n",
            " -4.58106883e-02  6.06737509e-02  6.06380180e-02  4.85596098e-02\n",
            " -4.56088744e-02 -5.71936443e-02 -1.55094853e-02  3.40963267e-02\n",
            "  9.48153553e-04 -9.94347408e-03  2.84657683e-02 -3.29024643e-02\n",
            " -2.83211116e-02  3.19907628e-02  2.61299107e-02 -2.74054855e-02\n",
            " -1.36352722e-02  7.47715589e-03  1.19430296e-01 -4.45807092e-02\n",
            "  1.07671879e-02 -8.69424269e-02 -2.19551232e-02  1.83874518e-02\n",
            " -1.06521556e-02 -1.89243145e-02 -3.06513999e-02 -3.04701868e-02\n",
            " -3.22214998e-02  4.12150919e-02  8.95758998e-03 -2.73179747e-02\n",
            "  9.39996447e-03 -9.57189419e-04 -1.94010269e-02 -4.92622592e-02\n",
            " -9.18892305e-03  4.66893949e-02  5.41893542e-02  2.21609436e-02\n",
            " -2.86352020e-02  5.20295575e-02  2.47589722e-02 -7.14267865e-02\n",
            " -1.26206921e-02  7.35522620e-03  2.13784967e-02  2.93514151e-02\n",
            " -2.57651191e-02  5.20562343e-02 -2.74892393e-02 -3.10242567e-02\n",
            " -9.02880505e-02  6.10371791e-02 -5.22610024e-02  2.13111378e-02\n",
            "  4.41735461e-02  3.23370770e-02  1.75648611e-02 -2.39519849e-02\n",
            " -2.69709565e-02  5.11278845e-02  2.69064419e-02 -4.51932661e-02\n",
            "  2.52656150e-03  2.44934224e-02 -2.89541222e-02  2.79992614e-02\n",
            " -1.36022344e-02 -4.32368480e-02  1.85830146e-02  7.63600547e-05\n",
            "  2.43510236e-03 -3.73321772e-03 -1.72279850e-02  1.01292739e-02\n",
            "  1.98437292e-02 -2.60018334e-02 -3.40177747e-03  1.09125776e-02\n",
            " -4.16363589e-02  3.37032191e-02 -2.81634834e-02  1.79126430e-02\n",
            " -4.53095213e-02 -1.09819025e-02 -2.20828876e-03  1.99102368e-02\n",
            "  3.56372371e-02 -3.11799124e-02  3.78752537e-02 -1.41408965e-02\n",
            " -2.16907579e-02  2.73019914e-02  3.69818695e-03  6.35387599e-02\n",
            "  1.22669153e-02 -6.02271082e-03 -7.60753360e-03 -1.86565034e-02\n",
            " -5.64716849e-03 -2.20050756e-03 -1.31825674e-02  1.67723969e-02\n",
            " -3.77264321e-02  2.97895428e-02 -5.01569882e-02  4.89088148e-02\n",
            " -6.07445128e-02 -8.39419141e-02 -5.09001054e-02  1.81768201e-02\n",
            "  6.66732788e-02 -3.30036576e-03 -2.82403431e-03 -5.35406061e-02\n",
            "  3.90341058e-02  2.19852515e-02  3.13554965e-02 -3.36526856e-02\n",
            "  1.96913630e-02  1.67883337e-02  5.04003018e-02  3.08061484e-03\n",
            " -7.24790676e-04  4.42907102e-02 -4.12959186e-03  4.29329164e-02\n",
            " -6.62552416e-02  1.16061489e-03 -2.81716399e-02  1.56885628e-02\n",
            "  9.78133827e-02  5.53594567e-02 -1.39378663e-02  2.12306920e-02\n",
            " -1.30955493e-02 -6.82027638e-02 -8.09120596e-04  4.99291569e-02\n",
            " -2.69266032e-02 -2.97804121e-02  3.84462103e-02  1.97354686e-02\n",
            "  3.37088406e-02  1.65873710e-02  5.77318622e-03 -3.04898154e-02\n",
            " -1.52511839e-02 -3.56159322e-02 -8.69218260e-03 -5.42296833e-33\n",
            "  3.24374111e-03 -3.46329659e-02  3.58932763e-02  1.83770731e-02\n",
            " -2.17505209e-02 -3.26411501e-02  2.88398727e-03  1.50463730e-02\n",
            " -1.75262569e-03 -1.99418589e-02 -6.10355847e-03  2.23847125e-02\n",
            " -8.78949009e-04  2.48684827e-02  3.39736640e-02  2.75593083e-02\n",
            "  3.37792486e-02  3.98564674e-02  2.55545266e-02  1.83042735e-02\n",
            " -2.92878766e-02  5.18082874e-03  8.37716216e-04 -3.66560258e-02\n",
            " -3.46732773e-02  3.82687002e-02  5.50824916e-03 -4.35187705e-02\n",
            "  2.44077872e-02  3.54167409e-02 -2.13442389e-02  2.86623873e-02\n",
            " -2.65393202e-04  3.73409092e-02 -8.68169963e-03  3.04786791e-03\n",
            " -2.71682106e-02 -3.85088064e-02 -6.12388700e-02 -2.00843648e-03\n",
            " -1.22080101e-02 -8.67197886e-02  3.75361089e-03 -1.77707635e-02\n",
            "  8.32475629e-03 -1.69167910e-02  7.02404156e-02  3.32234018e-02\n",
            "  4.34313193e-02  1.47016672e-02 -1.25546902e-01  1.50866620e-02\n",
            " -5.43164499e-02 -1.79150619e-03  4.99600917e-02 -1.53786503e-02\n",
            "  3.32683846e-02 -3.07708886e-02 -1.83896720e-02  9.45797563e-03\n",
            " -4.60291207e-02 -2.03868700e-03  2.62429062e-02 -5.00789396e-02\n",
            "  2.01835707e-02  6.08983077e-02 -2.01180689e-02 -2.60054376e-02\n",
            "  1.05925510e-02 -3.31153870e-02  1.62595529e-02  7.77862370e-02\n",
            " -1.90729683e-03 -5.62888850e-03  1.43715795e-02 -4.06833775e-02\n",
            " -5.14971018e-02  1.66253143e-04 -3.33061465e-03  1.44688822e-02\n",
            "  4.24922648e-04  3.04452889e-02 -1.83636770e-02  1.51186541e-03\n",
            "  2.99861338e-02 -3.68002243e-02  8.35627690e-03 -3.31025571e-02\n",
            "  2.66911834e-02  5.47830900e-03 -1.80524234e-02  2.42577009e-02\n",
            "  5.72709087e-03 -5.93372509e-02  1.04358487e-01 -9.87923238e-03\n",
            " -1.36105847e-02  5.79998605e-02  2.50108726e-02  2.89337393e-02\n",
            " -3.20521444e-02 -3.40233222e-02 -3.41698676e-02 -2.76981182e-02\n",
            "  6.47003129e-02  1.50797870e-02 -1.61925498e-02  3.03265937e-02\n",
            " -2.67187860e-02 -3.67774218e-02 -2.27845497e-02 -5.36433943e-02\n",
            "  1.90500021e-02 -3.42503376e-02  1.32688442e-02 -5.41318813e-03\n",
            "  7.49741821e-03 -7.37009745e-04 -3.08569707e-02  3.82288657e-02\n",
            " -2.08311230e-02 -3.43154930e-02  5.60238911e-03  1.45000098e-02\n",
            " -3.76364142e-02 -5.11782467e-02 -3.51075493e-02  1.71867963e-02\n",
            "  1.50721548e-02 -9.62026268e-02 -1.53545467e-02  1.58376452e-02\n",
            "  2.42940956e-07 -5.88808162e-03  7.68795833e-02  5.86063564e-02\n",
            "  2.21232697e-02 -2.36690864e-02  5.25274239e-02  1.48661416e-02\n",
            "  7.34179141e-03 -4.98920865e-03  4.37413752e-02 -1.28331883e-02\n",
            "  3.37342396e-02 -1.10814888e-02 -1.33938054e-02 -7.80063495e-02\n",
            " -1.36330593e-02  1.94749013e-02  1.91750925e-03 -3.00251786e-02\n",
            "  1.02691185e-04  9.54533294e-02  1.19653948e-01  3.73371728e-02\n",
            "  4.25125007e-03  2.05129907e-02 -3.85414846e-02 -1.90614536e-02\n",
            "  5.88793531e-02  6.81264624e-02 -3.12595740e-02 -6.50441125e-02\n",
            "  2.48045102e-02  3.90083675e-04  7.54761621e-02 -3.46075781e-02\n",
            "  1.32949334e-02  4.14005816e-02  3.07569169e-02  5.50354179e-03\n",
            " -1.53087277e-03  2.75993627e-02  6.46030158e-03  1.05398176e-02\n",
            " -3.09298709e-02  4.60232422e-02 -3.64921205e-02 -1.39540434e-02\n",
            " -3.53720710e-02  7.97824992e-04  1.40632782e-02  1.80258583e-02\n",
            " -1.43368607e-02  2.19214708e-03 -3.96873355e-02 -1.17282113e-02\n",
            " -4.45220545e-02  8.05770420e-03 -4.04861309e-02  3.56149152e-02\n",
            "  5.12852445e-02 -6.64038956e-02 -5.32594919e-02  8.92902352e-03\n",
            "  1.56424306e-02  1.02110937e-01  8.10770784e-03 -4.03859885e-03\n",
            "  2.02352536e-34 -1.38294064e-02 -1.17623620e-02  1.51006067e-02\n",
            "  8.25896338e-02  2.39228457e-02 -1.10378051e-02  3.65654519e-03\n",
            " -7.44783180e-03  2.94554979e-02  3.52995517e-03 -6.10421821e-02]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Requires !pip install sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",\n",
        "                                      device=\"cuda\") # choose the device to load the model to (note: GPU will often be *much* faster than CPU)\n",
        "\n",
        "# Create a list of sentences to turn into numbers\n",
        "sentences = [\n",
        "    \"The Sentences Transformers library provides an easy and open-source way to create embeddings.\",\n",
        "    \"Sentences can be embedded one by one or as a list of strings.\",\n",
        "    \"Embeddings are one of the most powerful concepts in machine learning!\",\n",
        "    \"Learn to use embeddings well and you'll be well on your way to being an AI engineer.\"\n",
        "]\n",
        "\n",
        "# Sentences are encoded/embedded by calling model.encode()\n",
        "embeddings = embedding_model.encode(sentences)\n",
        "embeddings_dict = dict(zip(sentences, embeddings))\n",
        "\n",
        "# See the embeddings\n",
        "for sentence, embedding in embeddings_dict.items():\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"Embedding:\", embedding)\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODZNQXgul065"
      },
      "source": [
        "Woah! That's a lot of numbers.\n",
        "\n",
        "How about we do just once sentence?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "WoYXVVJel065",
        "outputId": "b8da0357-2ebb-47dd-8c67-f51c8435857c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: Yo! How cool are embeddings?\n",
            "Embedding:\n",
            "[-1.97447482e-02 -4.51083714e-03 -4.98482492e-03  6.55445009e-02\n",
            " -9.87671968e-03  2.72835568e-02  3.66426110e-02 -3.30221280e-03\n",
            "  8.50079115e-03  8.24954547e-03 -2.28497442e-02  4.02430184e-02\n",
            " -5.75200021e-02  6.33692294e-02  4.43207473e-02 -4.49507162e-02\n",
            "  1.25284223e-02 -2.52012350e-02 -3.55292335e-02  1.29558872e-02\n",
            "  8.67024530e-03 -1.92917641e-02  3.55635560e-03  1.89506002e-02\n",
            " -1.47128012e-02 -9.39845853e-03  7.64171872e-03  9.62188747e-03\n",
            " -5.98928286e-03 -3.90169397e-02 -5.47824539e-02 -5.67456661e-03\n",
            "  1.11644994e-02  4.08067293e-02  1.76319099e-06  9.15297959e-03\n",
            " -8.77260044e-03  2.39382759e-02 -2.32784562e-02  8.04999545e-02\n",
            "  3.19176838e-02  5.12595987e-03 -1.47708356e-02 -1.62524562e-02\n",
            " -6.03213347e-02 -4.35689725e-02  4.51211482e-02 -1.79053750e-02\n",
            "  2.63367202e-02 -3.47867161e-02 -8.89172871e-03 -5.47674894e-02\n",
            " -1.24372896e-02 -2.38606650e-02  8.33496898e-02  5.71242124e-02\n",
            "  1.13328528e-02 -1.49594611e-02  9.20378417e-02  2.72709243e-02\n",
            " -1.42185939e-02  1.91209260e-02  1.49963228e-02 -3.12198643e-02\n",
            "  8.99579823e-02  4.51188534e-02  2.58020461e-02 -5.51741524e-03\n",
            "  1.15909772e-02  4.72100638e-02 -1.51018742e-02  1.70818474e-02\n",
            " -7.22598145e-03  3.45763154e-02 -8.76467675e-03  5.22016548e-02\n",
            " -6.49008900e-02 -4.31378707e-02  6.36964664e-02  4.02881205e-02\n",
            " -1.99043099e-02  5.39063942e-03  1.28820585e-02 -4.81255278e-02\n",
            "  4.58801389e-02 -2.17094850e-02  1.89203434e-02 -3.46344486e-02\n",
            " -1.66457538e-02  7.65167410e-03 -2.26693358e-02 -1.96454320e-02\n",
            "  1.87632348e-02  1.01383058e-02  6.85413331e-02 -5.39851096e-03\n",
            " -3.38229374e-03  4.08413187e-02  4.98623587e-02 -1.16485702e-02\n",
            "  8.91739130e-02  4.02785726e-02 -3.64715629e-03  4.37758416e-02\n",
            " -2.96079442e-02 -5.53758210e-03 -2.00209003e-02 -2.01983340e-02\n",
            "  4.59849201e-02  2.29337476e-02 -5.37305214e-02 -3.19279172e-02\n",
            "  1.37544516e-03  6.25036582e-02 -2.18308866e-02 -6.43255413e-02\n",
            " -2.24791579e-02  3.31954993e-02 -3.12837362e-02  5.17936535e-02\n",
            " -2.84002796e-02  2.55067609e-02  3.36492881e-02  7.50667453e-02\n",
            " -4.46477439e-03 -4.87705655e-02 -7.35218823e-02 -5.46353199e-02\n",
            "  8.88531469e-03  2.95797009e-02 -9.95698292e-03 -6.32764585e-03\n",
            "  4.46259677e-02 -1.58483926e-02 -1.71330161e-02  3.36602628e-02\n",
            " -1.57673669e-03 -5.45971990e-02  2.91161370e-02 -2.80596428e-02\n",
            "  2.96793431e-02  5.12153432e-02  1.48766255e-02 -4.76489253e-02\n",
            "  1.26052024e-02  1.49846170e-03  1.33206844e-02 -2.82468796e-02\n",
            " -3.29254717e-02 -8.53571109e-03 -5.27607650e-02  7.29350299e-02\n",
            " -6.41821325e-02 -2.51785270e-03 -9.02634952e-03 -1.10468804e-03\n",
            "  1.57514606e-02  4.30823714e-02  1.12269418e-02 -3.54585238e-02\n",
            "  4.95163426e-02  1.21271312e-02  1.66344142e-03 -5.06923348e-03\n",
            " -1.11001991e-02 -8.66917614e-03 -3.26440148e-02 -3.98021825e-02\n",
            " -2.05971245e-02  1.09074069e-02 -6.62529394e-02  3.71706709e-02\n",
            " -3.74916419e-02 -3.24731544e-02  5.85900024e-02  8.48080739e-02\n",
            "  3.92412357e-02  3.15814205e-02  3.78386565e-02 -1.35472659e-02\n",
            "  5.95062524e-02  2.58904938e-02 -1.31899957e-02  6.30589947e-02\n",
            "  3.27136889e-02  6.92141149e-03 -1.42606813e-02  7.76676685e-02\n",
            " -1.16103357e-02 -3.66427824e-02 -2.83837561e-02  2.72279810e-02\n",
            "  2.49365233e-02 -4.22296859e-03 -3.63100767e-02 -2.04887781e-02\n",
            "  3.98861095e-02 -2.64727455e-02  4.41382686e-03 -5.19635305e-02\n",
            "  1.71360953e-05  4.81284186e-02  2.04450246e-02  9.84970331e-02\n",
            "  3.68267894e-02  1.53405191e-02  7.50977953e-04 -3.38638760e-02\n",
            " -2.69872528e-02  4.72445413e-02  4.56702374e-02 -3.49246152e-02\n",
            " -1.18770394e-02  3.45578697e-03 -6.32300042e-03 -4.78412062e-02\n",
            "  1.84098631e-02 -2.23157480e-02 -3.70728038e-02  5.87340072e-02\n",
            "  6.22731587e-03 -1.46716051e-02  7.29223490e-02  2.21958780e-03\n",
            " -6.53119385e-02  3.51679511e-02 -1.54901613e-02  6.01421483e-02\n",
            " -9.41004604e-03  2.81196572e-02 -1.12651670e-02  5.24157600e-04\n",
            "  1.01888604e-01 -5.69957606e-02 -3.52360532e-02 -5.20476885e-03\n",
            " -8.46638158e-03  1.39209190e-02  1.80780292e-02 -1.10494018e-01\n",
            "  5.13116829e-02 -4.36432287e-02  2.84142829e-02  9.55941435e-03\n",
            "  4.28096354e-02 -3.95833254e-02  5.25829196e-02  1.92814805e-02\n",
            "  3.44889238e-03 -1.76870935e-02  3.85699086e-02  6.92507671e-03\n",
            " -3.59440632e-02 -2.63613500e-02 -4.96692583e-03  4.24526036e-02\n",
            " -4.22464050e-02  3.45897977e-03  3.55866700e-02 -1.68201849e-02\n",
            "  3.54331285e-02  4.52799909e-03  6.46285806e-03 -2.17710994e-02\n",
            " -2.50033587e-02  1.41418381e-02  1.51257794e-02 -2.99570095e-02\n",
            " -3.94227430e-02  1.87821761e-02 -1.68782321e-03 -9.83500388e-04\n",
            " -3.26321572e-02  5.06564742e-03 -8.90460890e-03 -1.55095328e-02\n",
            "  1.87758189e-02 -4.52472977e-02 -1.72956958e-02  3.50973569e-02\n",
            "  1.33018196e-02  1.00633400e-02 -4.36593518e-02 -1.68619324e-02\n",
            " -1.91048104e-02  6.35489151e-02  8.08325037e-03 -1.02532981e-02\n",
            " -4.53625293e-03 -4.60835919e-02 -1.64704509e-02 -6.24686573e-03\n",
            "  2.58868430e-02 -6.39064312e-02 -7.82397017e-03 -2.36076061e-02\n",
            "  2.74617579e-02  5.80535643e-02 -3.40748802e-02  6.46012202e-02\n",
            "  2.00063139e-02 -2.14935541e-02  1.69361047e-02 -5.54066058e-03\n",
            " -2.40397155e-02  3.09443735e-02 -2.34441948e-03  3.02590001e-02\n",
            " -4.57217880e-02  2.00641416e-02 -2.57117078e-02 -1.13376952e-03\n",
            " -3.57524678e-02  6.92953393e-02  2.80844164e-03  3.58742326e-02\n",
            " -1.52722728e-02 -3.41523327e-02  1.80923212e-02  1.65400058e-02\n",
            "  1.31705785e-02 -6.36677351e-03  5.49303479e-02  8.47315975e-03\n",
            " -4.26077135e-02  2.17085406e-02 -4.89023812e-02  1.18925047e-04\n",
            "  5.16286455e-02  7.59207818e-04  1.59222856e-02 -1.61299985e-02\n",
            "  1.44981612e-02  2.19508670e-02  3.02651450e-02 -3.44151556e-02\n",
            " -4.80380319e-02 -3.71690840e-02  4.68194634e-02 -3.46219279e-02\n",
            "  4.74828237e-04 -4.34820466e-02 -1.80124827e-02 -6.44845441e-02\n",
            " -2.66967788e-02  3.63660567e-02 -3.76219191e-02 -1.64600797e-02\n",
            "  2.20249202e-02  2.16018161e-04  3.64510342e-02 -2.76135597e-02\n",
            " -5.87059325e-03  6.97317207e-03 -1.25864451e-03  2.12773588e-02\n",
            "  6.21467736e-03 -3.57214026e-02 -5.09367175e-02  2.85553113e-02\n",
            "  6.48821816e-02  3.45731191e-02 -2.57280990e-02  4.52552829e-03\n",
            " -4.63605858e-02  3.32225636e-02  1.69977732e-03 -1.29354866e-02\n",
            " -3.03734578e-02  1.23609323e-02 -3.17942817e-04  1.66232195e-02\n",
            "  1.04892068e-02  1.71540510e-02  1.88860502e-02 -3.62256654e-02\n",
            "  4.65737022e-02  2.17129495e-02  4.97536734e-02  3.03067379e-02\n",
            "  1.59916270e-03 -6.30024523e-02 -6.34590676e-03  1.07311680e-04\n",
            " -5.56743983e-03  2.37264447e-02 -8.38231388e-03  5.38897254e-02\n",
            " -9.08976719e-02 -1.37359742e-02  1.18454266e-02  3.37265804e-03\n",
            " -2.81855222e-02  1.56337360e-03  2.22415235e-02  6.21024333e-02\n",
            " -8.68120864e-02 -4.40636184e-03 -1.63995549e-02  1.69665106e-02\n",
            " -1.34548368e-02  3.00701382e-03 -2.14617867e-02 -2.09503751e-02\n",
            " -1.39878122e-02 -1.23850219e-02  5.39979562e-02  6.03615008e-02\n",
            "  2.52982490e-02 -1.29661411e-01 -1.08081624e-01 -4.15776111e-03\n",
            " -7.20269838e-03  2.75885388e-02  4.87622209e-02 -2.95971315e-02\n",
            " -4.32554819e-02  2.75214985e-02  1.35718649e-02  3.87700349e-02\n",
            "  2.42039971e-02 -2.70842314e-02  8.59166011e-02 -1.98402517e-02\n",
            " -2.26343870e-02 -6.24927655e-02 -1.56844892e-02  4.11566496e-02\n",
            "  1.66952573e-02  7.97291473e-02 -3.24839130e-02  1.46564597e-03\n",
            " -3.27905975e-02  6.44815192e-02  2.09739301e-02 -7.56984949e-02\n",
            " -1.31795625e-03  2.24046316e-03 -6.60838466e-03 -6.84252307e-02\n",
            " -5.36860852e-03  6.55135512e-02  5.45568718e-03  1.58993062e-02\n",
            " -2.18052100e-02  2.16421345e-03  4.72959410e-03 -7.25654885e-02\n",
            " -1.59350727e-02 -1.05623119e-02  2.70786379e-02  1.93770020e-03\n",
            " -4.45122570e-02  2.89782919e-02  2.43083555e-02 -1.73885599e-02\n",
            " -3.80669311e-02 -3.06799207e-02 -3.24778147e-02 -4.33336420e-04\n",
            "  2.55846605e-02  2.70478558e-02 -1.72474902e-04 -4.93671570e-04\n",
            " -7.12094307e-02  5.69768772e-02  6.61401153e-02 -3.87267880e-02\n",
            " -1.30683789e-02  1.00663370e-02 -2.17740145e-02  1.92212630e-02\n",
            "  7.66692031e-03 -3.86652686e-02 -1.66109186e-02 -3.41467969e-02\n",
            " -1.04186218e-02  1.75906345e-02 -1.23776291e-02 -1.68434083e-02\n",
            " -2.40112878e-02  4.70195059e-03  4.88457037e-03  4.73663397e-02\n",
            "  4.34112139e-02 -8.08339287e-03 -2.48272233e-02 -1.93978008e-02\n",
            " -3.16525623e-02 -1.56418588e-02 -7.79947126e-03  1.28888143e-02\n",
            "  2.61943545e-02  3.65826674e-03  5.79228476e-02  5.43152057e-02\n",
            " -5.05587161e-02  1.78920361e-03 -2.45471038e-02 -2.47596204e-02\n",
            "  3.60354176e-03  1.94152538e-02 -4.23822962e-02 -1.86907127e-02\n",
            "  2.32946388e-02 -3.17982771e-02 -2.60645617e-02 -5.40358713e-03\n",
            " -3.82070281e-02  2.21719686e-02  1.33360550e-02  5.58054261e-02\n",
            " -3.57716866e-02 -3.54791805e-02  1.27723301e-02  6.80178180e-02\n",
            "  5.37151955e-02  2.54151542e-02 -1.16639193e-02 -1.07512558e-02\n",
            " -9.74426605e-03  7.20506487e-03  9.21904389e-03 -4.73684780e-02\n",
            " -3.89397307e-03  3.11453696e-02  3.62331942e-02 -1.65903158e-02\n",
            " -3.63394432e-02  1.95634961e-02 -2.15059184e-02 -7.04772118e-03\n",
            "  9.13179107e-03 -4.05358374e-02 -3.67075615e-02  1.16995983e-01\n",
            "  1.17913850e-01  8.00503418e-02 -1.61983352e-02 -2.00732816e-02\n",
            " -5.54061346e-02 -7.22410679e-02  2.14557331e-02 -4.46441787e-04\n",
            " -1.42903300e-02  8.35543312e-03  3.34207267e-02  1.42891230e-02\n",
            "  4.62512746e-02 -3.53420489e-02  1.68673582e-02 -2.99740909e-03\n",
            " -5.44997044e-02 -4.80719693e-02  9.47544875e-04 -6.29721654e-33\n",
            " -2.30286438e-02 -2.51127873e-02 -5.35219461e-02 -2.09470168e-02\n",
            " -6.79715350e-03 -4.64015789e-02 -4.49631456e-03  1.65114906e-02\n",
            " -1.12677775e-02  1.33013520e-02 -1.72552820e-02 -1.96653251e-02\n",
            "  5.53235505e-03  1.02775563e-02  9.47347027e-04 -2.24023033e-02\n",
            "  5.30364737e-02  7.77775282e-03 -9.48472135e-03  2.25515962e-02\n",
            " -4.34492249e-03  2.25208588e-02  1.98086351e-02 -7.57428780e-02\n",
            " -4.36679320e-03  2.50829607e-02  2.59393342e-02 -3.07076629e-02\n",
            "  7.04764798e-02  8.63500610e-02 -7.75880441e-02  1.59991737e-02\n",
            " -5.04692160e-02  4.88355123e-02  3.74994357e-03 -6.12926262e-04\n",
            " -3.87277529e-02 -2.32235566e-02 -3.63983363e-02 -5.07025793e-03\n",
            "  1.10517936e-02 -3.26515622e-02  3.68387289e-02 -4.54949550e-02\n",
            " -1.18533219e-03  1.92691654e-03  2.18783766e-02  2.71093231e-02\n",
            " -4.06263769e-02  6.99159801e-02 -7.33281747e-02 -8.15294031e-03\n",
            " -1.42555702e-02  3.78031377e-03  1.20974272e-01 -6.68213442e-02\n",
            "  3.05051822e-02  1.24480631e-02 -4.59294505e-02  1.03872959e-02\n",
            " -3.97978090e-02 -1.33042084e-02 -1.59402210e-02 -4.29347157e-02\n",
            "  4.05275300e-02  7.07073957e-02 -4.50929552e-02 -3.62473391e-02\n",
            " -1.87588837e-02  1.60928089e-02  2.12657340e-02  6.70026019e-02\n",
            "  3.25864665e-02  1.51126049e-02  3.20371911e-02 -1.35436021e-02\n",
            "  2.31780857e-02 -1.13125425e-02  1.23796072e-02 -3.73517126e-02\n",
            "  1.55541906e-03  2.15824191e-02 -3.49441990e-02 -2.97690462e-02\n",
            "  2.32397765e-02 -1.25702573e-02 -1.09432777e-02 -8.87969136e-02\n",
            " -2.20183823e-02 -1.18423002e-02 -5.71083613e-02  3.91809531e-02\n",
            " -1.98827442e-02 -5.59270680e-02  7.60347676e-03  2.23641749e-02\n",
            " -1.86266955e-02  3.79805490e-02 -8.79606989e-04 -5.26199415e-02\n",
            "  2.05063773e-03  1.72815304e-02 -4.84029129e-02 -1.87740661e-02\n",
            "  9.82840191e-08  2.06594896e-02  3.03574465e-02  5.71858697e-03\n",
            " -5.33938445e-02 -2.46520881e-02  1.80341452e-02 -3.39978226e-02\n",
            "  3.46393754e-05 -6.40035272e-02  2.50049569e-02 -2.04112139e-02\n",
            " -2.72042444e-03 -3.55961472e-02  2.71922927e-02  6.48940429e-02\n",
            "  9.83456615e-04 -4.38491069e-02 -4.45296802e-02 -7.44884461e-03\n",
            "  1.15205320e-02 -2.91253487e-03 -2.15495229e-02  2.84248521e-03\n",
            "  4.29399312e-02 -6.09040521e-02 -7.86324218e-03 -3.90127441e-03\n",
            "  2.47718305e-07  7.75856082e-04  7.47736692e-02  1.99314253e-03\n",
            " -6.07223576e-03  3.69210541e-02  2.78421156e-02 -5.64900488e-02\n",
            "  1.61058959e-02 -9.50820278e-03 -2.60852836e-03 -2.45737787e-02\n",
            "  1.91390626e-02  5.08196205e-02  2.61258874e-02 -1.03838064e-01\n",
            " -3.05815972e-02 -3.53344530e-02 -4.07037176e-02 -2.19842251e-02\n",
            " -2.24092342e-02  5.05567938e-02  7.22607300e-02  5.54789566e-02\n",
            "  4.89434302e-02  3.37951025e-03 -6.84760213e-02  7.10320845e-03\n",
            "  3.15669365e-03  4.78091463e-02 -7.19796121e-02 -3.30301449e-02\n",
            "  3.19159552e-02  1.76428293e-03 -4.62790541e-02 -1.96379647e-02\n",
            "  1.67493951e-02  4.73603792e-02 -2.09441260e-02  7.10241217e-03\n",
            "  4.53146249e-02 -4.76523489e-02 -4.74880971e-02  1.00799482e-02\n",
            " -8.39594901e-02  3.36930044e-02 -3.72189730e-02  1.19432351e-02\n",
            " -3.16896439e-02 -1.29722897e-03 -1.55541347e-02  1.81728359e-02\n",
            " -1.49368802e-02 -1.70671400e-02 -4.19716462e-02  3.94657440e-03\n",
            " -2.24301796e-02  2.07292121e-02 -4.61415462e-02  8.50215554e-03\n",
            " -2.56865062e-02 -1.65337883e-02 -1.51847014e-02 -1.00041814e-02\n",
            "  2.19642632e-02  2.61104126e-02  7.31358975e-02 -1.83709357e-02\n",
            "  1.93979458e-34 -7.27937045e-03  5.96489012e-03  4.44310978e-02\n",
            "  4.14822884e-02  1.12917265e-02 -1.93217676e-02  4.41878550e-02\n",
            " -8.93788971e-03  3.61120105e-02 -5.52126244e-02 -2.89572217e-02]\n",
            "Embedding size: (768,)\n"
          ]
        }
      ],
      "source": [
        "single_sentence = \"Yo! How cool are embeddings?\"\n",
        "single_embedding = embedding_model.encode(single_sentence)\n",
        "print(f\"Sentence: {single_sentence}\")\n",
        "print(f\"Embedding:\\n{single_embedding}\")\n",
        "print(f\"Embedding size: {single_embedding.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e9PtXCyl065"
      },
      "source": [
        "Nice! We've now got a way to numerically represent each of our chunks.\n",
        "\n",
        "Our embedding has a shape of `(768,)` meaning it's a vector of 768 numbers which represent our text in high-dimensional space, too many for a human to comprehend but machines love high-dimensional space.\n",
        "\n",
        "> **Note:** No matter the size of the text input to our `all-mpnet-base-v2` model, it will be turned into an embedding size of `(768,)`. This value is fixed. So whether a sentence is 1 token long or 1000 tokens long, it will be truncated/padded with zeros to size 384 and then turned into an embedding vector of size `(768,)`. Of course, other embedding models may have different input/output shapes.\n",
        "\n",
        "How about we add an embedding field to each of our chunk items?\n",
        "\n",
        "Let's start by trying to create embeddings on the CPU, we'll time it with the `%%time` magic to see how long it takes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "QrRM1RZal065",
        "outputId": "f02ab3fd-e9f3-4312-ca1c-76b10bc5cc60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 0 ns\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Uncomment to see how long it takes to create embeddings on CPU\n",
        "# # Make sure the model is on the CPU\n",
        "# embedding_model.to(\"cpu\")\n",
        "\n",
        "# # Embed each chunk one by one\n",
        "# for item in tqdm(pages_and_chunks_over_min_token_len):\n",
        "#     item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQCsBIyol065"
      },
      "source": [
        "Ok not too bad... but this would take a *really* long time if we had a larger dataset.\n",
        "\n",
        "Now let's see how long it takes to create the embeddings with a GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "93f0fc4be888494193dc535a676cc431"
          ]
        },
        "id": "xgBA-lF1l065",
        "outputId": "8ed1728c-b294-4326-dd1a-a2dc7258c2ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 153/153 [00:03<00:00, 47.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 2.55 s\n",
            "Wall time: 3.24 s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Send the model to the GPU\n",
        "embedding_model.to(\"cuda\") # requires a GPU installed, for reference on my local machine, I'm using a NVIDIA RTX 4090\n",
        "\n",
        "# Create embeddings one by one on the GPU\n",
        "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
        "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlVYxBp0l066"
      },
      "source": [
        "Woah! Looks like the embeddings get created much faster (~10x faster on my machine) on the GPU!\n",
        "\n",
        "You'll likely notice this trend with many of your deep learning workflows. If you have access to a GPU, especially a NVIDIA GPU, you should use one if you can.\n",
        "\n",
        "But what if I told you we could go faster again?\n",
        "\n",
        "You see many modern models can handle batched predictions.\n",
        "\n",
        "This means computing on multiple samples at once.\n",
        "\n",
        "Those are the types of operations where a GPU flourishes!\n",
        "\n",
        "We can perform batched operations by turning our target text samples into a single list and then passing that list to our embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "LlNOpG-Ql066"
      },
      "outputs": [],
      "source": [
        "# Turn text chunks into a single list\n",
        "text_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks_over_min_token_len]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "cDaRZCr-l066",
        "outputId": "b388751f-42ea-4cb1-8a39-2133cffcd4be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 1.81 s\n",
            "Wall time: 2.45 s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0517, -0.0614, -0.0064,  ...,  0.0016, -0.0516, -0.0042],\n",
              "        [ 0.0596, -0.0115,  0.0141,  ...,  0.0185, -0.0993, -0.0270],\n",
              "        [ 0.0313, -0.0700, -0.0032,  ..., -0.0036, -0.0814, -0.0005],\n",
              "        ...,\n",
              "        [ 0.0146,  0.0670, -0.0453,  ..., -0.0257, -0.0356, -0.0279],\n",
              "        [ 0.0307,  0.0011, -0.0245,  ...,  0.0015, -0.0035,  0.0069],\n",
              "        [-0.0733,  0.0374, -0.0053,  ...,  0.0104, -0.0782, -0.0013]],\n",
              "       device='cuda:0')"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Embed all texts in batches\n",
        "text_chunk_embeddings = embedding_model.encode(text_chunks,\n",
        "                                               batch_size=32, # you can use different batch sizes here for speed/performance, I found 32 works well for this use case\n",
        "                                               convert_to_tensor=True) # optional to return embeddings as tensor instead of array\n",
        "\n",
        "text_chunk_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U8Xdk49l066"
      },
      "source": [
        "That's what I'm talking about!\n",
        "\n",
        "A ~4x improvement (on my GPU) in speed thanks to batched operations.\n",
        "\n",
        "So the tip here is to use a GPU when you can and use batched operations if you can too.\n",
        "\n",
        "Now let's save our chunks and their embeddings so we could import them later if we wanted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zulo_C8l066"
      },
      "source": [
        "### Save embeddings to file\n",
        "\n",
        "Since creating embeddings can be a timely process (not so much for our case but it can be for more larger datasets), let's turn our `pages_and_chunks_over_min_token_len` list of dictionaries into a DataFrame and save it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "_afqLY-El066"
      },
      "outputs": [],
      "source": [
        "# Save embeddings to file\n",
        "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
        "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
        "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k80jmZbdl066"
      },
      "source": [
        "And we can make sure it imports nicely by loading it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "I35ImH-5l066",
        "outputId": "9efa8a19-4bcc-4bfa-8aa6-21d23eeba299"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_number</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>sentence_chunk</th>\n",
              "      <th>chunk_char_count</th>\n",
              "      <th>chunk_word_count</th>\n",
              "      <th>chunk_token_count</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
              "      <td>Hilti Malaysia Sdn. Bhd. (157721-A) F-5-A | Si...</td>\n",
              "      <td>1420</td>\n",
              "      <td>253</td>\n",
              "      <td>355.00</td>\n",
              "      <td>[ 5.16788028e-02 -6.13528527e-02 -6.39902987e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
              "      <td>1.3  These conditions shall prevail unless exp...</td>\n",
              "      <td>794</td>\n",
              "      <td>131</td>\n",
              "      <td>198.50</td>\n",
              "      <td>[ 5.96073382e-02 -1.15058096e-02  1.41467396e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
              "      <td>Hilti Malaysia Sdn. Bhd. (157721-A) F-5-A | Si...</td>\n",
              "      <td>1296</td>\n",
              "      <td>230</td>\n",
              "      <td>324.00</td>\n",
              "      <td>[ 3.12790014e-02 -6.99829012e-02 -3.16991261e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
              "      <td>The Buyer shall be liable for all and any loca...</td>\n",
              "      <td>1223</td>\n",
              "      <td>228</td>\n",
              "      <td>305.75</td>\n",
              "      <td>[ 6.02481961e-02 -9.50166658e-02  2.21734419e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
              "      <td>3.3  In all other cases the price of the Goods...</td>\n",
              "      <td>187</td>\n",
              "      <td>36</td>\n",
              "      <td>46.75</td>\n",
              "      <td>[ 1.29733114e-02 -7.87319392e-02 -8.07073154e-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   page_number                                        pdf_name  \\\n",
              "0            1  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
              "1            1  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
              "2            2  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
              "3            2  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
              "4            2  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
              "\n",
              "                                      sentence_chunk  chunk_char_count  \\\n",
              "0  Hilti Malaysia Sdn. Bhd. (157721-A) F-5-A | Si...              1420   \n",
              "1  1.3  These conditions shall prevail unless exp...               794   \n",
              "2  Hilti Malaysia Sdn. Bhd. (157721-A) F-5-A | Si...              1296   \n",
              "3  The Buyer shall be liable for all and any loca...              1223   \n",
              "4  3.3  In all other cases the price of the Goods...               187   \n",
              "\n",
              "   chunk_word_count  chunk_token_count  \\\n",
              "0               253             355.00   \n",
              "1               131             198.50   \n",
              "2               230             324.00   \n",
              "3               228             305.75   \n",
              "4                36              46.75   \n",
              "\n",
              "                                           embedding  \n",
              "0  [ 5.16788028e-02 -6.13528527e-02 -6.39902987e-...  \n",
              "1  [ 5.96073382e-02 -1.15058096e-02  1.41467396e-...  \n",
              "2  [ 3.12790014e-02 -6.99829012e-02 -3.16991261e-...  \n",
              "3  [ 6.02481961e-02 -9.50166658e-02  2.21734419e-...  \n",
              "4  [ 1.29733114e-02 -7.87319392e-02 -8.07073154e-...  "
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import saved file and view\n",
        "text_chunks_and_embedding_df_load = pd.read_csv(embeddings_df_save_path)\n",
        "text_chunks_and_embedding_df_load.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpksJFHgl067"
      },
      "source": [
        "## 2. RAG - Search and Answer\n",
        "\n",
        "We discussed RAG briefly in the beginning but let's quickly recap.\n",
        "\n",
        "RAG stands for Retrieval Augmented Generation.\n",
        "\n",
        "Which is another way of saying \"given a query, search for relevant resources and answer based on those resources\".\n",
        "\n",
        "Let's breakdown each step:\n",
        "* **Retrieval** - Get relevant resources given a query. For example, if the query is \"what are the macronutrients?\" the ideal results will contain information about protein, carbohydrates and fats (and possibly alcohol) rather than information about which tractors are the best for farming (though that is also cool information).\n",
        "* **Augmentation** - LLMs are capable of generating text given a prompt. However, this generated text is designed to *look* right. And it often has some correct information, however, they are prone to hallucination (generating a result that *looks* like legit text but is factually wrong). In augmentation, we pass relevant information into the prompt and get an LLM to use that relevant information as the basis of its generation.\n",
        "* **Generation** - This is where the LLM will generate a response that has been flavoured/augmented with the retrieved resources. In turn, this not only gives us a potentially more correct answer, it also gives us resources to investigate more (since we know which resources went into the prompt).\n",
        "\n",
        "The whole idea of RAG is to get an LLM to be more factually correct based on your own input as well as have a reference to where the generated output may have come from.\n",
        "\n",
        "This is an incredibly helpful tool.\n",
        "\n",
        "Let's say you had 1000s of customer support documents.\n",
        "\n",
        "You could use RAG to generate direct answers to questions with links to relevant documentation.\n",
        "\n",
        "Or you were an insurance company with large chains of claims emails.\n",
        "\n",
        "You could use RAG to answer questions about the emails with sources.\n",
        "\n",
        "One helpful analogy is to think of LLMs as calculators for words.\n",
        "\n",
        "With good inputs, the LLM can sort them into helpful outputs.\n",
        "\n",
        "How?\n",
        "\n",
        "It starts with better search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXx2x6Sul067"
      },
      "source": [
        "### Similarity search\n",
        "\n",
        "Similarity search or semantic search or vector search is the idea of searching on *vibe*.\n",
        "\n",
        "If this sounds like woo, woo. It's not.\n",
        "\n",
        "Perhaps searching via *meaning* is a better analogy.\n",
        "\n",
        "With keyword search, you are trying to match the string \"apple\" with the string \"apple\".\n",
        "\n",
        "Whereas with similarity/semantic search, you may want to search \"macronutrients functions\".\n",
        "\n",
        "And get back results that don't necessarily contain the words \"macronutrients functions\" but get back pieces of text that match that meaning.\n",
        "\n",
        "> **Example:** Using similarity search on our textbook data with the query \"macronutrients function\" returns a paragraph that starts with:\n",
        ">\n",
        ">*There are three classes of macronutrients: carbohydrates, lipids, and proteins. These can be metabolically processed into cellular energy. The energy from macronutrients comes from their chemical bonds. This chemical energy is converted into cellular energy that is then utilized to perform work, allowing our bodies to conduct their basic functions.*\n",
        ">\n",
        "> as the first result. How cool!\n",
        "\n",
        "If you've ever used Google, you know this kind of workflow.\n",
        "\n",
        "But now we'd like to perform that across our own data.\n",
        "\n",
        "Let's import our embeddings we created earlier (tk -link to embedding file) and prepare them for use by turning them into a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "2Yy0Pg3gl067",
        "outputId": "262d4680-a5e2-4e57-8443-aa74ffa12b3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([153, 768])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Import texts and embedding df\n",
        "text_chunks_and_embedding_df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
        "\n",
        "# Convert embedding column back to np.array (it got converted to string when it got saved to CSV)\n",
        "text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
        "\n",
        "# Convert texts and embedding df to list of dicts\n",
        "pages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")\n",
        "\n",
        "# Convert embeddings to torch tensor and send to device (note: NumPy arrays are float64, torch tensors are float32 by default)\n",
        "embeddings = torch.tensor(np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()), dtype=torch.float32).to(device)\n",
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "bxIEBi69l067",
        "outputId": "afc5648b-ddf4-432a-c639-ceeb3950d941"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_number</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>sentence_chunk</th>\n",
              "      <th>chunk_char_count</th>\n",
              "      <th>chunk_word_count</th>\n",
              "      <th>chunk_token_count</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
              "      <td>Hilti Malaysia Sdn. Bhd. (157721-A) F-5-A | Si...</td>\n",
              "      <td>1420</td>\n",
              "      <td>253</td>\n",
              "      <td>355.00</td>\n",
              "      <td>[0.0516788028, -0.0613528527, -0.00639902987, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
              "      <td>1.3  These conditions shall prevail unless exp...</td>\n",
              "      <td>794</td>\n",
              "      <td>131</td>\n",
              "      <td>198.50</td>\n",
              "      <td>[0.0596073382, -0.0115058096, 0.0141467396, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
              "      <td>Hilti Malaysia Sdn. Bhd. (157721-A) F-5-A | Si...</td>\n",
              "      <td>1296</td>\n",
              "      <td>230</td>\n",
              "      <td>324.00</td>\n",
              "      <td>[0.0312790014, -0.0699829012, -0.00316991261, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
              "      <td>The Buyer shall be liable for all and any loca...</td>\n",
              "      <td>1223</td>\n",
              "      <td>228</td>\n",
              "      <td>305.75</td>\n",
              "      <td>[0.0602481961, -0.0950166658, 0.0221734419, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
              "      <td>3.3  In all other cases the price of the Goods...</td>\n",
              "      <td>187</td>\n",
              "      <td>36</td>\n",
              "      <td>46.75</td>\n",
              "      <td>[0.0129733114, -0.0787319392, -0.00807073154, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   page_number                                        pdf_name  \\\n",
              "0            1  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
              "1            1  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
              "2            2  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
              "3            2  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
              "4            2  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
              "\n",
              "                                      sentence_chunk  chunk_char_count  \\\n",
              "0  Hilti Malaysia Sdn. Bhd. (157721-A) F-5-A | Si...              1420   \n",
              "1  1.3  These conditions shall prevail unless exp...               794   \n",
              "2  Hilti Malaysia Sdn. Bhd. (157721-A) F-5-A | Si...              1296   \n",
              "3  The Buyer shall be liable for all and any loca...              1223   \n",
              "4  3.3  In all other cases the price of the Goods...               187   \n",
              "\n",
              "   chunk_word_count  chunk_token_count  \\\n",
              "0               253             355.00   \n",
              "1               131             198.50   \n",
              "2               230             324.00   \n",
              "3               228             305.75   \n",
              "4                36              46.75   \n",
              "\n",
              "                                           embedding  \n",
              "0  [0.0516788028, -0.0613528527, -0.00639902987, ...  \n",
              "1  [0.0596073382, -0.0115058096, 0.0141467396, -0...  \n",
              "2  [0.0312790014, -0.0699829012, -0.00316991261, ...  \n",
              "3  [0.0602481961, -0.0950166658, 0.0221734419, 0....  \n",
              "4  [0.0129733114, -0.0787319392, -0.00807073154, ...  "
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_chunks_and_embedding_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaPjacwRl067"
      },
      "source": [
        "Nice!\n",
        "\n",
        "Now let's prepare another instance of our embedding model. Not because we have to but because we'd like to make it so you can start the notebook from the cell above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "TX5ueeAjl068"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import util, SentenceTransformer\n",
        "\n",
        "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",\n",
        "                                      device=device) # choose the device to load the model to"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pEejPWdl068"
      },
      "source": [
        "Embedding model ready!\n",
        "\n",
        "Time to perform a semantic search.\n",
        "\n",
        "Let's say you were studying the macronutrients.\n",
        "\n",
        "And wanted to search your textbook for \"macronutrients functions\".\n",
        "\n",
        "Well, we can do so with the following steps:\n",
        "1. Define a query string (e.g. `\"macronutrients functions\"`) - note: this could be anything, specific or not.\n",
        "2. Turn the query string in an embedding with same model we used to embed our text chunks.\n",
        "3. Perform a [dot product](https://pytorch.org/docs/stable/generated/torch.dot.html) or [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) function between the text embeddings and the query embedding (we'll get to what these are shortly) to get similarity scores.\n",
        "4. Sort the results from step 3 in descending order (a higher score means more similarity in the eyes of the model) and use these values to inspect the texts.\n",
        "\n",
        "Easy!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhQEO3prl068"
      },
      "source": [
        "Woah!! Now that was fast!\n",
        "\n",
        "~0.00008 seconds to perform a dot product comparison across 1680 embeddings on my machine (NVIDIA RTX 4090 GPU).\n",
        "\n",
        "GPUs are optimized for these kinds of operations.\n",
        "\n",
        "So even if you we're to increase our embeddings by 100x (1680 -> 168,000), an exhaustive dot product operation would happen in ~0.008 seconds (assuming linear scaling).\n",
        "\n",
        "Heck, let's try it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we9I-8-Al068"
      },
      "source": [
        "Wow. That's quick!\n",
        "\n",
        "That means we can get pretty far by just storing our embeddings in `torch.tensor` for now.\n",
        "\n",
        "However, for *much* larger datasets, we'd likely look at a dedicated vector database/indexing libraries such as [Faiss](https://github.com/facebookresearch/faiss).\n",
        "\n",
        "Let's check the results of our original similarity search.\n",
        "\n",
        "[`torch.topk`](https://pytorch.org/docs/stable/generated/torch.topk.html) returns a tuple of values (scores) and indicies for those scores.\n",
        "\n",
        "The indicies relate to which indicies in the `embeddings` tensor have what scores in relation to the query embedding (higher is better).\n",
        "\n",
        "We can use those indicies to map back to our text chunks.\n",
        "\n",
        "First, we'll define a small helper function to print out wrapped text (so it doesn't print a whole text chunk as a single line)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "gXrIPk0rl068"
      },
      "outputs": [],
      "source": [
        "# Define helper function to print wrapped text\n",
        "import textwrap\n",
        "\n",
        "def print_wrapped(text, wrap_length=80):\n",
        "    wrapped_text = textwrap.fill(text, wrap_length)\n",
        "    print(wrapped_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIuczigYl068"
      },
      "source": [
        "Now we can loop through the `top_results_dot_product` tuple and match up the scores and indicies and then use those indicies to index on our `pages_and_chunks` variable to get the relevant text chunk.\n",
        "\n",
        "Sounds like a lot but we can do it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reqnCTpMl069"
      },
      "source": [
        "The first result looks to have nailed it!\n",
        "\n",
        "We get a very relevant answer to our query `\"macronutrients functions\"` even though its quite vague.\n",
        "\n",
        "That's the power of semantic search!\n",
        "\n",
        "And even better, if we wanted to inspect the result further, we get the page number where the text appears.\n",
        "\n",
        "How about we check the page to verify?\n",
        "\n",
        "We can do so by loading the page number containing the highest result (page 5 but really page 5 + 41 since our PDF page numbers start on page 41)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrZohOTEl069"
      },
      "source": [
        "Nice!\n",
        "\n",
        "Now we can do extra research if we'd like.\n",
        "\n",
        "We could repeat this workflow for any kind of query we'd like on our textbook.\n",
        "\n",
        "And it would also work for other datatypes too.\n",
        "\n",
        "We could use semantic search on customer support documents.\n",
        "\n",
        "Or email threads.\n",
        "\n",
        "Or company plans.\n",
        "\n",
        "Or our old journal entries.\n",
        "\n",
        "Almost anything!\n",
        "\n",
        "The workflow is the same:\n",
        "\n",
        "`ingest documents -> split into chunks -> embed chunks -> make a query -> embed the query -> compare query embedding to chunk embeddings`\n",
        "\n",
        "And we get relevant resources *along with* the source they came from!\n",
        "\n",
        "That's the **retrieval** part of Retrieval Augmented Generation (RAG).\n",
        "\n",
        "Before we get to the next two steps, let's take a small aside and discuss similarity measures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjRxBCBAl069"
      },
      "source": [
        "### Similarity measures: dot product and cosine similarity\n",
        "\n",
        "Let's talk similarity measures between vectors.\n",
        "\n",
        "Specifically, embedding vectors which are representations of data with magnitude and direction in high dimensional space (our embedding vectors have 768 dimensions).\n",
        "\n",
        "Two of the most common you'll across are the dot product and cosine similarity.\n",
        "\n",
        "They are quite similar.\n",
        "\n",
        "The main difference is that cosine similarity has a normalization step.\n",
        "\n",
        "| Similarity measure | Description | Code |\n",
        "| ----- | ----- | ----- |\n",
        "| [Dot Product](https://en.wikipedia.org/wiki/Dot_product) | - Measure of magnitude and direction between two vectors<br>- Vectors that are aligned in direction and magnitude have a higher positive value<br>- Vectors that are opposite in direction and magnitude have a higher negative value | [`torch.dot`](https://pytorch.org/docs/stable/generated/torch.dot.html), [`np.dot`](https://numpy.org/doc/stable/reference/generated/numpy.dot.html), [`sentence_transformers.util.dot_score`](https://www.sbert.net/docs/package_reference/util.html#sentence_transformers.util.dot_score) |\n",
        "| [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) | - Vectors get normalized by magnitude/[Euclidean norm](https://en.wikipedia.org/wiki/Norm_(mathematics))/L2 norm so they have unit length and are compared more so on direction<br>- Vectors that are aligned in direction have a value close to 1<br>- Vectors that are opposite in direction have a value close to -1 | [`torch.nn.functional.cosine_similarity`](https://pytorch.org/docs/stable/generated/torch.nn.functional.cosine_similarity.html), [`1 - scipy.spatial.distance.cosine`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html) (subtract the distance from 1 for similarity measure), [`sentence_transformers.util.cos_sim`](https://www.sbert.net/docs/package_reference/util.html#sentence_transformers.util.cos_sim) |\n",
        "\n",
        "For text similarity, you generally want to use cosine similarity as you are after the semantic measurements (direction) rather than magnitude.\n",
        "\n",
        "In our case, our embedding model `all-mpnet-base-v2` outputs normalized outputs (see the [Hugging Face model card](https://huggingface.co/sentence-transformers/all-mpnet-base-v2#usage-huggingface-transformers) for more on this) so dot product and cosine similarity return the same results. However, dot product is faster due to not need to perform a normalize step.\n",
        "\n",
        "To make things bit more concrete, let's make simple dot product and cosine similarity functions and view their results on different vectors.\n",
        "\n",
        "> **Note:** Similarity measures between vectors and embeddings can be used on any kind of embeddings, not just text embeddings. For example, you could measure image embedding similarity or audio embedding similarity. Or with text and image models like [CLIP](https://github.com/mlfoundations/open_clip), you can measure the similarity between text and image embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "f-bDNw8fl069",
        "outputId": "88cdd01d-e272-4bef-ad74-0c459d4662e7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def dot_product(vector1, vector2):\n",
        "    return torch.dot(vector1, vector2)\n",
        "\n",
        "def cosine_similarity(vector1, vector2):\n",
        "    dot_product = torch.dot(vector1, vector2)\n",
        "\n",
        "    # Get Euclidean/L2 norm of each vector (removes the magnitude, keeps direction)\n",
        "    norm_vector1 = torch.sqrt(torch.sum(vector1**2))\n",
        "    norm_vector2 = torch.sqrt(torch.sum(vector2**2))\n",
        "\n",
        "    return dot_product / (norm_vector1 * norm_vector2)\n",
        "\n",
        "# Example tensors\n",
        "#vector1 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
        "#vector2 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
        "#vector3 = torch.tensor([4, 5, 6], dtype=torch.float32)\n",
        "#vector4 = torch.tensor([-1, -2, -3], dtype=torch.float32)\n",
        "#\n",
        "## Calculate dot product\n",
        "#print(\"Dot product between vector1 and vector2:\", dot_product(vector1, vector2))\n",
        "#print(\"Dot product between vector1 and vector3:\", dot_product(vector1, vector3))\n",
        "#print(\"Dot product between vector1 and vector4:\", dot_product(vector1, vector4))\n",
        "#\n",
        "## Calculate cosine similarity\n",
        "#print(\"Cosine similarity between vector1 and vector2:\", cosine_similarity(vector1, vector2))\n",
        "#print(\"Cosine similarity between vector1 and vector3:\", cosine_similarity(vector1, vector3))\n",
        "#print(\"Cosine similarity between vector1 and vector4:\", cosine_similarity(vector1, vector4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiaOufr0l069"
      },
      "source": [
        "Notice for both dot product and cosine similarity the comparisons of `vector1` and `vector2` are the opposite of `vector1` and `vector4`.\n",
        "\n",
        "Comparing `vector1` and `vector2` both equations return positive values (14 for dot product and 1.0 for cosine similarity).\n",
        "\n",
        "But comparing `vector1` and `vector4` the result is in the negative direction.\n",
        "\n",
        "This makes sense because `vector4` is the negative version of `vector1`.\n",
        "\n",
        "Whereas comparing `vector1` and `vector3` shows a different outcome.\n",
        "\n",
        "For the dot product, the value is positive and larger then the comparison of two exactly the same vectors (32 vs 14).\n",
        "\n",
        "However, for the cosine similarity, thanks to the normalization step, comparing `vector1` and `vector3` results in a postive value close to 1 but not exactly 1.\n",
        "\n",
        "It is because of this that when comparing text embeddings, cosine similarity is generally favoured as it measures the difference in direction of a pair of vectors rather than difference in magnitude.\n",
        "\n",
        "And it is this difference in direction that is more generally considered to capture the semantic meaning/vibe of the text.\n",
        "\n",
        "The good news is that as mentioned before, the outputs of our embedding model `all-mpnet-base-v2` are already normalized.\n",
        "\n",
        "So we can continue using the dot product (cosine similarity is dot product + normalization).\n",
        "\n",
        "With similarity measures explained, let's functionize our semantic search steps from above so we can repeat them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR2PU5NKl069"
      },
      "source": [
        "### Functionizing our semantic search pipeline\n",
        "\n",
        "Let's put all of the steps from above for semantic search into a function or two so we can repeat the workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Se7N8Qztl069"
      },
      "outputs": [],
      "source": [
        "def retrieve_relevant_resources(query: str,\n",
        "                                embeddings: torch.tensor,\n",
        "                                model: SentenceTransformer=embedding_model,\n",
        "                                n_resources_to_return: int=5,\n",
        "                                print_time: bool=True):\n",
        "    \"\"\"\n",
        "    Embeds a query with model and returns top k scores and indices from embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    # Embed the query\n",
        "    query_embedding = model.encode(query,\n",
        "                                   convert_to_tensor=True)\n",
        "\n",
        "    # Get dot product scores on embeddings\n",
        "    start_time = timer()\n",
        "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
        "    end_time = timer()\n",
        "\n",
        "    if print_time:\n",
        "        print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
        "\n",
        "    scores, indices = torch.topk(input=dot_scores,\n",
        "                                 k=n_resources_to_return)\n",
        "\n",
        "    return scores, indices\n",
        "\n",
        "def print_top_results_and_scores(query: str,\n",
        "                                 embeddings: torch.tensor,\n",
        "                                 pages_and_chunks: list[dict]=pages_and_chunks,\n",
        "                                 n_resources_to_return: int=5):\n",
        "    \"\"\"\n",
        "    Takes a query, retrieves most relevant resources and prints them out in descending order.\n",
        "\n",
        "    Note: Requires pages_and_chunks to be formatted in a specific way (see above for reference).\n",
        "    \"\"\"\n",
        "\n",
        "    scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                                  embeddings=embeddings,\n",
        "                                                  n_resources_to_return=n_resources_to_return)\n",
        "\n",
        "    print(f\"Query: {query}\\n\")\n",
        "    print(\"Results:\")\n",
        "    # Loop through zipped together scores and indicies\n",
        "    for score, index in zip(scores, indices):\n",
        "        print(f\"Score: {score:.4f}\")\n",
        "        # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
        "        print_wrapped(pages_and_chunks[index][\"sentence_chunk\"])\n",
        "        # Print the page number too so we can reference the textbook further and check the results\n",
        "        print(f\"Page number: {pages_and_chunks[index]['page_number']}\")\n",
        "        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCoT3diOl069"
      },
      "source": [
        "Excellent! Now let's test our functions out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "Z1cQZ99el069",
        "outputId": "2d209b2d-2e85-4a74-894c-7de0001261ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Time taken to get scores on 153 embeddings: 0.00051 seconds.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([0.0741, 0.0658, 0.0416, 0.0398, 0.0396], device='cuda:0'),\n",
              " tensor([148,  35,   3, 147, 140], device='cuda:0'))"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"symptoms of pellagra\"\n",
        "from time import perf_counter as timer\n",
        "\n",
        "# Get just the scores and indices of top related results\n",
        "scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                              embeddings=embeddings)\n",
        "scores, indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "uMBdvMSQl06-",
        "outputId": "6eec0061-1f57-43a2-f467-916223320b00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Time taken to get scores on 153 embeddings: 0.00006 seconds.\n",
            "Query: symptoms of pellagra\n",
            "\n",
            "Results:\n",
            "Score: 0.0741\n",
            "CONSOLIDATED STATEMENT OF COMPREHENSIVE INCOME OF HILTI GROUP CONSOLIDATED\n",
            "INCOME STATEMENT OF HILTI GROUP Please note The notes to the consolidated\n",
            "financial statements are an integral part of, and should be read in conjunction\n",
            "with, the consolidated balance sheet, the consolidated income statement, the\n",
            "consolidated statement of comprehensive income and the consolidated cash flow\n",
            "statement.in CHF million 2020 2019 Net sales 5,332.2 5,899.9 Other operating\n",
            "revenues 149.4 154.9 TOTAL OPERATING REVENUES 5,481.6 6,054.8 Change in\n",
            "inventory (29.0) (25.4) Material costs (1,416.2) (1,623.0) Personnel expenses\n",
            "(2,282.4) (2,452.8) Depreciation and amortization (394.9) (374.0) Losses on\n",
            "trade and other receivables (51.7) (51.9) Other operating expenses (579.2)\n",
            "(745.1) TOTAL OPERATING EXPENSES (4,753.4) (5,272.2) OPERATING RESULT 728.2\n",
            "782.6 Other revenues and expenses (net) (28.9) (13.5) Finance costs (47.7)\n",
            "(53.3) NET INCOME BEFORE INCOME TAX EXPENSE 651.6 715.8 Income tax expense\n",
            "(120.9) (124.6) NET INCOME 530.7 591.2 Attributable to: Equity holders of the\n",
            "parent 529.9 588.1 Non-controlling interests 0.8 3.1 in CHF million 2020 2019\n",
            "NET INCOME 530.7 591.2 Net movement on cash flow hedges (1.7) (1.6) Deferred tax\n",
            "on net movement on cash flow hedges 0.2 0.2 Foreign currency translation\n",
            "differences (57.6) (48.1) Deferred tax on foreign currency translation\n",
            "differences 0.5 0.2 ITEMS THAT MAY BE SUBSEQUENTLY RECLASSIFIED TO THE INCOME\n",
            "STATEMENT (58.6) (49.3) Remeasurements on employee benefits 18.6 (81.7) Deferred\n",
            "tax on remeasurements on employee benefits (2.0) 13.4 ITEMS THAT WILL NEVER BE\n",
            "RECLASSIFIED TO THE INCOME STATEMENT 16.6 (68.3) OTHER COMPREHENSIVE INCOME\n",
            "(OCI) (42.0) (117.6) TOTAL COMPREHENSIVE INCOME 488.7 473.6 Attributable to:\n",
            "Equity holders of the parent 488.6 470.6 Non-controlling interests 0.1 3.0 2020\n",
            "Hilti Company Report 76–77\n",
            "Page number: 41\n",
            "\n",
            "\n",
            "Score: 0.0658\n",
            "Start vacuum.8. Verify proper operation of the dust collection system, including\n",
            "suction at the extraction head. •       Check for damage or leaks in the vacuum,\n",
            "hose, and extraction head. •   See instructions for vacuum. Drilling 1. Start\n",
            "the vacuum before beginning to drill. •  Hold the drill perpendicular to the\n",
            "work surface and keep the extraction head in contact with the work surface.\n",
            "Page number: 5\n",
            "\n",
            "\n",
            "Score: 0.0416\n",
            "The Buyer shall be liable for all and any local taxes or charges as appropriate.\n",
            "2.4  The Buyer agrees that section 39(3) of the Sale of Goods Act 1957 (Act 32)\n",
            "(“the Act”) shall not apply to Goods sent by the Company.  2.5  The Company\n",
            "shall be entitled to invoice the Buyer by post, facsimile or email for the price\n",
            "of the Goods in Ringgit Malaysia or such other currency as the Company shall\n",
            "agree in writing.  2.6  The Company has the right to invoice the Buyer for the\n",
            "cost of any packaging, transportation of the Goods or any additional costs\n",
            "resulting from any other alteration made by the Buyer on or at the time of\n",
            "delivery or upon notification by the Company that the Goods are awaiting\n",
            "collection. Any such additional costs may be invoiced by the Company in Ringgit\n",
            "Malaysia or such other currency as the Company shall agree in writing.   3. FUEL\n",
            "SURCHARGE/ CARRIAGE AND INSURANCE  3.1  The cost of fuel surcharge to the\n",
            "Buyer's premises in Malaysia shall be in accordance with the charges pre-agreed\n",
            "between the Buyer and the Company.  3.2  The cost of carriage and insurance of\n",
            "the Goods to the Buyer’s premises in Malaysia shall be in accordance with the\n",
            "charges laid out in the Company’s current price list.\n",
            "Page number: 2\n",
            "\n",
            "\n",
            "Score: 0.0398\n",
            "CONSOLIDATED BALANCE SHEET  OF HILTI GROUP AS AT 31 DECEMBER Please note The\n",
            "share capital consists of 253,440 registered shares with a par value of CHF 500\n",
            "each as well as reserves. All of the registered shares are owned by the Martin\n",
            "Hilti Family Trust. Equity and liabilities in CHF million 2020 2019 Non-\n",
            "controlling interests 7.9 6.7 Equity attributable to equity holders of the\n",
            "parent 3,464.2 3,269.6 TOTAL EQUITY 3,472.1 3,276.3 Provisions 9.5 12.5 Employee\n",
            "benefits 614.4 636.8 Deferred income tax liabilities 123.9 119.7 Bonds 449.8\n",
            "299.9 Long-term bank borrowings 43.3 54.0 Lease liabilities 330.8 332.5 Contract\n",
            "liabilities 83.2 90.6 Trade and other payables 17.8 36.2 TOTAL NON-CURRENT\n",
            "LIABILITIES 1,672.7 1,582.2 Provisions 7.6 8.4 Employee benefits 7.9 8.5 Trade\n",
            "and other payables 468.4 471.7 Current income taxes payable 107.6 116.9 Accrued\n",
            "liabilities and deferred income 437.8 461.7 Contract liabilities 108.9 108.3\n",
            "Short-term bank borrowings 142.9 226.0 Lease liabilities 113.4 116.1 Derivative\n",
            "financial instruments 6.7 3.0 TOTAL CURRENT LIABILITIES 1,401.2 1,520.6 TOTAL\n",
            "LIABILITIES 3,073.9 3,102.8 TOTAL EQUITY AND LIABILITIES 6,546.0 6,379.1 Assets\n",
            "in CHF million 2020 2019 Intangible assets 942.5 893.4 Property, plant and\n",
            "equipment 959.7 952.6 Right of use assets 423.2 435.2 Investment property 1.9\n",
            "1.9 Investments in associates and joint ventures 2.7 2.7 Deferred income tax\n",
            "assets 134.3 143.0 Other financial investments 18.5 16.6 Trade and other\n",
            "receivables 789.5 800.9 Derivative financial instruments 3.8 4.7 TOTAL NON-\n",
            "CURRENT ASSETS 3,276.1 3,251.0 Inventories 587.5 645.6 Trade and other\n",
            "receivables 1,245.7 1,249.6 Current income taxes receivable 9.6 13.6 Accrued\n",
            "income and prepayments 63.9 67.2 Derivative financial instruments 6.5 11.0\n",
            "Financial assets at fair value through profit or loss 23.8 27.3 Cash and cash\n",
            "equivalents 1,332.9 1,113.8 TOTAL CURRENT ASSETS 3,269.9 3,128.1 TOTAL ASSETS\n",
            "6,546.0 6,379.1 2020 Hilti Company Report 74–75\n",
            "Page number: 40\n",
            "\n",
            "\n",
            "Score: 0.0396\n",
            "The sales development followed three phases: a strong start in the first two and\n",
            "a half months, a lockdown-in- duced decrease until the end of May and a\n",
            "heterogeneous yet steady recovery in the second half of 2020. While the Group’s\n",
            "sales decrease was most pronounced after the first five months at 16.3 percent,\n",
            "the situ- ation improved from June onwards, resulting in a 9.6 percent full year\n",
            "sales decrease in Swiss francs and 4.3 percent in local currencies. On a\n",
            "regional level, the results differed quite substantially depending on the\n",
            "severity of the pandemic and the lock- down approaches of the local gov-\n",
            "ernments. While Central and Eastern Europe and Northern Asia managed to close\n",
            "the year with positive sales growth, Southern Asia and the Middle East faced a\n",
            "double-digit decrease. The Americas finished the year with a 4.6 percent\n",
            "decrease which was disproportionately impacted by Latin America. Significantly\n",
            "weaker curren- cies in emerging markets, as well as a weaker euro and US dollar,\n",
            "led to a negative currency impact on Group sales of over 5 percent. Reaction to\n",
            "the COVID-19 pandemic At the end of March, Hilti launched a four-pillar program\n",
            "to cope with the COVID-19 challenges. A strong emphasis was put on protecting\n",
            "the health of Hilti’s employees and par- ticularly the sales force, resulting in\n",
            "significantly less time being spent with customers and on jobsites during the\n",
            "(partial) lockdowns.\n",
            "Page number: 38\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print out the texts of the top scores\n",
        "print_top_results_and_scores(query=query,\n",
        "                             embeddings=embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading LLM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEfzFbyql06-"
      },
      "source": [
        "### Checking local GPU memory availability\n",
        "\n",
        "Let's find out what hardware we've got available and see what kind of model(s) we'll be able to load.\n",
        "\n",
        "> **Note:** You can also check this with the `!nvidia-smi` command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PzckE6hfl06-",
        "outputId": "94b3c813-6772-40d3-b988-afe63c559948"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available GPU memory: 6 GB\n"
          ]
        }
      ],
      "source": [
        "# Get GPU available memory\n",
        "import torch\n",
        "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
        "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
        "gpu_memory_gb = 6\n",
        "print(f\"Available GPU memory: {gpu_memory_gb} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TuMBhHs5l06-",
        "outputId": "93123b85-b348-4d59-ab52-49b6b4183b78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU memory: 6 | Recommended model: Gemma 2B in 4-bit precision.\n",
            "use_quantization_config set to: True\n",
            "model_id set to: google/gemma-2b-it\n"
          ]
        }
      ],
      "source": [
        "# Note: the following is Gemma focused, however, there are more and more LLMs of the 2B and 7B size appearing for local use.\n",
        "if gpu_memory_gb < 5.1:\n",
        "    print(f\"Your available GPU memory is {gpu_memory_gb}GB, you may not have enough memory to run a Gemma LLM locally without quantization.\")\n",
        "elif gpu_memory_gb < 8.1:\n",
        "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in 4-bit precision.\")\n",
        "    use_quantization_config = True\n",
        "    model_id = \"google/gemma-2b-it\"\n",
        "elif gpu_memory_gb < 19.0:\n",
        "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in float16 or Gemma 7B in 4-bit precision.\")\n",
        "    use_quantization_config = False\n",
        "    model_id = \"google/gemma-2b-it\"\n",
        "elif gpu_memory_gb > 19.0:\n",
        "    print(f\"GPU memory: {gpu_memory_gb} | Recommend model: Gemma 7B in 4-bit or float16 precision.\")\n",
        "    use_quantization_config = False\n",
        "    model_id = \"google/gemma-7b-it\"\n",
        "\n",
        "print(f\"use_quantization_config set to: {use_quantization_config}\")\n",
        "print(f\"model_id set to: {model_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRvOj0TAl06-"
      },
      "source": [
        "### Loading an LLM locally\n",
        "\n",
        "Alright! Looks like `gemma-7b-it` it is (for my local machine with an RTX 4090, change the `model_id` and `use_quantization_config` values to suit your needs)!\n",
        "\n",
        "There are plenty of examples of how to load the model on the `gemma-7b-it` [Hugging Face model card](https://huggingface.co/google/gemma-7b-it).\n",
        "\n",
        "Good news is, the Hugging Face [`transformers`](https://huggingface.co/docs/transformers/) library has all the tools we need.\n",
        "\n",
        "To load our LLM, we're going to need a few things:\n",
        "1. A quantization config (optional) - This will determine whether or not we load the model in 4bit precision for lower memory usage. The we can create this with the [`transformers.BitsAndBytesConfig`](https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/quantization#transformers.BitsAndBytesConfig) class (requires installing the [`bitsandbytes` library](https://github.com/TimDettmers/bitsandbytes)).\n",
        "2. A model ID - This is the reference Hugging Face model ID which will determine which tokenizer and model gets used. For example `gemma-7b-it`.\n",
        "3. A tokenzier - This is what will turn our raw text into tokens ready for the model. We can create it using the [`transformers.AutoTokenzier.from_pretrained`](https://huggingface.co/docs/transformers/v4.38.2/en/model_doc/auto#transformers.AutoTokenizer) method and passing it our model ID.\n",
        "4. An LLM model - Again, using our model ID we can load a specific LLM model. To do so we can use the [`transformers.AutoModelForCausalLM.from_pretrained`](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForCausalLM.from_pretrained) method and passing it our model ID as well as other various parameters.\n",
        "\n",
        "As a bonus, we'll check if [Flash Attention 2](https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2) is available using `transformers.utils.is_flash_attn_2_available()`. Flash Attention 2 speeds up the attention mechanism in Transformer architecture models (which is what many modern LLMs are based on, including Gemma). So if it's available and the model is supported (not all models support Flash Attention 2), we'll use it. If it's not available, you can install it by following the instructions on the [GitHub repo](https://github.com/Dao-AILab/flash-attention).\n",
        "\n",
        "> **Note:** Flash Attention 2 currently works on NVIDIA GPUs with a compute capability score of 8.0+ (Ampere, Ada Lovelace, Hopper architectures). We can check our GPU compute capability score with [`torch.cuda.get_device_capability(0)`](https://pytorch.org/docs/stable/generated/torch.cuda.get_device_capability.html).\n",
        "\n",
        "> **Note:** To get access to the Gemma models, you will have to [agree to the terms & conditions](https://huggingface.co/google/gemma-7b-it) on the Gemma model page on Hugging Face. You will then have to authorize your local machine via the [Hugging Face CLI/Hugging Face Hub `login()` function](https://huggingface.co/docs/huggingface_hub/en/quick-start#authentication). Once you've done this, you'll be able to download the models. If you're using Google Colab, you can add a [Hugging Face token](https://huggingface.co/docs/hub/en/security-tokens) to the \"Secrets\" tab.\n",
        ">\n",
        "> Downloading an LLM locally can take a fair bit of time depending on your internet connection. Gemma 7B is about a 16GB download and Gemma 2B is about a 6GB download.\n",
        "\n",
        "Let's do it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "60a7efc798a14a2a8c68ce3063368715"
          ]
        },
        "id": "p8dADd5Jl06-",
        "outputId": "56376a7f-cdd5-4cc3-8799-ccc1808eb4f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:32: SyntaxWarning: invalid escape sequence '\\g'\n",
            "<>:33: SyntaxWarning: invalid escape sequence '\\H'\n",
            "<>:38: SyntaxWarning: invalid escape sequence '\\g'\n",
            "<>:40: SyntaxWarning: invalid escape sequence '\\H'\n",
            "<>:32: SyntaxWarning: invalid escape sequence '\\g'\n",
            "<>:33: SyntaxWarning: invalid escape sequence '\\H'\n",
            "<>:38: SyntaxWarning: invalid escape sequence '\\g'\n",
            "<>:40: SyntaxWarning: invalid escape sequence '\\H'\n",
            "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21212\\4207301797.py:32: SyntaxWarning: invalid escape sequence '\\g'\n",
            "  tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=\"models\\gemma-2b\",\n",
            "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21212\\4207301797.py:33: SyntaxWarning: invalid escape sequence '\\H'\n",
            "  cache_dir=\"D:\\HuggingFace\",\n",
            "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21212\\4207301797.py:38: SyntaxWarning: invalid escape sequence '\\g'\n",
            "  llm_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=\"models\\gemma-2b\",\n",
            "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21212\\4207301797.py:40: SyntaxWarning: invalid escape sequence '\\H'\n",
            "  cache_dir=\"D:\\HuggingFace\",\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "[INFO] Using attention implementation: sdpa\n",
            "[INFO] Using model_id: google/gemma-2b-it\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
            "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
            "Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.24s/it]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers.utils import is_flash_attn_2_available\n",
        "\n",
        "\n",
        "# 1. Create quantization config for smaller model loading (optional)\n",
        "# Requires !pip install bitsandbytes accelerate, see: https://github.com/TimDettmers/bitsandbytes, https://huggingface.co/docs/accelerate/\n",
        "# For models that require 4-bit quantization (use this if you have low GPU memory available)\n",
        "from transformers import BitsAndBytesConfig\n",
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
        "                                         bnb_4bit_use_double_quant=True,\n",
        "                                          bnb_4bit_quant_type=\"nf4\",\n",
        "                                          bnb_4bit_compute_dtype=torch.bfloat16)\n",
        "\n",
        "# Bonus: Setup Flash Attention 2 for faster inference, default to \"sdpa\" or \"scaled dot product attention\" if it's not available\n",
        "# Flash Attention 2 requires NVIDIA GPU compute capability of 8.0 or above, see: https://developer.nvidia.com/cuda-gpus\n",
        "# Requires !pip install flash-attn, see: https://github.com/Dao-AILab/flash-attention\n",
        "print(is_flash_attn_2_available())\n",
        "if (is_flash_attn_2_available()) and (torch.cuda.get_device_capability(0)[0] >= 8):\n",
        "  attn_implementation = \"flash_attention_2\"\n",
        "else:\n",
        "  attn_implementation = \"sdpa\"\n",
        "print(f\"[INFO] Using attention implementation: {attn_implementation}\")\n",
        "\n",
        "# 2. Pick a model we'd like to use (this will depend on how much GPU memory you have available)\n",
        "#model_id = \"google/gemma-7b-it\"\n",
        "model_id = \"google/gemma-2b-it\" # (we already set this above)\n",
        "print(f\"[INFO] Using model_id: {model_id}\")\n",
        "access_token = \"put your access token here\"\n",
        "\n",
        "# 3. Instantiate tokenizer (tokenizer turns text into numbers ready for the model)\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=\"models\\gemma-2b\", \n",
        "                                          cache_dir=\"D:\\HuggingFace\", \n",
        "                                          token=access_token,\n",
        "                                          local_files_only=True)\n",
        "\n",
        "# 4. Instantiate the model\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=\"models\\gemma-2b\",\n",
        "                                               token=access_token,\n",
        "                                               cache_dir=\"D:\\HuggingFace\",\n",
        "                                               local_files_only=True,\n",
        "                                               quantization_config=quantization_config,\n",
        "                                               torch_dtype=torch.float16, # datatype to use, we want float16\n",
        "                                               low_cpu_mem_usage=True, # use full memory\n",
        "                                               attn_implementation=attn_implementation) # which attention version to use\n",
        "\n",
        "#llm_model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XbYI5y0l06-"
      },
      "source": [
        "We've got an LLM!\n",
        "\n",
        "Let's check it out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Q3x7casjl06-",
        "outputId": "9b5042d9-069e-44f8-b2f3-146657334d90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GemmaForCausalLM(\n",
              "  (model): GemmaModel(\n",
              "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0-17): 18 x GemmaDecoderLayer(\n",
              "        (self_attn): GemmaSdpaAttention(\n",
              "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "          (rotary_emb): GemmaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): GemmaMLP(\n",
              "          (gate_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=16384, out_features=2048, bias=False)\n",
              "          (act_fn): PytorchGELUTanh()\n",
              "        )\n",
              "        (input_layernorm): GemmaRMSNorm()\n",
              "        (post_attention_layernorm): GemmaRMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): GemmaRMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8ax32ICl06_"
      },
      "source": [
        "Ok, ok a bunch of layers ranging from embedding layers to attention layers (see the `GemmaFlashAttention2` layers!) to MLP and normalization layers.\n",
        "\n",
        "The good news is that we don't have to know too much about these to use the model.\n",
        "\n",
        "How about we get the number of parameters in our model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1NHSf3ZQl06_",
        "outputId": "7af7647e-5338-4ad3-a2f9-27de3c9a45a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1515268096"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_model_num_params(model: torch.nn.Module):\n",
        "    return sum([param.numel() for param in model.parameters()])\n",
        "\n",
        "get_model_num_params(llm_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFadcXdCl06_"
      },
      "source": [
        "Hmm, turns out that Gemma 7B is really Gemma 8.5B.\n",
        "\n",
        "It pays to do your own investigations!\n",
        "\n",
        "How about we get the models memory requirements?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9WcsKnMFl06_",
        "outputId": "f6cc1ae0-53a9-4ca9-aae2-764349cf5426"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model_mem_bytes': 2039641088, 'model_mem_mb': 1945.15, 'model_mem_gb': 1.9}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_model_mem_size(model: torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Get how much memory a PyTorch model takes up.\n",
        "\n",
        "    See: https://discuss.pytorch.org/t/gpu-memory-that-model-uses/56822\n",
        "    \"\"\"\n",
        "    # Get model parameters and buffer sizes\n",
        "    mem_params = sum([param.nelement() * param.element_size() for param in model.parameters()])\n",
        "    mem_buffers = sum([buf.nelement() * buf.element_size() for buf in model.buffers()])\n",
        "\n",
        "    # Calculate various model sizes\n",
        "    model_mem_bytes = mem_params + mem_buffers # in bytes\n",
        "    model_mem_mb = model_mem_bytes / (1024**2) # in megabytes\n",
        "    model_mem_gb = model_mem_bytes / (1024**3) # in gigabytes\n",
        "\n",
        "    return {\"model_mem_bytes\": model_mem_bytes,\n",
        "            \"model_mem_mb\": round(model_mem_mb, 2),\n",
        "            \"model_mem_gb\": round(model_mem_gb, 2)}\n",
        "\n",
        "get_model_mem_size(llm_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db3euU1fl06_"
      },
      "source": [
        "Nice, looks like this model takes up 15.97GB of space on the GPU.\n",
        "\n",
        "Plus a little more for the forward pass (due to all the calculations happening between the layers).\n",
        "\n",
        "Hence why I rounded it up to be ~19GB in the table above.\n",
        "\n",
        "Now let's get to the fun part, generating some text!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_Ovjx2Bl06_"
      },
      "source": [
        "### Generating text with our LLM\n",
        "\n",
        "We can generate text with our LLM `model` instance by calling the [`generate()` method](https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/text_generation#transformers.GenerationConfig) (this method has plenty of options to pass into it alongside the text) on it and passing it a tokenized input.\n",
        "\n",
        "The tokenized input comes from passing a string of text to our `tokenizer`.\n",
        "\n",
        "It's important to note that you should use a tokenizer that has been paired with a model.\n",
        "\n",
        "Otherwise if you try to use a different tokenizer and then pass those inputs to a model, you will likely get errors/strange results.\n",
        "\n",
        "For some LLMs, there's a specific template you should pass to them for ideal outputs.\n",
        "\n",
        "For example, the `gemma-7b-it` model has been trained in a dialogue fashion (instruction tuning).\n",
        "\n",
        "In this case, our `tokenizer` has a [`apply_chat_template()` method](https://huggingface.co/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.apply_chat_template) which can prepare our input text in the right format for the model.\n",
        "\n",
        "Let's try it out.\n",
        "\n",
        "> **Note:** The following demo has been modified from the Hugging Face model card for [Gemma 7B](https://huggingface.co/google/gemma-7b-it). Many similar demos of usage are available on the model cards of similar models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "YlTORYDIl06_",
        "outputId": "993cab8e-743e-49fa-e6cf-a0ced52a6ac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input text:\n",
            "What are the macronutrients, and what roles do they play in the human body?\n",
            "\n",
            "Prompt (formatted):\n",
            "<bos><start_of_turn>user\n",
            "What are the macronutrients, and what roles do they play in the human body?<end_of_turn>\n",
            "<start_of_turn>model\n",
            "\n"
          ]
        }
      ],
      "source": [
        "input_text = \"What are the macronutrients, and what roles do they play in the human body?\"\n",
        "print(f\"Input text:\\n{input_text}\")\n",
        "\n",
        "# Create prompt template for instruction-tuned model\n",
        "dialogue_template = [\n",
        "    {\"role\": \"user\",\n",
        "     \"content\": input_text}\n",
        "]\n",
        "\n",
        "# Apply the chat template\n",
        "prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
        "                                       tokenize=False, # keep as raw text (not tokenized)\n",
        "                                       add_generation_prompt=True)\n",
        "print(f\"\\nPrompt (formatted):\\n{prompt}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91ag5Hm4l06_"
      },
      "source": [
        "Notice the scaffolding around our input text, this is the kind of turn-by-turn instruction tuning our model has gone through.\n",
        "\n",
        "Our next step is to tokenize this formatted text and pass it to our model's `generate()` method.\n",
        "\n",
        "We'll make sure our tokenized text is on the same device as our model (GPU) using `to(\"cuda\")`.\n",
        "\n",
        "Let's generate some text!\n",
        "\n",
        "We'll time it for fun with the `%%time` magic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "E02YELGyl06_",
        "outputId": "26b84717-b184-46aa-9d2b-9b18eab35949"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model input (tokenized):\n",
            "{'input_ids': tensor([[     2,      2,    106,   1645,    108,   1841,    708,    573, 186809,\n",
            "         184592, 235269,    578,   1212,  16065,    749,    984,   1554,    575,\n",
            "            573,   3515,   2971, 235336,    107,    108,    106,   2516,    108]],\n",
            "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1]], device='cuda:0')}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\gemma\\modeling_gemma.py:573: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model output (tokens):\n",
            "tensor([     2,      2,    106,   1645,    108,   1841,    708,    573, 186809,\n",
            "        184592, 235269,    578,   1212,  16065,    749,    984,   1554,    575,\n",
            "           573,   3515,   2971, 235336,    107,    108,    106,   2516,    108,\n",
            "         21404, 235269,   1517, 235303, 235256,    476,  25497,    576,    573,\n",
            "        186809, 184592,    578,   1024,  16065,    575,    573,   3515,   2971,\n",
            "        235292,    109,    688,  12298,   1695, 184592,    688,    708,  37132,\n",
            "           674,    573,   2971,   4026,    575,   8107,  15992,   1178,  34366,\n",
            "        235265,   2365,   3658,    573,   4547,  13854,    604,  29703, 235269,\n",
            "         44760, 235269,    578,   1156,  24582,    674,   1501,    908,    573,\n",
            "          2971, 235265,    109,    688,    651,   2149,   1872, 186809, 184592,\n",
            "           708,  66058,    109, 235287,   5231, 156615,  56227,  66058,  34428,\n",
            "          4134,    604,    573,   2971, 235303, 235256,   5999,    578,  29703,\n",
            "        235265,   2365,    708,    573,   2971, 235303, 235256,   1872,   4303,\n",
            "           576,   9719, 235265,    108, 235287,   5231,  49471,  66058,   2125,\n",
            "          8727,    604,   4547,    578,  68808,  29703, 235269,  44760, 235269,\n",
            "           578,  53186, 235265,   1165,   1170,   7154,    577,  41748,   5330,\n",
            "          9347,   5902, 235265,    108, 235287,   5231,  33690,  66058,  57697,\n",
            "          4134, 235269,   7154,    577,  33398,  48765,    578,  31740, 235269,\n",
            "           578,   7154,    577,   2029,   7459,    573,   2971, 235265,    109,\n",
            "           688,   6273,   2845, 186809, 184592,   3707,  66058,    109, 235287,\n",
            "          5231, 156615,  56227,  66058,    108,    141, 235287,  13702,  72780,\n",
            "        235269,   1582,    685,  30859, 235269, 162835, 235269,    578, 109955,\n",
            "        235269,    708,   7290, 122712,    578,  36105,    731,    573,   2971,\n",
            "        235265,    108,    141, 235287,  25280,  72780, 235269,   1582,    685,\n",
            "         57634, 235269,  20149, 235269,    578,  77723, 235269,    708, 122712,\n",
            "           978,  13708,    578,   3658,    476,  27476,   4303,    576,   4134,\n",
            "        235265,    108, 235287,   5231,  49471,  66058,    108,    141, 235287,\n",
            "         47839,  26005,  22589,    708,    573,   4547,  13854,    576,  20361,\n",
            "        235265,    108,    141, 235287,   8345, 235290,  53763,  26005,  22589,\n",
            "           798,    614,  78472,    731,    573,   2971,    774,   1156,  37132,\n",
            "        235265,    108, 235287,   5231,  33690,  66058,    108,    141, 235287,\n",
            "        128508,   6181,    603,    476], device='cuda:0')\n",
            "\n",
            "CPU times: total: 9.53 s\n",
            "Wall time: 14.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Tokenize the input text (turn it into numbers) and send it to GPU\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "print(f\"Model input (tokenized):\\n{input_ids}\\n\")\n",
        "\n",
        "# Generate outputs passed on the tokenized input\n",
        "# See generate docs: https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/text_generation#transformers.GenerationConfig\n",
        "outputs = llm_model.generate(**input_ids,\n",
        "                             max_new_tokens=256) # define the maximum number of new tokens to create\n",
        "print(f\"Model output (tokens):\\n{outputs[0]}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcrWDD7xl06_"
      },
      "source": [
        "Woohoo! We just generated some text on our local GPU!\n",
        "\n",
        "Well not just yet...\n",
        "\n",
        "Our LLM accepts tokens in and sends tokens back out.\n",
        "\n",
        "We can conver the output tokens to text using [`tokenizer.decode()`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizer.decode)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DWrMF0jxl06_",
        "outputId": "b2ee68d8-5c75-44c1-a9b6-5d04adde3f8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model output (decoded):\n",
            "<bos><bos><start_of_turn>user\n",
            "What are the macronutrients, and what roles do they play in the human body?<end_of_turn>\n",
            "<start_of_turn>model\n",
            "Sure, here's a breakdown of the macronutrients and their roles in the human body:\n",
            "\n",
            "**Macronutrients** are nutrients that the body needs in larger amounts than calories. They provide the building blocks for tissues, enzymes, and other molecules that make up the body.\n",
            "\n",
            "**The three main macronutrients are:**\n",
            "\n",
            "* **Carbohydrates:** Provide energy for the body's cells and tissues. They are the body's main source of fuel.\n",
            "* **Protein:** Is essential for building and repairing tissues, enzymes, and hormones. It also helps to regulate blood sugar levels.\n",
            "* **Fat:** Provides energy, helps to absorb vitamins and minerals, and helps to insulate the body.\n",
            "\n",
            "**Other important macronutrients include:**\n",
            "\n",
            "* **Carbohydrates:**\n",
            "    * Simple carbohydrates, such as glucose, fructose, and lactose, are quickly digested and absorbed by the body.\n",
            "    * Complex carbohydrates, such as starch, fiber, and cellulose, are digested more slowly and provide a sustained source of energy.\n",
            "* **Protein:**\n",
            "    * Essential amino acids are the building blocks of proteins.\n",
            "    * Non-essential amino acids can be synthesized by the body from other nutrients.\n",
            "* **Fat:**\n",
            "    * Dietary fat is a\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Decode the output tokens to text\n",
        "outputs_decoded = tokenizer.decode(outputs[0])\n",
        "print(f\"Model output (decoded):\\n{outputs_decoded}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7vyRcx1l07A"
      },
      "source": [
        "Woah! That looks like a pretty good answer.\n",
        "\n",
        "But notice how the output contains the prompt text as well?\n",
        "\n",
        "How about we do a little formatting to replace the prompt in the output text?\n",
        "\n",
        "> **Note:** `\"<bos>\"` and `\"<eos>\"` are special tokens to denote \"beginning of sentence\" and \"end of sentence\" respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "VSCKc45Jl07A",
        "outputId": "166735d2-641b-4654-9eab-c252030af3cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input text: What are the macronutrients, and what roles do they play in the human body?\n",
            "\n",
            "Output text:\n",
            "Sure, here's a breakdown of the macronutrients and their roles in the human body:\n",
            "\n",
            "**Macronutrients** are nutrients that the body needs in larger amounts than calories. They provide the building blocks for tissues, enzymes, and other molecules that make up the body.\n",
            "\n",
            "**The three main macronutrients are:**\n",
            "\n",
            "* **Carbohydrates:** Provide energy for the body's cells and tissues. They are the body's main source of fuel.\n",
            "* **Protein:** Is essential for building and repairing tissues, enzymes, and hormones. It also helps to regulate blood sugar levels.\n",
            "* **Fat:** Provides energy, helps to absorb vitamins and minerals, and helps to insulate the body.\n",
            "\n",
            "**Other important macronutrients include:**\n",
            "\n",
            "* **Carbohydrates:**\n",
            "    * Simple carbohydrates, such as glucose, fructose, and lactose, are quickly digested and absorbed by the body.\n",
            "    * Complex carbohydrates, such as starch, fiber, and cellulose, are digested more slowly and provide a sustained source of energy.\n",
            "* **Protein:**\n",
            "    * Essential amino acids are the building blocks of proteins.\n",
            "    * Non-essential amino acids can be synthesized by the body from other nutrients.\n",
            "* **Fat:**\n",
            "    * Dietary fat is a\n"
          ]
        }
      ],
      "source": [
        "print(f\"Input text: {input_text}\\n\")\n",
        "print(f\"Output text:\\n{outputs_decoded.replace(prompt, '').replace('<bos>', '').replace('<eos>', '')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSxEW_5hl07A"
      },
      "source": [
        "How cool is that!\n",
        "\n",
        "We just officially generated text from an LLM running locally.\n",
        "\n",
        "So we've covered the R (retrieval) and G (generation) of RAG.\n",
        "\n",
        "How about we check out the last step?\n",
        "\n",
        "Augmentation.\n",
        "\n",
        "First, let's put together a list of queries we can try out with our pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YmBPmA1Hl07A"
      },
      "outputs": [],
      "source": [
        "# Nutrition-style questions generated with GPT4\n",
        "gpt4_questions = [\n",
        "    \"What are the macronutrients, and what roles do they play in the human body?\",\n",
        "    \"How do vitamins and minerals differ in their roles and importance for health?\",\n",
        "    \"Describe the process of digestion and absorption of nutrients in the human body.\",\n",
        "    \"What role does fibre play in digestion? Name five fibre containing foods.\",\n",
        "    \"Explain the concept of energy balance and its importance in weight management.\"\n",
        "]\n",
        "\n",
        "# Manually created question list\n",
        "manual_questions = [\n",
        "    \"How often should infants be breastfed?\",\n",
        "    \"What are symptoms of pellagra?\",\n",
        "    \"How does saliva help with digestion?\",\n",
        "    \"What is the RDI for protein per day?\",\n",
        "    \"water soluble vitamins\"\n",
        "]\n",
        "\n",
        "query_list = gpt4_questions + manual_questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX-Mj9XXl07A"
      },
      "source": [
        "And now let's check if our `retrieve_relevant_resources()` function works with our list of queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "q14-3Y_bl07A",
        "outputId": "48af748c-ff36-4968-f8d7-6f171b867dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: water soluble vitamins\n",
            "[INFO] Time taken to get scores on 29 embeddings: 0.00032 seconds.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([0.0219, 0.0204, 0.0199, 0.0084, 0.0078], device='cuda:0'),\n",
              " tensor([ 2,  3, 16, 28, 27], device='cuda:0'))"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "query = random.choice(query_list)\n",
        "\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "# Get just the scores and indices of top related results\n",
        "scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                              embeddings=embeddings)\n",
        "scores, indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzdVb7sWl07A"
      },
      "source": [
        "Beautiful!\n",
        "\n",
        "Let's augment!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq_80636l07A"
      },
      "source": [
        "### Augmenting our prompt with context items\n",
        "\n",
        "What we'd like to do with augmentation is take the results from our search for relevant resources and put them into the prompt that we pass to our LLM.\n",
        "\n",
        "In essence, we start with a base prompt and update it with context text.\n",
        "\n",
        "Let's write a function called `prompt_formatter` that takes in a query and our list of context items (in our case it'll be select indices from our list of dictionaries inside `pages_and_chunks`) and then formats the query with text from the context items.\n",
        "\n",
        "We'll apply the dialogue and chat template to our prompt before returning it as well.\n",
        "\n",
        "> **Note:** The process of augmenting or changing a prompt to an LLM is known as prompt engineering. And the best way to do it is an active area of research. For a comprehensive guide on different prompt engineering techniques, I'd recommend the Prompt Engineering Guide ([promptingguide.ai](https://www.promptingguide.ai/)), [Brex's Prompt Engineering Guide](https://github.com/brexhq/prompt-engineering) and the paper [Prompt Design and Engineering: Introduction and Advanced Models](https://arxiv.org/abs/2401.14423)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "L_4SsfKwl07A"
      },
      "outputs": [],
      "source": [
        "def prompt_formatter(query: str,\n",
        "                     context_items: list[dict]) -> str:\n",
        "    \"\"\"\n",
        "    Augments query with text-based context from context_items.\n",
        "    \"\"\"\n",
        "    # Join context items into one dotted paragraph\n",
        "    context = \"- \" + \"\\n- \".join([item[\"sentence_chunk\"] for item in context_items])\n",
        "\n",
        "    # Create a base prompt with examples to help the model\n",
        "    # Note: this is very customizable, I've chosen to use 3 examples of the answer style we'd like.\n",
        "    # We could also write this in a txt file and import it in if we wanted.\n",
        "    base_prompt = \"\"\"Based on the following context items, please answer the query.\n",
        "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
        "Don't return the thinking, only return the answer.\n",
        "Make sure your answers are as explanatory as possible.\n",
        "Use the following examples as reference for the ideal answer style.\n",
        "\\nExample 1:\n",
        "Query: What are the fat-soluble vitamins?\n",
        "Answer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\n",
        "\\nExample 2:\n",
        "Query: What are the causes of type 2 diabetes?\n",
        "Answer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\n",
        "\\nExample 3:\n",
        "Query: What is the importance of hydration for physical performance?\n",
        "Answer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\n",
        "\\nNow use the following context to answer the user query:\n",
        "{context}\n",
        "\\nRelevant passages: <extract relevant passages from the context here>\n",
        "User query: {query}\n",
        "Answer:\"\"\"\n",
        "\n",
        "    # Update base prompt with context items and query\n",
        "    base_prompt = base_prompt.format(context=context, query=query)\n",
        "    \n",
        "    # Create prompt template for instruction-tuned model\n",
        "    dialogue_template = [\n",
        "        {\"role\": \"user\",\n",
        "        \"content\": base_prompt}\n",
        "    ]\n",
        "    print(dialogue_template)\n",
        "    # Apply the chat template\n",
        "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
        "                                          tokenize=False,\n",
        "                                          add_generation_prompt=True)\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYCQpdWll07B"
      },
      "source": [
        "What a good looking prompt!\n",
        "\n",
        "We can tokenize this and pass it straight to our LLM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUtM4Jozl07B"
      },
      "source": [
        "\n",
        "How about we functionize the generation step to make it easier to use?\n",
        "\n",
        "We can put a little formatting on the text being returned to make it look nice too.\n",
        "\n",
        "And we'll make an option to return the context items if needed as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "rHpOPHIIl07B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Time taken to get scores on 29 embeddings: 0.00006 seconds.\n",
            "[{'role': 'user', 'content': \"Based on the following context items, please answer the query.\\nGive yourself room to think by extracting relevant passages from the context before answering the query.\\nDon't return the thinking, only return the answer.\\nMake sure your answers are as explanatory as possible.\\nUse the following examples as reference for the ideal answer style.\\n\\nExample 1:\\nQuery: What are the fat-soluble vitamins?\\nAnswer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\\n\\nExample 2:\\nQuery: What are the causes of type 2 diabetes?\\nAnswer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\\n\\nExample 3:\\nQuery: What is the importance of hydration for physical performance?\\nAnswer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\\n\\nNow use the following context to answer the user query:\\n- Here are some examples of AI's capabilities in process management: \\uf0b7 Automatic assignment of the duration of manual processing steps in business processes. The process control system can itself predict the optimal timing of certain stages based on the accumulated information about their labor intensity. \\uf0b7 Selection of an approval route for a document based on its content, taking into account the workload of personnel and the competence of employees. \\uf0b7 Planning the time of completion of the process and determining its planned metrics based on the accumulated information about the precedents. \\uf0b7 Predicting violations of planned deadlines for processes and individual tasks, optimizing processes in the course of their execution - changing the priority of unfinished tasks, deadlines, automatic delegation of tasks taking into account the workload of employees and their competence, etc. \\uf0b7 Completion of assignments in the event of a critical violation of deadlines, generation of approval results and assignment reports based on precedents. \\uf0b7 Revealing hidden regulations, typical scenarios of document processing based on the accumulated history of free routing. The system can analyze typical processing methods and generate process templates.\\n- ISSN: 2776-1010    Volume 2, Issue 6, June, 2021   301     \\uf0b7 automatic standard control (checking the compliance of design and technological documents with the formal requirements of the quality management system) in design and engineering organizations; \\uf0b7 search for judicial precedents in the systems of management of claims and claims work; \\uf0b7 search for typical responses to requests in Service Desk services and contact centers; \\uf0b7 automatic audit of compliance with regulations for the use of documents and search for traces of possible malicious actions in security management systems;and much more.  In conclusion, it is worth noting that companies that actively use electronic document management systems and plan their development should pay attention to situations when even working with electronic documents becomes time consuming and leads to repetitive routine actions. Most likely, a solution is possible that will take the process to a new level through the integration of AI technologies - this is carried out within the framework of project development. Obviously, we are at the very beginning of using artificial intelligence in the field of document flow, but individual projects and ready-made solutions already today demonstrate the practice and prospects of using these technologies.  REFERENCES 1) Nemchinova EA, Plotnikova NP, Fedosin SA Preparation and processing of reference text information for classification using artificial neural networks // Nonlinear World.2019. Vol.17. No. 2. S. 27-33.\\n- ISSN: 2776-1010    Volume 2, Issue 6, June, 2021   300     So, the options for using AI technologies in the field of workflow are endless, and it is obvious that as technologies improve, more and more new ones will appear. Today, AI is most often used to solve three types of tasks - intelligent document search, automatic classification and automatic extraction of attributes (metadata) from the text of documents. Modern EDMS, as a rule, offer ready-made or customizable solutions for these tasks. Automatic generation of document metadata allows you to automate a wide variety of document processing scenarios: for example, automatic registration of documents in the system, autorun of certain processing processes, assignment of those responsible for the processing of processes, assignment of due dates, etc. There are also less common applications of AI technologies in the EDMS, focused on specific processing procedures - and then we will consider various examples of the use of AI technologies that seem interesting and promising to us, and some of them are already being implemented in the framework of pilot projects.  CONCLUSION Obviously, the need to use artificial intelligence technologies in the above examples is a consequence of the lack of structure in the processed content. Given a sufficient amount of metadata describing various attributes of a document, these same tasks could be solved based on strict formal processing rules, but the elimination of unstructured content from an organization's business processes is a distant future. Artificial intelligence technologies open up special prospects in the field of corporate process automation and optimization.\\n- \\uf0b7 Determine if the model will be suitable for the working environment. A visual representation of the life cycle of the group data processing and analysis process is shown in Figure 1:\\n- ISSN: 2776-1010    Volume 2, Issue 6, June, 2021   294     were made by participants in business processes based on the content of documents, and other information that accompanies these business processes. An important characteristic of this information, in contrast to similar information in paper workflow, is that it is available for machine processing and can serve as a source material for the application of machine learning technologies. On the other hand, the rapid development of artificial intelligence technologies, and machine learning in particular, has made the use of these technologies available and relatively inexpensive to create specialized solutions. It is they who will ensure the maximum efficiency of work with documents and easily relieve employees of routine operations.  CLASSICAL APPROACHES TO THE IMPLEMENTATION OF ARTIFICIAL INTELLIGENCE SYSTEMS In the processes of document flow, two of the most laborious operations can be distinguished - the translation of documents from paper to electronic machine-readable form and the search for documents. It is no coincidence that these two areas attracted the attention of developers in the first place. Recognition and document search technologies are no longer something new and are very widespread, but recently they have acquired a new sound associated with the development of AI technologies. If the traditional recognition tasks were reduced to digitizing individual letters and symbols - full-text recognition, and the limit was the parsing of their semantics, based on the binding of character sets to certain positions in the paper form of a document (form recognition), then now artificial intelligence systems allow to do so much more.\\n\\nRelevant passages: <extract relevant passages from the context here>\\nUser query: Give me documents that is about Hilti's roles and responsibilities\\nAnswer:\"}]\n",
            "[INFO] Time taken to get scores on 29 embeddings: 0.00007 seconds.\n",
            "[{'role': 'user', 'content': \"Based on the following context items, please answer the query.\\nGive yourself room to think by extracting relevant passages from the context before answering the query.\\nDon't return the thinking, only return the answer.\\nMake sure your answers are as explanatory as possible.\\nUse the following examples as reference for the ideal answer style.\\n\\nExample 1:\\nQuery: What are the fat-soluble vitamins?\\nAnswer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\\n\\nExample 2:\\nQuery: What are the causes of type 2 diabetes?\\nAnswer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\\n\\nExample 3:\\nQuery: What is the importance of hydration for physical performance?\\nAnswer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\\n\\nNow use the following context to answer the user query:\\n- 6. S. 36-39. 4) Kislitsyn EV, Panova MV, Zhernakov RS Principles of application of neural network technologies in the analysis of big data // Prospects of science.2017. No.9, pp.7-10. 5) Vitenburg EA The architecture of the software complex for intelligent decision support in the design of the security system of the enterprise information system. Bulletin of Cybernetics.\\n- ISSN: 2776-1010    Volume 2, Issue 6, June, 2021   301     \\uf0b7 automatic standard control (checking the compliance of design and technological documents with the formal requirements of the quality management system) in design and engineering organizations; \\uf0b7 search for judicial precedents in the systems of management of claims and claims work; \\uf0b7 search for typical responses to requests in Service Desk services and contact centers; \\uf0b7 automatic audit of compliance with regulations for the use of documents and search for traces of possible malicious actions in security management systems;and much more.  In conclusion, it is worth noting that companies that actively use electronic document management systems and plan their development should pay attention to situations when even working with electronic documents becomes time consuming and leads to repetitive routine actions. Most likely, a solution is possible that will take the process to a new level through the integration of AI technologies - this is carried out within the framework of project development. Obviously, we are at the very beginning of using artificial intelligence in the field of document flow, but individual projects and ready-made solutions already today demonstrate the practice and prospects of using these technologies.  REFERENCES 1) Nemchinova EA, Plotnikova NP, Fedosin SA Preparation and processing of reference text information for classification using artificial neural networks // Nonlinear World.2019. Vol.17. No. 2. S. 27-33.\\n- For example, to select separate semantic data from the document not in accordance with the binding to the position in the text of the document, but in accordance with their meaning. Thus, the Compreno platform, developed by the Russian company ABBYY, provides developers with mechanisms that provide the ability not only to translate paper documents into a machine-readable form, but also to extract individual words and related expressions with certain semantics from flat text that is not presented in a structured form. For example, in the text of the contract, attributes and phrases can be highlighted that characterize the subject of the contract, the legal addresses of the counterparties and the names of the responsible persons, the amount of the contract and other structured data. For this, special technologies are used for high-level semantic text analysis based on so-called ontologies (special dictionaries describing certain subject areas). The creation of these ontologies is carried out by linguistic specialists, and the system transfers their knowledge of the described subject areas to the field of computer technology. This example illustrates one of two classical approaches to the implementation of artificial intelligence systems - the so-called top-down approach, which allows high-level psychological processes occurring in a person's consciousness to be simulated in a computer system. These technologies of semantic parsing of text and the selection of individual semantic entities can be used not only for automatic search for attributes (metadata) in documents, but also for solving other problems, for example: intelligent search for documents not based on syntactic analysis (the presence of certain lexical structures and their variations in the text), but based on the\\n- Here are some examples of AI's capabilities in process management: \\uf0b7 Automatic assignment of the duration of manual processing steps in business processes. The process control system can itself predict the optimal timing of certain stages based on the accumulated information about their labor intensity. \\uf0b7 Selection of an approval route for a document based on its content, taking into account the workload of personnel and the competence of employees. \\uf0b7 Planning the time of completion of the process and determining its planned metrics based on the accumulated information about the precedents. \\uf0b7 Predicting violations of planned deadlines for processes and individual tasks, optimizing processes in the course of their execution - changing the priority of unfinished tasks, deadlines, automatic delegation of tasks taking into account the workload of employees and their competence, etc. \\uf0b7 Completion of assignments in the event of a critical violation of deadlines, generation of approval results and assignment reports based on precedents. \\uf0b7 Revealing hidden regulations, typical scenarios of document processing based on the accumulated history of free routing. The system can analyze typical processing methods and generate process templates.\\n- \\uf0b7 And this is not a complete list of possible applications of AI technologies in the field of process management. In addition to these general cases, various specific applications of the described technologies can be found in each subject area. Here are some notable implemented examples:\\n\\nRelevant passages: <extract relevant passages from the context here>\\nUser query: What does a chief privacy officer do in Hilti\\nAnswer:\"}]\n"
          ]
        }
      ],
      "source": [
        "def ask(query,\n",
        "        temperature=0.7,\n",
        "        max_new_tokens=512,\n",
        "        format_answer_text=True,\n",
        "        return_references=True):\n",
        "    \"\"\"\n",
        "    Takes a query, finds relevant resources/context and generates an answer to the query based on the relevant resources.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get just the scores and indices of top related results\n",
        "    scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                                  embeddings=embeddings)\n",
        "\n",
        "    # Create a list of context items\n",
        "    context_items = [pages_and_chunks[i] for i in indices]\n",
        "\n",
        "    # Add score to context item\n",
        "    for i, item in enumerate(context_items):\n",
        "        item[\"score\"] = scores[i].cpu() # return score back to CPU\n",
        "\n",
        "    # Format the prompt with context items\n",
        "    prompt = prompt_formatter(query=query,\n",
        "                              context_items=context_items)\n",
        "\n",
        "    # Tokenize the prompt\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Generate an output of tokens\n",
        "    outputs = llm_model.generate(**input_ids,\n",
        "                                 temperature=temperature,\n",
        "                                 do_sample=True,\n",
        "                                 max_new_tokens=max_new_tokens)\n",
        "\n",
        "    # Turn the output tokens into text\n",
        "    output_text = tokenizer.decode(outputs[0])\n",
        "\n",
        "    if format_answer_text:\n",
        "        # Replace special tokens and unnecessary help message\n",
        "        output_text = output_text.replace(prompt, \"\").replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").replace(\"Sure, here is the answer to the user query:\\n\\n\", \"\")\n",
        "\n",
        "    # Only return the answer without the context items\n",
        "    if return_references:\n",
        "        return output_text, context_items\n",
        "\n",
        "    return output_text, None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtpIifj3l07B"
      },
      "source": [
        "What a good looking function!\n",
        "\n",
        "The workflow could probably be a little refined but this should work!\n",
        "\n",
        "Let's try it out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO3YVVHjl07B",
        "outputId": "23f475d8-a716-4b57-c37d-6c3f2316a9ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: How often should infants be breastfed?\n",
            "[INFO] Time taken to get scores on 29 embeddings: 0.00009 seconds.\n",
            "[{'role': 'user', 'content': \"Based on the following context items, please answer the query.\\nGive yourself room to think by extracting relevant passages from the context before answering the query.\\nDon't return the thinking, only return the answer.\\nMake sure your answers are as explanatory as possible.\\nUse the following examples as reference for the ideal answer style.\\n\\nExample 1:\\nQuery: What are the fat-soluble vitamins?\\nAnswer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\\n\\nExample 2:\\nQuery: What are the causes of type 2 diabetes?\\nAnswer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\\n\\nExample 3:\\nQuery: What is the importance of hydration for physical performance?\\nAnswer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\\n\\nNow use the following context to answer the user query:\\n- ISSN: 2776-1010    Volume 2, Issue 6, June, 2021   297     f: (x, x ’) between objects from X (x, x’ ε X, f ε Y). The quality of identifying relationships is checked by some metric selected based on the problem being solved. Unsupervised learning is used to solve the following types of problems: 1. The task of clustering. 2. Search for association rules. 3. Reducing the dimension of the data.\\n- The process is performed within the recommended life cycle, allowing you to structure data processing and analysis projects. This life cycle represents the milestones that are typically completed by projects, often iteratively: 1. Commercial aspect. 2. Obtaining and analyzing data. 3. Simulation 4. Deployment 5.\\n- If the assumptions about the decision criteria were made correctly, then as the training sample grows, the probability of an adequate prediction should increase, otherwise it is necessary to change the hypothesis about the criteria. Formally, the formulation of the unsupervised learning problem can be described as follows. Let X be a set of data - descriptions of some objects. It is necessary to find a set Y consisting of interconnections\\n- 4. Data visualization. To a certain extent, each of the last three tasks is a derivative of the first or its particular case. Let us consider in more detail the formulations of these tasks. The task of searching for association rules means identifying in the feature descriptions of objects (source data) such sets and values of features that are especially often (not by chance often) found in the source data. If we draw an analogy with the first task, then each rule in this case can be represented as a cluster. The task of reducing the dimension of data is as follows. There is a large (much larger) volume of feature descriptions of objects.\\n- ISSN: 2776-1010    Volume 2, Issue 6, June, 2021   296      Fig.1. The life cycle of the data processing and analysis process  METHODS OF TRAINING AND ASSESSMENT OF ITS QUALITY As mentioned above, the main characteristic of systems developed using machine learning methods is the ability to learn. Depending on the types of problems to be solved, various algorithms are used to implement this key feature. Within the framework of this article, we will consider the type of unsupervised learning, and also define the classes of problems that are suitable for this type. Initially, the structure of the network is not defined. The learning process is as follows: a specific copy of a document from the reference sample is fed to the input, for which the corresponding category is fixed at the output - as a result, the structure of the neural network is flashed. Starting from a certain step of learning (formation of the network structure), it can already begin to predict the result (in our case, whether the document should be assigned to one category or another).\\n\\nRelevant passages: <extract relevant passages from the context here>\\nUser query: How often should infants be breastfed?\\nAnswer:\"}]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer:\n",
            "\n",
            "The context does not provide any information about how often infants should be breastfed, so I cannot answer this query from the provided context.\n",
            "Context items:\n",
            "- SOURCE:357998-prospects-for-using-artificial-intellige-6e337f58.pdf.PageNumber:5.Context:ISSN: 2776-1010    Volume 2, Issue 6, June, 2021   297     f: (x, x ’) between objects from X (x, x’ ε X, f ε Y). The quality of identifying relationships is checked by some metric selected based on the problem being solved. Unsupervised learning is used to solve the following types of problems: 1. The task of clustering. 2. Search for association rules. 3. Reducing the dimension of the data.\n",
            "- SOURCE:357998-prospects-for-using-artificial-intellige-6e337f58.pdf.PageNumber:3.Context:The process is performed within the recommended life cycle, allowing you to structure data processing and analysis projects. This life cycle represents the milestones that are typically completed by projects, often iteratively: 1. Commercial aspect. 2. Obtaining and analyzing data. 3. Simulation 4. Deployment 5.\n",
            "- SOURCE:357998-prospects-for-using-artificial-intellige-6e337f58.pdf.PageNumber:4.Context:If the assumptions about the decision criteria were made correctly, then as the training sample grows, the probability of an adequate prediction should increase, otherwise it is necessary to change the hypothesis about the criteria. Formally, the formulation of the unsupervised learning problem can be described as follows. Let X be a set of data - descriptions of some objects. It is necessary to find a set Y consisting of interconnections\n",
            "- SOURCE:357998-prospects-for-using-artificial-intellige-6e337f58.pdf.PageNumber:5.Context:4. Data visualization. To a certain extent, each of the last three tasks is a derivative of the first or its particular case. Let us consider in more detail the formulations of these tasks. The task of searching for association rules means identifying in the feature descriptions of objects (source data) such sets and values of features that are especially often (not by chance often) found in the source data. If we draw an analogy with the first task, then each rule in this case can be represented as a cluster. The task of reducing the dimension of data is as follows. There is a large (much larger) volume of feature descriptions of objects.\n",
            "- SOURCE:357998-prospects-for-using-artificial-intellige-6e337f58.pdf.PageNumber:4.Context:ISSN: 2776-1010    Volume 2, Issue 6, June, 2021   296      Fig.1. The life cycle of the data processing and analysis process  METHODS OF TRAINING AND ASSESSMENT OF ITS QUALITY As mentioned above, the main characteristic of systems developed using machine learning methods is the ability to learn. Depending on the types of problems to be solved, various algorithms are used to implement this key feature. Within the framework of this article, we will consider the type of unsupervised learning, and also define the classes of problems that are suitable for this type. Initially, the structure of the network is not defined. The learning process is as follows: a specific copy of a document from the reference sample is fed to the input, for which the corresponding category is fixed at the output - as a result, the structure of the neural network is flashed. Starting from a certain step of learning (formation of the network structure), it can already begin to predict the result (in our case, whether the document should be assigned to one category or another).\n"
          ]
        }
      ],
      "source": [
        "query = random.choice(query_list)\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "# Answer query with context and return context\n",
        "answer, context_items = ask(query=query,\n",
        "                            temperature=0.7,\n",
        "                            max_new_tokens=512,\n",
        "                            return_references=True)\n",
        "\n",
        "print(f\"Answer:\\n\")\n",
        "print(answer)\n",
        "#print_wrapped(answer)\n",
        "print(f\"Context items:\")\n",
        "context = \"- \" + \"\\n- \".join([str(\"SOURCE:\" + item[\"pdf_name\"] + \".PageNumber:\" + str(item[\"page_number\"]) + \".Context:\" + item[\"sentence_chunk\"]) for item in context_items])\n",
        "print(context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e14TK6Nfl07B"
      },
      "source": [
        "Local RAG workflow complete!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hosting in Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.26.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (5.3.0)\n",
            "Requirement already satisfied: fastapi in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.110.1)\n",
            "Requirement already satisfied: ffmpy in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==0.15.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.22.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (3.8.4)\n",
            "Requirement already satisfied: numpy~=1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (3.10.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.2.1)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (10.3.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.6.4)\n",
            "Requirement already satisfied: pydub in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.3.5)\n",
            "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.9.4)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.29.0)\n",
            "Requirement already satisfied: fsspec in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio-client==0.15.1->gradio) (2024.3.1)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio-client==0.15.1->gradio) (11.0.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.21.1)\n",
            "Requirement already satisfied: toolz in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (4.3.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: idna in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.3)\n",
            "Requirement already satisfied: requests in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.0->gradio) (2.16.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.17.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
        "!pip install gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://ff6b4c7cfe145f5eff.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "ename": "ConnectTimeout",
          "evalue": "_ssl.c:983: The handshake operation timed out",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_transports\\default.py:69\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_transports\\default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\connection.py:99\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\connection.py:76\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\connection.py:154\u001b[0m, in \u001b[0;36mHTTPConnection._connect\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_tls\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m--> 154\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_tls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_backends\\sync.py:152\u001b[0m, in \u001b[0;36mSyncStream.start_tls\u001b[1;34m(self, ssl_context, server_hostname, timeout)\u001b[0m\n\u001b[0;32m    148\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    149\u001b[0m     socket\u001b[38;5;241m.\u001b[39mtimeout: ConnectTimeout,\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[0;32m    151\u001b[0m }\n\u001b[1;32m--> 152\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[1;34m(map)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[1;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[1;31mConnectTimeout\u001b[0m: _ssl.c:983: The handshake operation timed out",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[69], line 28\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result  \u001b[38;5;66;03m# Return both the answer and the return_answer\u001b[39;00m\n\u001b[0;32m     23\u001b[0m demo \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mChatInterface(question,\n\u001b[0;32m     24\u001b[0m                         additional_inputs\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     25\u001b[0m                             gr\u001b[38;5;241m.\u001b[39mCheckbox(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn References\u001b[39m\u001b[38;5;124m\"\u001b[39m, interactive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m                         ]\n\u001b[0;32m     27\u001b[0m                         )\n\u001b[1;32m---> 28\u001b[0m \u001b[43mdemo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\blocks.py:2328\u001b[0m, in \u001b[0;36mBlocks.launch\u001b[1;34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, auth_dependency, _frontend)\u001b[0m\n\u001b[0;32m   2325\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTML, Javascript, display  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   2327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_url:\n\u001b[1;32m-> 2328\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mnetworking\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl_ok\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshare_url\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   2329\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.25\u001b[39m)\n\u001b[0;32m   2330\u001b[0m     artifact \u001b[38;5;241m=\u001b[39m HTML(\n\u001b[0;32m   2331\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<div><iframe src=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m width=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m height=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m allow=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautoplay; camera; microphone; clipboard-read; clipboard-write;\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m frameborder=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m allowfullscreen></iframe></div>\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2332\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\networking.py:53\u001b[0m, in \u001b[0;36murl_ok\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m     52\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mhttpx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m401\u001b[39m, \u001b[38;5;241m302\u001b[39m):  \u001b[38;5;66;03m# 401 or 302 if auth is set\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_api.py:278\u001b[0m, in \u001b[0;36mhead\u001b[1;34m(url, params, headers, cookies, auth, proxy, proxies, follow_redirects, cert, verify, timeout, trust_env)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhead\u001b[39m(\n\u001b[0;32m    256\u001b[0m     url: URLTypes,\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    268\u001b[0m     trust_env: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    269\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Sends a `HEAD` request.\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    on this function, as `HEAD` requests should not include a request body.\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_api.py:106\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, params, content, data, files, json, headers, cookies, auth, proxy, proxies, timeout, follow_redirects, verify, cert, trust_env)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03mSends an HTTP request.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Client(\n\u001b[0;32m     98\u001b[0m     cookies\u001b[38;5;241m=\u001b[39mcookies,\n\u001b[0;32m     99\u001b[0m     proxy\u001b[38;5;241m=\u001b[39mproxy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m     trust_env\u001b[38;5;241m=\u001b[39mtrust_env,\n\u001b[0;32m    105\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m client:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:827\u001b[0m, in \u001b[0;36mClient.request\u001b[1;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[0;32m    812\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m    814\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[0;32m    815\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    816\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    825\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[0;32m    826\u001b[0m )\n\u001b[1;32m--> 827\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[0;32m    910\u001b[0m )\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1012\u001b[0m     )\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_transports\\default.py:232\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(request\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    231\u001b[0m )\n\u001b[1;32m--> 232\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    153\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
            "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_transports\\default.py:86\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     85\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
            "\u001b[1;31mConnectTimeout\u001b[0m: _ssl.c:983: The handshake operation timed out"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Time taken to get scores on 153 embeddings: 0.00025 seconds.\n",
            "[{'role': 'user', 'content': \"Based on the following context items, please answer the query.\\nGive yourself room to think by extracting relevant passages from the context before answering the query.\\nDon't return the thinking, only return the answer.\\nMake sure your answers are as explanatory as possible.\\nUse the following examples as reference for the ideal answer style.\\n\\nExample 1:\\nQuery: What are the fat-soluble vitamins?\\nAnswer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\\n\\nExample 2:\\nQuery: What are the causes of type 2 diabetes?\\nAnswer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\\n\\nExample 3:\\nQuery: What is the importance of hydration for physical performance?\\nAnswer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\\n\\nNow use the following context to answer the user query:\\n- Hilti employees also have by default an obligation of secrecy which applies to the processing of Personal Data. Hilti applies the highest data protection standards and pro- vides Third-Party beneficiary rights to Data Subjects. These rights are enforceable no matter where Personal Data is pro- cessed by Hilti. Where additional rights can be granted to Data Subjects for example as per national data protection laws and regulations, Hilti undertakes to respond to such right. Hilti provides an up-to-date list of Hilti Entities bound by the BCR available on: www.hilti.group.3. DATA PROTECTION OFFICER a.\\t Purpose Data Protection Officers (“DPO’s”) are a key role in the data protection accountability-based framework. Hilti has ap- pointed a network of DPOs to ensure the implementation of compliance and internal privacy policies throughout the whole organization.\\n- www.hilti.group 16 12. APPENDIX 1\\u2009/ DEFINITIONS Binding Corporate Rules\\u2009/\\u2009Controller’s Policy (“BCR”): BCR (Binding Corporate Rules) are an EU mechanism to allow international transfers of Personal Data across Hilti Group worldwide Entities and organization. BCR are legally binding and approved by the EU data protection regulators. Hilti Entities sign the herewith BCR and Joint Agreement to comply with the same level of data protection and internal rules for processing Personal Data. Chief Privacy Officer (“CPO”): CPO means the Hilti Chief Privacy Officer. The CPO is respon- sible for reviewing and monitoring Hilti’s data protection  compliance and reporting to the highest level of management. Controller: Controller means the natural or legal person, public  authority, agency, or other body which, alone or jointly with others, determines the purposes and means of the  processing of Personal Data. Such Controller can be Hilti HQ, a Hilti Entity, or a Third Party.\\n- b.\\t Roles and responsibilities Chief Privacy Officer: Hilti has appointed a Chief Privacy Officer (“CPO”) responsible for monitoring compliance with data protection laws and regulations and easily accessible from each Hilti Entity. CPO is the designated Data Protection Officer for Hilti, and its contact details are communicated to the Liechtenstein Data Protection Authority as per GDPR Article 37. The CPO has been appointed based on his/her expert knowledge in the field of data protection and data privacy, as well as overall years of experience which attest their professional qualities required to fulfill the tasks of a CPO. The required skills are: •\\t Expertise and in-depth understanding of national, EEA, global data protection and privacy laws, regulations and practices •\\t Advanced knowledge of the business sector and Hilti internal organization EXECUTIVE BOARD CHIEF PRIVACY OFFICER GLOBAL DATA PROTECTION REGIONAL DATA PROTECTION OFFICER PROJECT OWNER LOCAL DATA PROTECTION OFFICER LOCAL PROCESS OWNER\\n- www.hilti.group 4 •\\t Good understanding of processing activities and operations carried out by Hilti •\\t Integrity and high professional ethics •\\t Understanding of GDPR processes and principles •\\t Outstanding communication skills in order to train and work with various teams and business lines •\\t Ability to guarantee secrecy and high confidentiality during the performance of their duties The role of CPO has been strictly assessed and Hilti ensures the independence of the CPO role which is free from any conflict of interest within Hilti. The CPO operates from Hilti’s Headquarters and reports to the highest management level. The CPO undertakes to fulfill the following tasks: •\\t Regularly or where necessary, informs and advises the Executive Board •\\t Monitors compliance with data protection regulations and internal policies, including to protect Personal Data, assign responsibilities, raise awareness, and ensure the training of staff involved in processing operations and related audits •\\t \\t Provides advice where requested with regards to Data Protection Impact Assessments and monitors their performance •\\t \\t Cooperates with the Supervisory Authorities •\\t \\t Acts as a contact point for the Supervisory Authorities on any issue relating to processing of Personal Data, including prior consultation where required and to consult where appropriate with regard to any other matter •\\t \\t Provides guidance by evaluating the risks associated with all data processing activities including but not limited to the scope, nature, context, and purposes for the processing •\\t \\t Monitors and annually reports on compliance at a global level to the executive board of directors •\\t \\t Ensures the integration of data protection in overall compliance management, this includes but is not limited to the product and services development process as well as continued process reviews and enhancements •\\t \\t Supervises the Global Team •\\t \\t Informs the Executive Board or highest management level of any question or concern arising during the performance of his/her duties •\\t \\t Decides on or requests audits on an ad hoc basis Global Team: The Global Team (“Global Team”) is com- posed of privacy professionals specializing in legal and technical implementation of data protection matters. The Global Team directly reports to the CPO and is involved at the earliest stage of Hilti operations to assess data protection. The Global Team tasks are the following: •\\t Providing CPO and business lines with legal and technical assessments with regards to data protection •\\t \\t Drafting internal policies and processes •\\t \\t Providing business lines with guidance •\\t \\t Conducting DPIA •\\t \\t Promoting data protection by Design and by Default in the whole organization •\\t \\t Regularly reviewing organization’s governance in regard to data protection •\\t \\t Providing regular guidance for regional and local DPOs and monitoring performance at a regional and local level •\\t \\t Raising awareness in the organization •\\t \\t Providing Regional and Local DPOs with training •\\t \\t Supporting global corporate audit teams in the performance of audit program •\\t \\t Updating the record of processing activities at a global level on behalf of the Controller (Hilti Entity or Hilti HQ) •\\t \\t Drafting and reviewing data processing agreements for global contracts •\\t \\t Handling Data Subject requests including assessment of Data Subject Rights The Global Team works hand-in-hand with the CPO, performs in an independent manner and undertakes strict secrecy and confidentiality during the course of their duties. Regional DPOs: Regional DPOs are appointed to coordinate data protection policies at a regional level according to Hilti’s internal organization. Regional DPOs are responsible for the following tasks: •\\t \\t Ensuring a legal watch for the region and informing the Global Team for further assessment •\\t \\t Communicating to Local DPOs action plans, roadmaps and insights provided by the Global Team or CPO •\\t \\t Providing the Global Team with periodic reports on performance •\\t Seeking guidance from the Global Team or CPO •\\t \\t Handling DSR and claims Local DPOs and Local Process Owners: Local DPOs are responsible for monitoring data protection practices and processing activities in Hilti Entities. Local DPOs are responsible for the following tasks: •\\t \\t Locally implementing global and regional internal policies •\\t \\t Evaluating local processing activities together with project owners •\\t \\t Drafting data processing agreements with local vendors •\\t \\t Ensuring a legal watch and reporting to Regional DPO, Head of Legal and Compliance or the Global Team •\\t \\t Updating the record of processing activities at a local level and ensuring this is continuously updated and maintained •\\t \\t Handling DSR and claims Local Process Owners are responsible for assisting their respective Local DPO and informing them regarding the devel- opment of local activities.\\n- www.hilti.group 10 7. ACCOUNTABILITY Hilti undertakes to act in accordance with data protection principles. Therefore, Hilti HQ is bound by the herewith BCR and takes responsibility for developing processes and demonstrating compliance with the BCR.8. AUDIT OF BCR Hilti establishes internal data protection rules and policies to ensure proper safeguards for processing Personal Data. As part of this, Hilti has implemented a data protec- tion audit program. The purpose of audits is to assess Hilti’s compliance against the BCR, where both Hilti Group and its Entities implement data protection policies on an ongoing basis in accordance with BCR.9.\\n\\nRelevant passages: <extract relevant passages from the context here>\\nUser query: What does a chief privacy officer do in Hilti\\nAnswer:\"}]\n",
            "[INFO] Time taken to get scores on 153 embeddings: 0.00007 seconds.\n",
            "[{'role': 'user', 'content': \"Based on the following context items, please answer the query.\\nGive yourself room to think by extracting relevant passages from the context before answering the query.\\nDon't return the thinking, only return the answer.\\nMake sure your answers are as explanatory as possible.\\nUse the following examples as reference for the ideal answer style.\\n\\nExample 1:\\nQuery: What are the fat-soluble vitamins?\\nAnswer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\\n\\nExample 2:\\nQuery: What are the causes of type 2 diabetes?\\nAnswer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\\n\\nExample 3:\\nQuery: What is the importance of hydration for physical performance?\\nAnswer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\\n\\nNow use the following context to answer the user query:\\n- Hilti employees also have by default an obligation of secrecy which applies to the processing of Personal Data. Hilti applies the highest data protection standards and pro- vides Third-Party beneficiary rights to Data Subjects. These rights are enforceable no matter where Personal Data is pro- cessed by Hilti. Where additional rights can be granted to Data Subjects for example as per national data protection laws and regulations, Hilti undertakes to respond to such right. Hilti provides an up-to-date list of Hilti Entities bound by the BCR available on: www.hilti.group.3. DATA PROTECTION OFFICER a.\\t Purpose Data Protection Officers (“DPO’s”) are a key role in the data protection accountability-based framework. Hilti has ap- pointed a network of DPOs to ensure the implementation of compliance and internal privacy policies throughout the whole organization.\\n- www.hilti.group 16 12. APPENDIX 1\\u2009/ DEFINITIONS Binding Corporate Rules\\u2009/\\u2009Controller’s Policy (“BCR”): BCR (Binding Corporate Rules) are an EU mechanism to allow international transfers of Personal Data across Hilti Group worldwide Entities and organization. BCR are legally binding and approved by the EU data protection regulators. Hilti Entities sign the herewith BCR and Joint Agreement to comply with the same level of data protection and internal rules for processing Personal Data. Chief Privacy Officer (“CPO”): CPO means the Hilti Chief Privacy Officer. The CPO is respon- sible for reviewing and monitoring Hilti’s data protection  compliance and reporting to the highest level of management. Controller: Controller means the natural or legal person, public  authority, agency, or other body which, alone or jointly with others, determines the purposes and means of the  processing of Personal Data. Such Controller can be Hilti HQ, a Hilti Entity, or a Third Party.\\n- b.\\t Roles and responsibilities Chief Privacy Officer: Hilti has appointed a Chief Privacy Officer (“CPO”) responsible for monitoring compliance with data protection laws and regulations and easily accessible from each Hilti Entity. CPO is the designated Data Protection Officer for Hilti, and its contact details are communicated to the Liechtenstein Data Protection Authority as per GDPR Article 37. The CPO has been appointed based on his/her expert knowledge in the field of data protection and data privacy, as well as overall years of experience which attest their professional qualities required to fulfill the tasks of a CPO. The required skills are: •\\t Expertise and in-depth understanding of national, EEA, global data protection and privacy laws, regulations and practices •\\t Advanced knowledge of the business sector and Hilti internal organization EXECUTIVE BOARD CHIEF PRIVACY OFFICER GLOBAL DATA PROTECTION REGIONAL DATA PROTECTION OFFICER PROJECT OWNER LOCAL DATA PROTECTION OFFICER LOCAL PROCESS OWNER\\n- www.hilti.group 4 •\\t Good understanding of processing activities and operations carried out by Hilti •\\t Integrity and high professional ethics •\\t Understanding of GDPR processes and principles •\\t Outstanding communication skills in order to train and work with various teams and business lines •\\t Ability to guarantee secrecy and high confidentiality during the performance of their duties The role of CPO has been strictly assessed and Hilti ensures the independence of the CPO role which is free from any conflict of interest within Hilti. The CPO operates from Hilti’s Headquarters and reports to the highest management level. The CPO undertakes to fulfill the following tasks: •\\t Regularly or where necessary, informs and advises the Executive Board •\\t Monitors compliance with data protection regulations and internal policies, including to protect Personal Data, assign responsibilities, raise awareness, and ensure the training of staff involved in processing operations and related audits •\\t \\t Provides advice where requested with regards to Data Protection Impact Assessments and monitors their performance •\\t \\t Cooperates with the Supervisory Authorities •\\t \\t Acts as a contact point for the Supervisory Authorities on any issue relating to processing of Personal Data, including prior consultation where required and to consult where appropriate with regard to any other matter •\\t \\t Provides guidance by evaluating the risks associated with all data processing activities including but not limited to the scope, nature, context, and purposes for the processing •\\t \\t Monitors and annually reports on compliance at a global level to the executive board of directors •\\t \\t Ensures the integration of data protection in overall compliance management, this includes but is not limited to the product and services development process as well as continued process reviews and enhancements •\\t \\t Supervises the Global Team •\\t \\t Informs the Executive Board or highest management level of any question or concern arising during the performance of his/her duties •\\t \\t Decides on or requests audits on an ad hoc basis Global Team: The Global Team (“Global Team”) is com- posed of privacy professionals specializing in legal and technical implementation of data protection matters. The Global Team directly reports to the CPO and is involved at the earliest stage of Hilti operations to assess data protection. The Global Team tasks are the following: •\\t Providing CPO and business lines with legal and technical assessments with regards to data protection •\\t \\t Drafting internal policies and processes •\\t \\t Providing business lines with guidance •\\t \\t Conducting DPIA •\\t \\t Promoting data protection by Design and by Default in the whole organization •\\t \\t Regularly reviewing organization’s governance in regard to data protection •\\t \\t Providing regular guidance for regional and local DPOs and monitoring performance at a regional and local level •\\t \\t Raising awareness in the organization •\\t \\t Providing Regional and Local DPOs with training •\\t \\t Supporting global corporate audit teams in the performance of audit program •\\t \\t Updating the record of processing activities at a global level on behalf of the Controller (Hilti Entity or Hilti HQ) •\\t \\t Drafting and reviewing data processing agreements for global contracts •\\t \\t Handling Data Subject requests including assessment of Data Subject Rights The Global Team works hand-in-hand with the CPO, performs in an independent manner and undertakes strict secrecy and confidentiality during the course of their duties. Regional DPOs: Regional DPOs are appointed to coordinate data protection policies at a regional level according to Hilti’s internal organization. Regional DPOs are responsible for the following tasks: •\\t \\t Ensuring a legal watch for the region and informing the Global Team for further assessment •\\t \\t Communicating to Local DPOs action plans, roadmaps and insights provided by the Global Team or CPO •\\t \\t Providing the Global Team with periodic reports on performance •\\t Seeking guidance from the Global Team or CPO •\\t \\t Handling DSR and claims Local DPOs and Local Process Owners: Local DPOs are responsible for monitoring data protection practices and processing activities in Hilti Entities. Local DPOs are responsible for the following tasks: •\\t \\t Locally implementing global and regional internal policies •\\t \\t Evaluating local processing activities together with project owners •\\t \\t Drafting data processing agreements with local vendors •\\t \\t Ensuring a legal watch and reporting to Regional DPO, Head of Legal and Compliance or the Global Team •\\t \\t Updating the record of processing activities at a local level and ensuring this is continuously updated and maintained •\\t \\t Handling DSR and claims Local Process Owners are responsible for assisting their respective Local DPO and informing them regarding the devel- opment of local activities.\\n- www.hilti.group 10 7. ACCOUNTABILITY Hilti undertakes to act in accordance with data protection principles. Therefore, Hilti HQ is bound by the herewith BCR and takes responsibility for developing processes and demonstrating compliance with the BCR.8. AUDIT OF BCR Hilti establishes internal data protection rules and policies to ensure proper safeguards for processing Personal Data. As part of this, Hilti has implemented a data protec- tion audit program. The purpose of audits is to assess Hilti’s compliance against the BCR, where both Hilti Group and its Entities implement data protection policies on an ongoing basis in accordance with BCR.9.\\n\\nRelevant passages: <extract relevant passages from the context here>\\nUser query: What does a chief privacy officer do in Hilti\\nAnswer:\"}]\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def question(message, history, return_references):\n",
        "  answer, context_items = ask   (query=message,\n",
        "                                temperature=0.9,\n",
        "                                max_new_tokens=512,\n",
        "                                return_references=return_references)\n",
        "  if context_items == None:\n",
        "    return answer\n",
        "  else:\n",
        "    context = \"\\n\".join([\n",
        "f\"\"\"{index+1}. src: http://localhost:3000/pdfs/{item[\"pdf_name\"]}#page={item[\"page_number\"]}.\n",
        "PageNumber: **{item[\"page_number\"]}**.\n",
        "> \"{item[\"sentence_chunk\"]}\"\n",
        "\n",
        "*****\n",
        "\n",
        "\"\"\" for index, item in enumerate(context_items)])\n",
        "    result = answer + \"\\n## References:\\n\" + context\n",
        "    return result  # Return both the answer and the return_answer\n",
        "\n",
        "\n",
        "demo = gr.ChatInterface(question,\n",
        "                        additional_inputs=[\n",
        "                            gr.Checkbox(label=\"Return References\", interactive=True)\n",
        "                        ]\n",
        "                        )\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "demo.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The context does not provide any information about how often infants should be breastfed, so I cannot answer this query from the provided context.\n",
            "## References:\n",
            "1. src: http://localhost:3000/pdfs/357998-prospects-for-using-artificial-intellige-6e337f58.pdf#5.\n",
            "\n",
            "PageNumber: **5**.\n",
            "> \"ISSN: 2776-1010    Volume 2, Issue 6, June, 2021   297     f: (x, x ’) between objects from X (x, x’ ε X, f ε Y). The quality of identifying relationships is checked by some metric selected based on the problem being solved. Unsupervised learning is used to solve the following types of problems: 1. The task of clustering. 2. Search for association rules. 3. Reducing the dimension of the data.\"\n",
            "\n",
            "*****\n",
            "\n",
            "\n",
            "1. src: http://localhost:3000/pdfs/357998-prospects-for-using-artificial-intellige-6e337f58.pdf#3.\n",
            "\n",
            "PageNumber: **3**.\n",
            "> \"The process is performed within the recommended life cycle, allowing you to structure data processing and analysis projects. This life cycle represents the milestones that are typically completed by projects, often iteratively: 1. Commercial aspect. 2. Obtaining and analyzing data. 3. Simulation 4. Deployment 5.\"\n",
            "\n",
            "*****\n",
            "\n",
            "\n",
            "1. src: http://localhost:3000/pdfs/357998-prospects-for-using-artificial-intellige-6e337f58.pdf#4.\n",
            "\n",
            "PageNumber: **4**.\n",
            "> \"If the assumptions about the decision criteria were made correctly, then as the training sample grows, the probability of an adequate prediction should increase, otherwise it is necessary to change the hypothesis about the criteria. Formally, the formulation of the unsupervised learning problem can be described as follows. Let X be a set of data - descriptions of some objects. It is necessary to find a set Y consisting of interconnections\"\n",
            "\n",
            "*****\n",
            "\n",
            "\n",
            "1. src: http://localhost:3000/pdfs/357998-prospects-for-using-artificial-intellige-6e337f58.pdf#5.\n",
            "\n",
            "PageNumber: **5**.\n",
            "> \"4. Data visualization. To a certain extent, each of the last three tasks is a derivative of the first or its particular case. Let us consider in more detail the formulations of these tasks. The task of searching for association rules means identifying in the feature descriptions of objects (source data) such sets and values of features that are especially often (not by chance often) found in the source data. If we draw an analogy with the first task, then each rule in this case can be represented as a cluster. The task of reducing the dimension of data is as follows. There is a large (much larger) volume of feature descriptions of objects.\"\n",
            "\n",
            "*****\n",
            "\n",
            "\n",
            "1. src: http://localhost:3000/pdfs/357998-prospects-for-using-artificial-intellige-6e337f58.pdf#4.\n",
            "\n",
            "PageNumber: **4**.\n",
            "> \"ISSN: 2776-1010    Volume 2, Issue 6, June, 2021   296      Fig.1. The life cycle of the data processing and analysis process  METHODS OF TRAINING AND ASSESSMENT OF ITS QUALITY As mentioned above, the main characteristic of systems developed using machine learning methods is the ability to learn. Depending on the types of problems to be solved, various algorithms are used to implement this key feature. Within the framework of this article, we will consider the type of unsupervised learning, and also define the classes of problems that are suitable for this type. Initially, the structure of the network is not defined. The learning process is as follows: a specific copy of a document from the reference sample is fed to the input, for which the corresponding category is fixed at the output - as a result, the structure of the neural network is flashed. Starting from a certain step of learning (formation of the network structure), it can already begin to predict the result (in our case, whether the document should be assigned to one category or another).\"\n",
            "\n",
            "*****\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "context = \"\\n\".join([\n",
        "f\"\"\"1. src: http://localhost:3000/pdfs/{item[\"pdf_name\"]}#{item[\"page_number\"]}.\n",
        "\n",
        "PageNumber: **{item[\"page_number\"]}**.\n",
        "> \"{item[\"sentence_chunk\"]}\"\n",
        "\n",
        "*****\n",
        "\n",
        "\"\"\" for item in context_items])\n",
        "result = answer + \"\\n## References:\\n\" + context\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
