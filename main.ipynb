{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8N1ZTVYl06v"
   },
   "source": [
    "## Requirements and setup\n",
    "\n",
    "* Local NVIDIA GPU (I used a NVIDIA RTX 4090 on a Windows 11 machine) or Google Colab with access to a GPU.\n",
    "* Environment setup (see [setup details on GitHub](https://github.com/mrdbourke/simple-local-rag/?tab=readme-ov-file#setup)).\n",
    "* Data source (for example, a PDF).\n",
    "* Internet connection (to download the models, but once you have them, it'll run offline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IB-1Zkd-l06v"
   },
   "outputs": [],
   "source": [
    "# Perform Google Colab installs (if running in Google Colab)\n",
    "import os\n",
    "\n",
    "if \"COLAB_GPU\" in os.environ:\n",
    "    print(\"[INFO] Running in Google Colab, installing requirements.\")\n",
    "    !pip install -U torch # requires torch 2.1.1+ (for efficient sdpa implementation)\n",
    "    !pip install PyMuPDF # for reading PDFs with Python\n",
    "    !pip install tqdm # for progress bars\n",
    "    !pip install sentence-transformers # for embedding models\n",
    "    !pip install accelerate # for quantization model loading\n",
    "    !pip install bitsandbytes # for quantizing models (less storage space)\n",
    "    !pip install flash-attn --no-build-isolation # for faster attention mechanism = faster LLM inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeBms9dWl06w"
   },
   "source": [
    "## 1. Document/Text Processing and Embedding Creation\n",
    "\n",
    "Ingredients:\n",
    "* PDF document of choice.\n",
    "* Embedding model of choice.\n",
    "\n",
    "Steps:\n",
    "1. Import PDF document.\n",
    "2. Process text for embedding (e.g. split into chunks of sentences).\n",
    "3. Embed text chunks with embedding model.\n",
    "4. Save embeddings to file for later use (embeddings will store on file for many years or until you lose your hard drive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZzYVFeKl06w"
   },
   "source": [
    "### Import PDF Document\n",
    "\n",
    "This will work with many other kinds of documents.\n",
    "\n",
    "However, we'll start with PDF since many people have PDFs.\n",
    "\n",
    "But just keep in mind, text files, email chains, support documentation, articles and more can also work.\n",
    "\n",
    "We're going to pretend we're nutrition students at the University of Hawai'i, reading through the open-source PDF textbook [*Human Nutrition: 2020 Edition*](https://pressbooks.oer.hawaii.edu/humannutrition2/).\n",
    "\n",
    "There are several libraries to open PDFs with Python but I found that [PyMuPDF](https://github.com/pymupdf/pymupdf) works quite well in many cases.\n",
    "\n",
    "First we'll download the PDF if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YBGE8j95l06w",
    "outputId": "b04233c3-8a6c-4fe2-9d5c-30285c691354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiltipdfs\\Hilti Malaysia - Terms and Conditions 2019.pdf\n",
      "Hiltipdfs\\Hilti-Submittal-Package-OSHA-1926.1153.pdf\n",
      "Hiltipdfs\\Hilti_BindingCorporateRules.pdf\n",
      "Hiltipdfs\\Hilti_GB_2020_en_pdf.pdf\n",
      "Hiltipdfs\\Technical-information-ASSET-DOC-LOC-10908813.pdf\n"
     ]
    }
   ],
   "source": [
    "# Download PDF file\n",
    "#import os\n",
    "#import requests\n",
    "#\n",
    "## Get PDF document\n",
    "#file_path = \"human-nutrition-text.pdf\"\n",
    "#\n",
    "## Download PDF if it doesn't already exist\n",
    "#if not os.path.exists(file_path):\n",
    "#  print(\"File doesn't exist, downloading...\")\n",
    "#\n",
    "#  # The URL of the PDF you want to download\n",
    "#  url = \"https://pressbooks.oer.hawaii.edu/humannutrition2/open/download?type=pdf\"\n",
    "#\n",
    "#  # The local filename to save the downloaded file\n",
    "#  filename = file_path\n",
    "#\n",
    "#  # Send a GET request to the URL\n",
    "#  response = requests.get(url)\n",
    "#\n",
    "#  # Check if the request was successful\n",
    "#  if response.status_code == 200:\n",
    "#      # Open a file in binary write mode and save the content to it\n",
    "#      with open(filename, \"wb\") as file:\n",
    "#          file.write(response.content)\n",
    "#      print(f\"The file has been downloaded and saved as {filename}\")\n",
    "#  else:\n",
    "#      print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "#else:\n",
    "#  print(f\"File {file_path} exists.\")\n",
    "import os\n",
    "\n",
    "choice = \"pdf\"\n",
    "\n",
    "if choice == \"pdf\":\n",
    "    folder_path = 'Hiltipdfs' # replace with the path to your folder\n",
    "    file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        print(file_path)\n",
    "elif choice == \"slides\":\n",
    "    folder_path = 'Slides' # replace with the path to your folder\n",
    "    file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.pptx')]\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pBQjhIgl06x"
   },
   "source": [
    "PDF acquired!\n",
    "\n",
    "We can import the pages of our PDF to text by first defining the PDF path and then opening and reading it with PyMuPDF (`import fitz`).\n",
    "\n",
    "We'll write a small helper function to preprocess the text as it gets read. Note that not all text will be read in the same so keep this in mind for when you prepare your text.\n",
    "\n",
    "We'll save each page to a dictionary and then append that dictionary to a list for ease of use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "357da8cd990d4ec494ca9bb7110a0b47"
     ]
    },
    "id": "4scku8g1l06x",
    "outputId": "b02a2752-cd4b-47cc-caa9-9c1030ecf34a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 427.99it/s]\n",
      "5it [00:00, 357.14it/s]\n",
      "19it [00:00, 327.59it/s]\n",
      "45it [00:00, 177.16it/s]\n",
      "1it [00:00, 166.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': 1,\n",
       "  'pdf_name': 'Hilti Malaysia - Terms and Conditions 2019.pdf',\n",
       "  'page_char_count': 2282,\n",
       "  'page_word_count': 451,\n",
       "  'page_sentence_count_raw': 11,\n",
       "  'page_token_count': 570.5,\n",
       "  'text': 'Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | Sime Darby Brunsfield Tower  No. 2 | Jalan PJU 1A/7A  Oasis Square I Oasis Damansara  47301 Petaling Jaya I Selangor I Malaysia  Toll Free 1800 880 985 | F +603 7848 7399 | www.hilti.com.my  HILTI (MALAYSIA) SDN. BHD.  TERMS AND CONDITIONS      1.   GENERAL    1.1   In these conditions the following words have the meanings shown:     \"Buyer\"   means the person, firm or company purchasing Goods       \"Company\" means Hilti (Malaysia) Sdn Bhd or one of its associated or subsidiary  companies as the case may be       \"Contract\"  means the agreement between the Company and the Buyer for the  purchase of Goods from the Company by the Buyer        \"Contracts\" includes all agreements between the Company and the Buyer for the  purchase of Goods from the Company by the Buyer        \"Goods\"  means the goods and services supplied by the Company and  purchased by the Buyer on the terms of the Contract     “Saleable means those unused items in original packaging, Condition” defect-free  and in unbroken quantities    1.2   Unless agreed otherwise, these conditions shall be incorporated in all Contracts of  the Company to sell Goods and shall be the entire conditions under which the sale  takes place. All other terms, conditions or other representations are excluded from  the Contracts between the Buyer and the Company including any terms and  conditions which the Buyer may purport to apply under any order for Goods.    1.3   These conditions shall prevail unless expressly varied in writing and signed by a  Director on behalf of the Company.    1.4   No statement, description, information, warranty, condition or recommendation  contained in any catalogue, price list, advertisement or communication or made  verbally by any of the agents or employees of the Company shall be construed to  vary in any way any of the conditions under this Contract unless otherwise agreed in  accordance with Clause 1.3 above.    1.5   Any written quotation, estimate and/or advertised price for the Goods shall be an  invitation to treat and no binding contract shall be created by placing an order on the  Company’s website or otherwise until the Company has acknowledged the order to  the Buyer either verbally or in writing as appropriate.'},\n",
       " {'page_number': 2,\n",
       "  'pdf_name': 'Hilti Malaysia - Terms and Conditions 2019.pdf',\n",
       "  'page_char_count': 2776,\n",
       "  'page_word_count': 562,\n",
       "  'page_sentence_count_raw': 18,\n",
       "  'page_token_count': 694.0,\n",
       "  'text': \"Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | Sime Darby Brunsfield Tower  No. 2 | Jalan PJU 1A/7A  Oasis Square I Oasis Damansara  47301 Petaling Jaya I Selangor I Malaysia  Toll Free 1800 880 985 | F +603 7848 7399 | www.hilti.com.my  2.   PRICE    2.1   Subject to Clause 2.2 below, the price payable for Goods shall, unless otherwise  stated by the Company in writing and agreed on its behalf, be the price list of the  Company current at the date of dispatch and in the case of an order for delivery by  installments the price payable for each installment shall be the Company's current  price list at the date of the dispatch of each installment.    2.2   Unless otherwise agreed, the Company's prices may be subject to variation to take  account of variations in wages, materials or other costs since the date of the  Company's quotation (or if no quotation is issued) the Buyer's order. The Company  accordingly reserves the right to adjust on reasonable basis (reasonable objection by  the Buyer not unreasonable withheld) the invoice price payable by the amount of any  increase or decrease in such costs after the price is quoted via notice in writing to the  Buyer and the invoice so adjusted shall be payable as if it were the original Contract  price.    2.3   All prices are exclusive of Goods and Services Tax. The Buyer shall be liable for all  and any local taxes or charges as appropriate.    2.4   The Buyer agrees that section 39(3) of the Sale of Goods Act 1957 (Act 32) (“the  Act”) shall not apply to Goods sent by the Company.    2.5   The Company shall be entitled to invoice the Buyer by post, facsimile or email for the  price of the Goods in Ringgit Malaysia or such other currency as the Company shall  agree in writing.    2.6   The Company has the right to invoice the Buyer for the cost of any packaging,  transportation of the Goods or any additional costs resulting from any other alteration  made by the Buyer on or at the time of delivery or upon notification by the Company  that the Goods are awaiting collection. Any such additional costs may be invoiced by  the Company in Ringgit Malaysia or such other currency as the Company shall agree  in writing.      3.   FUEL SURCHARGE/ CARRIAGE AND INSURANCE    3.1   The cost of fuel surcharge to the Buyer's premises in Malaysia shall be in accordance  with the charges pre-agreed between the Buyer and the Company.    3.2   The cost of carriage and insurance of the Goods to the Buyer’s premises in Malaysia  shall be in accordance with the charges laid out in the Company’s current price list.    3.3   In all other cases the price of the Goods shall be exclusive of carriage and insurance  to the Buyer's premises.    3.4   Export orders shall be charged Free On Board (port of Malaysia).\"},\n",
       " {'page_number': 3,\n",
       "  'pdf_name': 'Hilti Malaysia - Terms and Conditions 2019.pdf',\n",
       "  'page_char_count': 2728,\n",
       "  'page_word_count': 558,\n",
       "  'page_sentence_count_raw': 16,\n",
       "  'page_token_count': 682.0,\n",
       "  'text': \"Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | Sime Darby Brunsfield Tower  No. 2 | Jalan PJU 1A/7A  Oasis Square I Oasis Damansara  47301 Petaling Jaya I Selangor I Malaysia  Toll Free 1800 880 985 | F +603 7848 7399 | www.hilti.com.my  4.   ADDITIONAL COSTS      The Buyer agrees to pay for any loss or extra costs above the quoted price for the  Goods which are directly or indirectly incurred by the Company through the Buyer's  instructions or lack of instruction or through failure or delay in taking delivery or  through any act or default on the part of the Buyer, its servants or agents.      5.   TERMS OF PAYMENT    5.1   All payments due under any Contract are due and payable within thirty (30) days from  the date of the invoice issued to the Buyer.  The Buyer shall not be entitled to exercise  any set off, lien or any other similar right or claim.    5.2   If the Goods are delivered in installments, the Company shall be entitled to invoice  each installment as and when delivery thereof has been made and payment shall be  due in accordance with Clause 5.1 above in respect of each invoice.    5.3   Any failure by the Buyer to either pay any due installment in accordance with this  Contract or failure to give delivery instructions in respect of any Goods shall cause  the whole of the price for Goods already manufactured at the time of such a default,  to become due forthwith without any notice    5.4   Prompt payment shall be a condition precedent to future deliveries of the Goods due  under any Contract.    5.5   Without prejudice to any other rights it may have, the Company is entitled to charge  and to be paid interest at 2% per month above the then current base rate of HSBC  Bank Malaysia Berhad on any overdue payment of the price of the Goods or the price  of any installments thereof.      6.   DELIVERY    6.1   The period for delivery shall be the period within which the Goods are intended to be  despatched from the Company's premises and shall be calculated from the date of  the receipt by the Company of the Buyer's order or the date of receipt of all necessary  information to enable the Company to manufacture or procure the manufacture of the  Goods whichever shall be the later and the Buyer shall take delivery of the Goods  within such period. If no period is stipulated by the Company, then delivery will be  such time after receipt of instructions as the Company thinks reasonable.    6.2   All times or dates given for delivery of the Goods are given in good faith but without  any responsibility on the part of the Company. Time of delivery shall not be of the  essence of any Contract nor shall the Company be under any liability for any delay  beyond the Company's control.\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requires !pip install PyMuPDF, see: https://github.com/pymupdf/pymupdf\n",
    "import fitz # (pymupdf, found this is better than pypdf for our use case, note: licence is AGPL-3.0, keep that in mind if you want to use any code commercially)\n",
    "from tqdm.auto import tqdm # for progress bars, requires !pip install tqdm\n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    \"\"\"Performs minor formatting on text.\"\"\"\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip() # note: this might be different for each doc (best to experiment)\n",
    "\n",
    "    # Other potential text formatting functions can go here\n",
    "    return cleaned_text\n",
    "\n",
    "# Open PDF and get lines/pages\n",
    "# Note: this only focuses on text, rather than images/figures etc\n",
    "def open_and_read_pdf(file_path: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Opens a PDF file, reads its text content page by page, and collects statistics.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The file path to the PDF document to be opened and read.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dictionaries, each containing the page number\n",
    "        (adjusted), character count, word count, sentence count, token count, and the extracted text\n",
    "        for each page.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(file_path)  # open a document\n",
    "    pdf_name = os.path.basename(file_path)\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(doc)):  # iterate the document pages\n",
    "        text = page.get_text()  # get plain text encoded as UTF-8\n",
    "        text = text_formatter(text)\n",
    "        pages_and_texts.append({\"page_number\": page_number + 1, \n",
    "                                \"pdf_name\": pdf_name,\n",
    "                                \"page_char_count\": len(text),\n",
    "                                \"page_word_count\": len(text.split(\" \")),\n",
    "                                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "                                \"page_token_count\": len(text) / 4,  # 1 token = ~4 chars, see: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
    "                                \"text\": text})\n",
    "    return pages_and_texts\n",
    "\n",
    "\n",
    "pages_and_texts = []\n",
    "for file_path in file_paths:\n",
    "    pages_and_texts.extend(open_and_read_pdf(file_path=file_path))\n",
    "pages_and_texts[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lts3_uJ3l06x"
   },
   "source": [
    "Now let's get a random sample of the pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OtKr1pQul06x",
    "outputId": "9002ee73-521b-4425-d929-bc294858bc2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 10,\n",
       "  'pdf_name': 'Hilti Malaysia - Terms and Conditions 2019.pdf',\n",
       "  'page_char_count': 2450,\n",
       "  'page_word_count': 484,\n",
       "  'page_sentence_count_raw': 17,\n",
       "  'page_token_count': 612.5,\n",
       "  'text': 'Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | Sime Darby Brunsfield Tower  No. 2 | Jalan PJU 1A/7A  Oasis Square I Oasis Damansara  47301 Petaling Jaya I Selangor I Malaysia  Toll Free 1800 880 985 | F +603 7848 7399 | www.hilti.com.my  packaging, design, trade name that is similar or identical to the Company’s intellectual  property.    In case of breach of the aforesaid terms, the Company shall be entitled to institute  legal proceedings against the Buyer for all losses and damages suffered as a result  thereof on full indemnity basis.    14.   FORCE MAJEURE      The Company shall be entitled to delay or cancel delivery or to reduce the amount of  the Goods delivered if it is prevented from, hindered or delayed in manufacturing,  obtaining or delivering the Goods by normal route or means of delivery through any  circumstances beyond its control including, but not limited to, strikes, lock-outs and  other industrial actions, riots, acts of God, flood, lightning, revolution, acts of  terrorism, accidents, war, fire, reduction in or unavailability of power at manufacturing  plant, breakdown of plant or machinery or shortage or unavailability of or failures of  supplies of power, fuel, transport, equipment and raw materials which adversely  affect Hilti’s supply chain or breakdown of plant or machinery.      15.   WAIVER      The waiver by the Company of any right or the failure by the Company to exercise  any right or to insist on the strict performance of any provision of this Contract shall  not operate as a waiver of, or preclude any further exercise or enforcement of any  other right or provision of this Contract.      16.   SEVERABILITY    15.1   Each provision of this Contract is severable and distinct from the others. The parties  intend that every such provision shall be and remain valid and enforceable to the  fullest extent permitted by law. If in any particular case any of these conditions shall  be held to be invalid or shall not apply to this Contract, the other conditions shall  continue  in  full  force  and  effect.      17.   ASSIGNMENT      The Buyer may not assign, sub-contract or in any way dispose of its rights or  obligations under this Contract without the prior written consent of the Company.      18.   NOTICES    18.1   Any notice required to be served under this Contract shall be served on the Company  at its registered office in Malaysia or such other address as the Company may from'},\n",
       " {'page_number': 9,\n",
       "  'pdf_name': 'Hilti Malaysia - Terms and Conditions 2019.pdf',\n",
       "  'page_char_count': 2627,\n",
       "  'page_word_count': 509,\n",
       "  'page_sentence_count_raw': 10,\n",
       "  'page_token_count': 656.75,\n",
       "  'text': \"Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | Sime Darby Brunsfield Tower  No. 2 | Jalan PJU 1A/7A  Oasis Square I Oasis Damansara  47301 Petaling Jaya I Selangor I Malaysia  Toll Free 1800 880 985 | F +603 7848 7399 | www.hilti.com.my  12.5   The Company makes no representation or warranty that the use of the Goods does  not infringe the rights of any third party and the Company accepts no liability in this  respect.      13.   DEFAULT OR INSOLVENCY OF BUYER    13.1   In the event that:    13.1.1  the Buyer shall be in breach of any of its obligations under the Contract;    13.1.2  any distress or execution shall be levied on the Buyer's property or assets; or    13.1.3  if the Buyer (an individual or partnership) shall make or offer to make any voluntary  arrangement or composition with its creditors or become bankrupt or if any  bankruptcy petition be presented against him;    13.1.4  (if the Buyer is a company) has an administrative receiver or administrator appointed  or makes a voluntary arrangement with its creditors or commences to be wound up;  or    13.1.5  otherwise if the Buyer fails to pays its debts as and when they fall due; or    13.1.6  such equivalent event in Clauses 13.1.1 to Clause 13.1.5 occurs to the Buyer in its  local jurisdiction; the Company at its discretion and without prejudice to any other  right or claim may by notice in writing forthwith determine wholly or in part the  Contract and any and all of the other Contracts between the Company and the Buyer  and may (without prejudice to the Company's rights subsequently to determine the  Contract for the same cause should it so decide) by notice in writing suspend further  delivery of the Goods and recover possession of any Goods not paid for.    13A.  INTELLECTUAL PROPERTY    The Buyer undertakes not to, whether by itself, its proprietor/partners, servants or any  of them or otherwise howsoever, order, export, import, offer for sale or supply, sell,  supply, distribute or otherwise deal with the Goods or any other goods under the brand  names(s) or trade mark(s) owned or used by the Company or the Company’s supplier  which are not supplied by or through the Company or which are imported through  parallel trade or which are faked products.     The Buyer shall fully co-operate with the Company with a view to stopping any  infringement of any intellectual property rights (including, but not limited to trade mark  rights) of the Company in the Goods.     The Buyer acknowledges and accepts that the Company retains all intellectual  property belonging to the Company or the Company‘s affiliates or any branding,\"},\n",
       " {'page_number': 5,\n",
       "  'pdf_name': 'Hilti_BindingCorporateRules.pdf',\n",
       "  'page_char_count': 5559,\n",
       "  'page_word_count': 924,\n",
       "  'page_sentence_count_raw': 23,\n",
       "  'page_token_count': 1389.75,\n",
       "  'text': 'www.hilti.group 5 4. TRAINING PROGRAM FOR HILTI\\t EMPLOYEES Employees have permanent or regular access to and pro- cess Personal Data during the performance of their daily  activities at Hilti. Therefore, to raise awareness within all  departments, Hilti has taken measures for employees to  better understand how to carry out their work duties gen- erally, but also depending on their area of work in accor- dance with data protection practices. 5.\\t APPLICABLE DATA PROTECTION\\t PRINCIPLES FOR THE PROCESSING OF\\t\\t PERSONAL DATA Hilti is determined to apply the data protection principles  defined in the EEA to Personal Data worldwide. Such level  of protection is enforced by Hilti to guarantee a proper  processing of Personal Data, ensuring key elements such  as the processing of Personal Data in accordance with  the minimisation principle, data quality or default security  practices.  Hilti has established an action plan to prevent and mitigate  any Personal Data Breach and where applicable, to inform  Data Subjects or the Supervisory Authorities. Hilti enforces data protection principles, as explained in  these BCR, irrespective of the applicable data protection  law, unless it is providing more stringent requirements than  those set up in the BCR. All of these principles are promoted  and implemented within Hilti by means of data protection  by Design and by Default policies and trainings in order to  ensure overall Personal Data governance. a. Transparency, fairness, and lawfulness\\t principles The principle of fairness and transparency requires that  any information and communication relating to the   processing of Personal Data is easily accessible and easy  to understand, as well as drafted in a clear and plain   language. Hilti will only process personal data in a   lawfully, fairly, and transparent manner.  The principle of lawfulness means that the data processing  is taking place according to a defined legal basis.  To ensure the application of these three main principles, Hilti  has put in place various measures, these include: •\\t Transparency measures for the processing (as detailed under BCR Section 6). Definition of the legal basis for each processing activity. •\\t The applicable legal basis can either be:\\t - Consent of the Data Subject\\t - Contractual relationship or pre-contractual relationship with the Data Subject\\t - Hilti’s legal obligations\\t - \\t The protection of vital interests of the Data Subject as well as of another natural person or, where applicable\\t - \\t The legitimate interests (by conducting a balance of interest’s assessment with Data Subjects’ rights, freedoms, and expectations) pursued by the Controller or by a Third-Party, except where such interests are overridden by the interests or fundamental rights and  freedoms of the Data Subject which require protection  of Personal Data, in particular where the Data Subject  is a child The processing of special categories of Personal Data is  lawful only where, in addition to the legal bases listed above,  one of the following exemptions applies: •\\t Explicit consent of the Data Subject •\\t Processing is necessary for the purposes of carrying out the obligations and exercising specific rights of the Controller or of the Data Subject in the field of em-  ployment and social security and social protection law •\\t \\t Processing is necessary to protect the vital interests of the Data Subject or of another natural person where the Data Subject is physically or legally incapable of giving consent •\\t Processing relates to Personal Data which are manifestly made public by the Data Subject •\\t \\t Processing is necessary for the establishment, exercise or defence of legal claims or whenever courts are acting in their judicial capacity •\\t \\t Processing is necessary for reasons of public interest in the area of public health, such as protecting against serious cross-border threats to health or ensuring high standards of quality and safety of health care and of medicinal products or medical devices, on the basis of Union or Member State law which provides for suitable and specific measures to safeguard the rights and freedoms of the Data Subject, in particular professional secrecy In order to make sure that there is no oversight, Hilti  has put in place tools (see BCR Section 7) and will inform  Data Subjects on the applicable legal basis along with the  information Data Subjects are entitled to (see BCR Section 6). b. Purpose limitation This principle means Personal Data is collected for  specified, explicit and legitimate purposes and not further  processed in a manner that is incompatible with those  purposes. Hilti ensures that Personal Data are processed only to fulfil  its specific, clear, and legitimate purposes. Data Subjects  are informed of such purposes which are defined before  collecting Personal Data (see BCR Section 6). Personal Data will not be further processed in a manner  which is deemed incompatible with the defined purposes. Hilti will only process Personal Data for a new purpose if and  insofar as it has obtained consent from the Data Subject.  However, such consent collection is not carried out where  the new purpose for processing can be reasonably expected  from Data Subjects. To determine whether a processing activity can be done for  another purpose which is compatible with the initial purpose  for which Personal Data is collected, Hilti takes into account: •\\t Any link between the purposes for which Personal Data have been collected and the purposes for the intended further processing'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.sample(pages_and_texts, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBF_nevfl06y"
   },
   "source": [
    "### Get some stats on the text\n",
    "\n",
    "Let's perform a rough exploratory data analysis (EDA) to get an idea of the size of the texts (e.g. character counts, word counts etc) we're working with.\n",
    "\n",
    "The different sizes of texts will be a good indicator into how we should split our texts.\n",
    "\n",
    "Many embedding models have limits on the size of texts they can ingest, for example, the [`sentence-transformers`](https://www.sbert.net/docs/pretrained_models.html) model [`all-mpnet-base-v2`](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) has an input size of 384 tokens.\n",
    "\n",
    "This means that the model has been trained in ingest and turn into embeddings texts with 384 tokens (1 token ~= 4 characters ~= 0.75 words).\n",
    "\n",
    "Texts over 384 tokens which are encoded by this model will be auotmatically reduced to 384 tokens in length, potentially losing some information.\n",
    "\n",
    "We'll discuss this more in the embedding section.\n",
    "\n",
    "For now, let's turn our list of dictionaries into a DataFrame and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FHlCczGEl06y",
    "outputId": "53ed0141-ee5b-4f06-a494-264d291d3e82"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
       "      <td>2282</td>\n",
       "      <td>451</td>\n",
       "      <td>11</td>\n",
       "      <td>570.50</td>\n",
       "      <td>Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
       "      <td>2776</td>\n",
       "      <td>562</td>\n",
       "      <td>18</td>\n",
       "      <td>694.00</td>\n",
       "      <td>Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
       "      <td>2728</td>\n",
       "      <td>558</td>\n",
       "      <td>16</td>\n",
       "      <td>682.00</td>\n",
       "      <td>Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
       "      <td>2867</td>\n",
       "      <td>595</td>\n",
       "      <td>14</td>\n",
       "      <td>716.75</td>\n",
       "      <td>Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
       "      <td>2938</td>\n",
       "      <td>572</td>\n",
       "      <td>16</td>\n",
       "      <td>734.50</td>\n",
       "      <td>Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                        pdf_name  \\\n",
       "0            1  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
       "1            2  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
       "2            3  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
       "3            4  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
       "4            5  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
       "\n",
       "   page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "0             2282              451                       11   \n",
       "1             2776              562                       18   \n",
       "2             2728              558                       16   \n",
       "3             2867              595                       14   \n",
       "4             2938              572                       16   \n",
       "\n",
       "   page_token_count                                               text  \n",
       "0            570.50  Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...  \n",
       "1            694.00  Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...  \n",
       "2            682.00  Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...  \n",
       "3            716.75  Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...  \n",
       "4            734.50  Hilti Malaysia Sdn. Bhd. (157721-A)  F-5-A | S...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "E309vNgjl06y",
    "outputId": "aadb5639-f30b-43bc-c27f-663bbbd658dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>82.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>82.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.09</td>\n",
       "      <td>2346.77</td>\n",
       "      <td>409.88</td>\n",
       "      <td>12.72</td>\n",
       "      <td>586.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.84</td>\n",
       "      <td>1861.12</td>\n",
       "      <td>318.34</td>\n",
       "      <td>10.33</td>\n",
       "      <td>465.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.25</td>\n",
       "      <td>982.00</td>\n",
       "      <td>162.25</td>\n",
       "      <td>6.00</td>\n",
       "      <td>245.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.00</td>\n",
       "      <td>1802.50</td>\n",
       "      <td>301.50</td>\n",
       "      <td>9.00</td>\n",
       "      <td>450.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.75</td>\n",
       "      <td>3003.25</td>\n",
       "      <td>577.25</td>\n",
       "      <td>18.75</td>\n",
       "      <td>750.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.00</td>\n",
       "      <td>7394.00</td>\n",
       "      <td>1307.00</td>\n",
       "      <td>47.00</td>\n",
       "      <td>1848.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count        82.00            82.00            82.00                    82.00   \n",
       "mean         16.09          2346.77           409.88                    12.72   \n",
       "std          12.84          1861.12           318.34                    10.33   \n",
       "min           1.00             0.00             1.00                     1.00   \n",
       "25%           5.25           982.00           162.25                     6.00   \n",
       "50%          12.00          1802.50           301.50                     9.00   \n",
       "75%          24.75          3003.25           577.25                    18.75   \n",
       "max          45.00          7394.00          1307.00                    47.00   \n",
       "\n",
       "       page_token_count  \n",
       "count             82.00  \n",
       "mean             586.69  \n",
       "std              465.28  \n",
       "min                0.00  \n",
       "25%              245.50  \n",
       "50%              450.62  \n",
       "75%              750.81  \n",
       "max             1848.50  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stats\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDaFCDlsl06y"
   },
   "source": [
    "Okay, looks like our average token count per page is 287.\n",
    "\n",
    "For this particular use case, it means we could embed an average whole page with the `all-mpnet-base-v2` model (this model has an input capacity of 384)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSjT4dTfl06y"
   },
   "source": [
    "### Further text processing (splitting pages into sentences)\n",
    "\n",
    "The ideal way of processing text before embedding it is still an active area of research.\n",
    "\n",
    "A simple method I've found helpful is to break the text into chunks of sentences.\n",
    "\n",
    "As in, chunk a page of text into groups of 5, 7, 10 or more sentences (these values are not set in stone and can be explored).\n",
    "\n",
    "But we want to follow the workflow of:\n",
    "\n",
    "`Ingest text -> split it into groups/chunks -> embed the groups/chunks -> use the embeddings`\n",
    "\n",
    "Some options for splitting text into sentences:\n",
    "\n",
    "1. Split into sentences with simple rules (e.g. split on \". \" with `text = text.split(\". \")`, like we did above).\n",
    "2. Split into sentences with a natural language processing (NLP) library such as [spaCy](https://spacy.io/) or [nltk](https://www.nltk.org/).\n",
    "\n",
    "Why split into sentences?\n",
    "\n",
    "* Easier to handle than larger pages of text (especially if pages are densely filled with text).\n",
    "* Can get specific and find out which group of sentences were used to help within a RAG pipeline.\n",
    "\n",
    "> **Resource:** See [spaCy install instructions](https://spacy.io/usage).\n",
    "\n",
    "Let's use spaCy to break our text into sentences since it's likely a bit more robust than just using `text.split(\". \")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7kheP2iyl06y",
    "outputId": "d537727e-6dc6-4cd1-962c-48bfaadb2d66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is a sentence., This another sentence.]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English # see https://spacy.io/usage for install instructions\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "# Add a sentencizer pipeline, see https://spacy.io/api/sentencizer/\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# Create a document instance as an example\n",
    "doc = nlp(\"This is a sentence. This another sentence.\")\n",
    "assert len(list(doc.sents)) == 2\n",
    "\n",
    "# Access the sentences of the document\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKvNeALwl06y"
   },
   "source": [
    "We don't necessarily need to use spaCy, however, it's an open-source library designed to do NLP tasks like this at scale.\n",
    "\n",
    "So let's run our small sentencizing pipeline on our pages of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "177454fcc3344b03b750eda50269c27f"
     ]
    },
    "id": "Qs-KNV6Rl06z",
    "outputId": "dac6a0b0-ab05-4fe6-d8a2-af4c1f8c9f64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 257.05it/s]\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "\n",
    "    # Make sure all sentences are strings\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "\n",
    "    # Count the sentences\n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZOG_TGOgl06z",
    "outputId": "25946c61-eecf-4c8c-ab3b-9c1a2b488327"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 8,\n",
       "  'pdf_name': 'Hilti_GB_2020_en_pdf.pdf',\n",
       "  'page_char_count': 1408,\n",
       "  'page_word_count': 238,\n",
       "  'page_sentence_count_raw': 10,\n",
       "  'page_token_count': 352.0,\n",
       "  'text': '“We passionately create enthusiastic customers  and build a better future.” This mission statement  is based on the conviction that we grow together  with the people around us – with our customers,  employees and partners. Personal exchanges and  the aspiration to never rest, only to improve, has  put us in the position to provide world-class prod- ucts, systems, software and services. Our strategic objective is sustainable value cre- ation through market leadership and differentia- tion – market leadership in terms of relative market  share, and differentiation via the direct sale of our  portfolio. We will continue to follow the successful course of  recent years in 2020 and beyond, while emphasiz- ing four proven strategic fields of activity. We are  investing in continuous innovation. In doing so we  will continue to rely on the core of our corporate  strategy: the direct access to and partnership with  our customers in the construction industry. Op- erational excellence in all processes ensures our  customers’ success and firms up our leading posi- tion on the market. A high-performing global team  with roughly 30,000 employees works diligently  every day to achieve these targets. WE PASSIONATELY  CREATE ENTHUSI- ASTIC CUSTOMERS  AND BUILD A  BETTER FUTURE In our Sustainability Report, you can learn more  about how Hilti is building a better future. 2020 Hilti Company Report 10–11',\n",
       "  'sentences': ['“We passionately create enthusiastic customers  and build a better future.”',\n",
       "   'This mission statement  is based on the conviction that we grow together  with the people around us – with our customers,  employees and partners.',\n",
       "   'Personal exchanges and  the aspiration to never rest, only to improve, has  put us in the position to provide world-class prod- ucts, systems, software and services.',\n",
       "   'Our strategic objective is sustainable value cre- ation through market leadership and differentia- tion – market leadership in terms of relative market  share, and differentiation via the direct sale of our  portfolio.',\n",
       "   'We will continue to follow the successful course of  recent years in 2020 and beyond, while emphasiz- ing four proven strategic fields of activity.',\n",
       "   'We are  investing in continuous innovation.',\n",
       "   'In doing so we  will continue to rely on the core of our corporate  strategy: the direct access to and partnership with  our customers in the construction industry.',\n",
       "   'Op- erational excellence in all processes ensures our  customers’ success and firms up our leading posi- tion on the market.',\n",
       "   'A high-performing global team  with roughly 30,000 employees works diligently  every day to achieve these targets.',\n",
       "   'WE PASSIONATELY  CREATE ENTHUSI- ASTIC CUSTOMERS  AND BUILD A  BETTER FUTURE In our Sustainability Report, you can learn more  about how Hilti is building a better future.',\n",
       "   '2020 Hilti Company Report 10–11'],\n",
       "  'page_sentence_count_spacy': 11}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect an example\n",
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSQ5uTAYl06z"
   },
   "source": [
    "Wonderful!\n",
    "\n",
    "Now let's turn out list of dictionaries into a DataFrame and get some stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DM4vLozil06z",
    "outputId": "f9d581ba-afec-4e2d-ca4b-8b35ec6da15b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>82.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>82.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.09</td>\n",
       "      <td>2346.77</td>\n",
       "      <td>409.88</td>\n",
       "      <td>12.72</td>\n",
       "      <td>586.69</td>\n",
       "      <td>12.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.84</td>\n",
       "      <td>1861.12</td>\n",
       "      <td>318.34</td>\n",
       "      <td>10.33</td>\n",
       "      <td>465.28</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.25</td>\n",
       "      <td>982.00</td>\n",
       "      <td>162.25</td>\n",
       "      <td>6.00</td>\n",
       "      <td>245.50</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.00</td>\n",
       "      <td>1802.50</td>\n",
       "      <td>301.50</td>\n",
       "      <td>9.00</td>\n",
       "      <td>450.62</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.75</td>\n",
       "      <td>3003.25</td>\n",
       "      <td>577.25</td>\n",
       "      <td>18.75</td>\n",
       "      <td>750.81</td>\n",
       "      <td>18.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.00</td>\n",
       "      <td>7394.00</td>\n",
       "      <td>1307.00</td>\n",
       "      <td>47.00</td>\n",
       "      <td>1848.50</td>\n",
       "      <td>45.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count        82.00            82.00            82.00                    82.00   \n",
       "mean         16.09          2346.77           409.88                    12.72   \n",
       "std          12.84          1861.12           318.34                    10.33   \n",
       "min           1.00             0.00             1.00                     1.00   \n",
       "25%           5.25           982.00           162.25                     6.00   \n",
       "50%          12.00          1802.50           301.50                     9.00   \n",
       "75%          24.75          3003.25           577.25                    18.75   \n",
       "max          45.00          7394.00          1307.00                    47.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  \n",
       "count             82.00                      82.00  \n",
       "mean             586.69                      12.43  \n",
       "std              465.28                       9.99  \n",
       "min                0.00                       0.00  \n",
       "25%              245.50                       6.00  \n",
       "50%              450.62                       9.00  \n",
       "75%              750.81                      18.75  \n",
       "max             1848.50                      45.00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-gtBTyml06z"
   },
   "source": [
    "For our set of text, it looks like our raw sentence count (e.g. splitting on `\". \"`) is quite close to what spaCy came up with.\n",
    "\n",
    "Now we've got our text split into sentences, how about we gorup those sentences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rlKmn80l06z"
   },
   "source": [
    "### Chunking our sentences together\n",
    "\n",
    "Let's take a step to break down our list of sentences/text into smaller chunks.\n",
    "\n",
    "As you might've guessed, this process is referred to as **chunking**.\n",
    "\n",
    "Why do we do this?\n",
    "\n",
    "1. Easier to manage similar sized chunks of text.\n",
    "2. Don't overload the embedding models capacity for tokens (e.g. if an embedding model has a capacity of 384 tokens, there could be information loss if you try to embed a sequence of 400+ tokens).\n",
    "3. Our LLM context window (the amount of tokens an LLM can take in) may be limited and requires compute power so we want to make sure we're using it as well as possible.\n",
    "\n",
    "Something to note is that there are many different ways emerging for creating chunks of information/text.\n",
    "\n",
    "For now, we're going to keep it simple and break our pages of sentences into groups of 10 (this number is arbitrary and can be changed, I just picked it because it seemed to line up well with our embedding model capacity of 384).\n",
    "\n",
    "On average each of our pages has 10 sentences.\n",
    "\n",
    "And an average total of 287 tokens per page.\n",
    "\n",
    "So our groups of 10 sentences will also be ~287 tokens long.\n",
    "\n",
    "This gives us plenty of room for the text to embedded by our `all-mpnet-base-v2` model (it has a capacity of 384 tokens).\n",
    "\n",
    "To split our groups of sentences into chunks of 10 or less, let's create a function which accepts a list as input and recursively breaks into down into sublists of a specified size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "d37ee16f5d1f4f46bb489856aaeaa677"
     ]
    },
    "id": "4iyR-CzNl06z",
    "outputId": "cb031f45-1db2-4b79-8553-49cc26b1b2bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define split size to turn groups of sentences into chunks\n",
    "num_sentence_chunk_size = 6\n",
    "\n",
    "# Create a function that recursively splits a list into desired sizes\n",
    "def split_list(input_list: list,\n",
    "               slice_size: int) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Splits the input_list into sublists of size slice_size (or as close as possible).\n",
    "\n",
    "    For example, a list of 17 sentences would be split into two lists of [[10], [7]]\n",
    "    \"\"\"\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "# Loop through pages and texts and split sentences into chunks\n",
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                         slice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "iUnGrtuSl06z",
    "outputId": "9558eb0b-5d81-4011-d5ce-dc29ae67bfe9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 14,\n",
       "  'pdf_name': 'Hilti_BindingCorporateRules.pdf',\n",
       "  'page_char_count': 5045,\n",
       "  'page_word_count': 848,\n",
       "  'page_sentence_count_raw': 22,\n",
       "  'page_token_count': 1261.25,\n",
       "  'text': 'www.hilti.group 14 best efforts to obtain the right to waive this prohibition in  order to communicate as much information as it can and as  soon as possible and be able to demonstrate that it did so.  If despite using its best efforts a Hilti Entity or Hilti HQ is  unable to notify the competent Supervisory Authority, it  undertakes to at least annually provide the Supervisory   Authority with information related to the requests received  by the national security state bodies or authorities and at  least the information listed above. The transfers of Personal Data from a Hilti Entity to national  security state bodies or authorities shall never be done in  an excessive, disproportionate, and indiscriminate manner  which would go beyond what is necessary in a democratic  society. c. Relationship between national laws and BCR Hilti bound by the BCR implements very protective measures for the rights and freedoms of Data Subjects. The application of the highest data protection standards in all Hilti internal processes ensures that it develops its products and services in accordance with the principles set out in the BCR. Nevertheless, and in accordance with the provisions of   European data protection laws and regulations, there are  situations in which national laws and regulations may be  more protective than the principles set forth and applied  in the Hilti BCR or provide specific requirements. Where  such local legislation requires a higher level of protection  for Personal Data than those set forth in the BCR, it will take  precedence over the BCR. Where local legislation requires a  lower level of protection for Personal Data, the BCR will take  precedence. Such protective or additional provisions are assessed with  respect to the principles relating to the processing of Per- sonal Data.  As a consequence, any Hilti Entity undertakes to comply  with the applicable national or local provisions whenever  these have additional and protective effects for Data Sub- jects or provide specific provisions applicable in the country.  Each Hilti Entity is responsible for taking additional actions  where deemed necessary in accordance with the national  laws in which it is based. Such provisions include: •\\t Right for Data Subjects to decide on the fate of their Personal Data after death including exercising of rights by heirs or designated persons •\\t Processing of Personal Data in the field of employment, social security, or social protection law •\\t Application of Data Subject rights •\\t Conducting Data Protection Impact Assessments (DPIA) in accordance with specific local requirements •\\t Exercise DPO tasks in accordance with local requirements (e.g., secrecy obligation) Hilti Entities communicate to and provide the Regional Data  Protection Officer, the Global Team and CPO with a copy of  such local or national laws and applicable requirements. Where a Hilti Entity is taking actions, such as developing  local processes or policies, it must provide the Global Team  and CPO with a copy and details of such procedure or policy.  It has to be noted that such national laws do not override  BCR and are to be considered to be additional requirements  applicable in the country or state where the Hilti Entity is  based. In the event such new provisions are applicable in  one or several Hilti Entities, the latter must act and train  the relevant employees to ensure that such provisions are  implemented in existing processes or create new ones. Furthermore, there are cases where Hilti needs to assess  national requirements which may affect Personal Data  transfers.  In such case, Hilti will conduct an assessment prior to any  transfer of Personal Data to a third country.  This analysis is conducted by the exporting entity with  assistance of the importing entity to determine the con- ditions and circumstances by which the transfer can take  place, such as the categories of Personal Data transferred,  categories of Data Subjects, type of processing activity,  dataflow, evaluation of TOM’s as well as legislations, stat- utes, court orders or mandatory standards applicable to  such transfer of Personal Data and/or such importing entity.  Where the result of such assessment prevents the exporting  entity from fulfilling its obligations under the herewith BCR,  such exporting entity will either: •\\t Not start any transfer of Personal Data to the importing entity or •\\t For existing processing activities, discontinue any transfer of Personal Data or •\\t Implement supplementary measures in order to maintain the highest data protection standards as defined in the herewith BCR and in accordance with the latest EEA/ EDPB guidance In the event no supplementary measures can be put in  place, the exporting entity will either not start the processing  activity or suspend any transfer of Personal Data.  The assessment can take the form of a DPIA with specific  information relating to the supplementary measures. The  documentation is made available to Supervisory Authorities  upon request.',\n",
       "  'sentences': ['www.hilti.group 14 best efforts to obtain the right to waive this prohibition in  order to communicate as much information as it can and as  soon as possible and be able to demonstrate that it did so.',\n",
       "   ' If despite using its best efforts a Hilti Entity or Hilti HQ is  unable to notify the competent Supervisory Authority, it  undertakes to at least annually provide the Supervisory   Authority with information related to the requests received  by the national security state bodies or authorities and at  least the information listed above.',\n",
       "   'The transfers of Personal Data from a Hilti Entity to national  security state bodies or authorities shall never be done in  an excessive, disproportionate, and indiscriminate manner  which would go beyond what is necessary in a democratic  society.',\n",
       "   'c. Relationship between national laws and BCR Hilti bound by the BCR implements very protective measures for the rights and freedoms of Data Subjects.',\n",
       "   'The application of the highest data protection standards in all Hilti internal processes ensures that it develops its products and services in accordance with the principles set out in the BCR.',\n",
       "   'Nevertheless, and in accordance with the provisions of   European data protection laws and regulations, there are  situations in which national laws and regulations may be  more protective than the principles set forth and applied  in the Hilti BCR or provide specific requirements.',\n",
       "   'Where  such local legislation requires a higher level of protection  for Personal Data than those set forth in the BCR, it will take  precedence over the BCR.',\n",
       "   'Where local legislation requires a  lower level of protection for Personal Data, the BCR will take  precedence.',\n",
       "   'Such protective or additional provisions are assessed with  respect to the principles relating to the processing of Per- sonal Data.',\n",
       "   ' As a consequence, any Hilti Entity undertakes to comply  with the applicable national or local provisions whenever  these have additional and protective effects for Data Sub- jects or provide specific provisions applicable in the country.',\n",
       "   ' Each Hilti Entity is responsible for taking additional actions  where deemed necessary in accordance with the national  laws in which it is based.',\n",
       "   'Such provisions include: •\\t Right for Data Subjects to decide on the fate of their Personal Data after death including exercising of rights by heirs or designated persons •\\t Processing of Personal Data in the field of employment, social security, or social protection law •\\t Application of Data Subject rights •\\t Conducting Data Protection Impact Assessments (DPIA) in accordance with specific local requirements •\\t Exercise DPO tasks in accordance with local requirements (e.g., secrecy obligation) Hilti Entities communicate to and provide the Regional Data  Protection Officer, the Global Team and CPO with a copy of  such local or national laws and applicable requirements.',\n",
       "   'Where a Hilti Entity is taking actions, such as developing  local processes or policies, it must provide the Global Team  and CPO with a copy and details of such procedure or policy.',\n",
       "   ' It has to be noted that such national laws do not override  BCR and are to be considered to be additional requirements  applicable in the country or state where the Hilti Entity is  based.',\n",
       "   'In the event such new provisions are applicable in  one or several Hilti Entities, the latter must act and train  the relevant employees to ensure that such provisions are  implemented in existing processes or create new ones.',\n",
       "   'Furthermore, there are cases where Hilti needs to assess  national requirements which may affect Personal Data  transfers.',\n",
       "   ' In such case, Hilti will conduct an assessment prior to any  transfer of Personal Data to a third country.',\n",
       "   ' This analysis is conducted by the exporting entity with  assistance of the importing entity to determine the con- ditions and circumstances by which the transfer can take  place, such as the categories of Personal Data transferred,  categories of Data Subjects, type of processing activity,  dataflow, evaluation of TOM’s as well as legislations, stat- utes, court orders or mandatory standards applicable to  such transfer of Personal Data and/or such importing entity.',\n",
       "   ' Where the result of such assessment prevents the exporting  entity from fulfilling its obligations under the herewith BCR,  such exporting entity will either: •\\t Not start any transfer of Personal Data to the importing entity or •\\t For existing processing activities, discontinue any transfer of Personal Data or •\\t Implement supplementary measures in order to maintain the highest data protection standards as defined in the herewith BCR and in accordance with the latest EEA/ EDPB guidance In the event no supplementary measures can be put in  place, the exporting entity will either not start the processing  activity or suspend any transfer of Personal Data.',\n",
       "   ' The assessment can take the form of a DPIA with specific  information relating to the supplementary measures.',\n",
       "   'The  documentation is made available to Supervisory Authorities  upon request.'],\n",
       "  'page_sentence_count_spacy': 21,\n",
       "  'sentence_chunks': [['www.hilti.group 14 best efforts to obtain the right to waive this prohibition in  order to communicate as much information as it can and as  soon as possible and be able to demonstrate that it did so.',\n",
       "    ' If despite using its best efforts a Hilti Entity or Hilti HQ is  unable to notify the competent Supervisory Authority, it  undertakes to at least annually provide the Supervisory   Authority with information related to the requests received  by the national security state bodies or authorities and at  least the information listed above.',\n",
       "    'The transfers of Personal Data from a Hilti Entity to national  security state bodies or authorities shall never be done in  an excessive, disproportionate, and indiscriminate manner  which would go beyond what is necessary in a democratic  society.',\n",
       "    'c. Relationship between national laws and BCR Hilti bound by the BCR implements very protective measures for the rights and freedoms of Data Subjects.',\n",
       "    'The application of the highest data protection standards in all Hilti internal processes ensures that it develops its products and services in accordance with the principles set out in the BCR.',\n",
       "    'Nevertheless, and in accordance with the provisions of   European data protection laws and regulations, there are  situations in which national laws and regulations may be  more protective than the principles set forth and applied  in the Hilti BCR or provide specific requirements.'],\n",
       "   ['Where  such local legislation requires a higher level of protection  for Personal Data than those set forth in the BCR, it will take  precedence over the BCR.',\n",
       "    'Where local legislation requires a  lower level of protection for Personal Data, the BCR will take  precedence.',\n",
       "    'Such protective or additional provisions are assessed with  respect to the principles relating to the processing of Per- sonal Data.',\n",
       "    ' As a consequence, any Hilti Entity undertakes to comply  with the applicable national or local provisions whenever  these have additional and protective effects for Data Sub- jects or provide specific provisions applicable in the country.',\n",
       "    ' Each Hilti Entity is responsible for taking additional actions  where deemed necessary in accordance with the national  laws in which it is based.',\n",
       "    'Such provisions include: •\\t Right for Data Subjects to decide on the fate of their Personal Data after death including exercising of rights by heirs or designated persons •\\t Processing of Personal Data in the field of employment, social security, or social protection law •\\t Application of Data Subject rights •\\t Conducting Data Protection Impact Assessments (DPIA) in accordance with specific local requirements •\\t Exercise DPO tasks in accordance with local requirements (e.g., secrecy obligation) Hilti Entities communicate to and provide the Regional Data  Protection Officer, the Global Team and CPO with a copy of  such local or national laws and applicable requirements.'],\n",
       "   ['Where a Hilti Entity is taking actions, such as developing  local processes or policies, it must provide the Global Team  and CPO with a copy and details of such procedure or policy.',\n",
       "    ' It has to be noted that such national laws do not override  BCR and are to be considered to be additional requirements  applicable in the country or state where the Hilti Entity is  based.',\n",
       "    'In the event such new provisions are applicable in  one or several Hilti Entities, the latter must act and train  the relevant employees to ensure that such provisions are  implemented in existing processes or create new ones.',\n",
       "    'Furthermore, there are cases where Hilti needs to assess  national requirements which may affect Personal Data  transfers.',\n",
       "    ' In such case, Hilti will conduct an assessment prior to any  transfer of Personal Data to a third country.',\n",
       "    ' This analysis is conducted by the exporting entity with  assistance of the importing entity to determine the con- ditions and circumstances by which the transfer can take  place, such as the categories of Personal Data transferred,  categories of Data Subjects, type of processing activity,  dataflow, evaluation of TOM’s as well as legislations, stat- utes, court orders or mandatory standards applicable to  such transfer of Personal Data and/or such importing entity.'],\n",
       "   [' Where the result of such assessment prevents the exporting  entity from fulfilling its obligations under the herewith BCR,  such exporting entity will either: •\\t Not start any transfer of Personal Data to the importing entity or •\\t For existing processing activities, discontinue any transfer of Personal Data or •\\t Implement supplementary measures in order to maintain the highest data protection standards as defined in the herewith BCR and in accordance with the latest EEA/ EDPB guidance In the event no supplementary measures can be put in  place, the exporting entity will either not start the processing  activity or suspend any transfer of Personal Data.',\n",
       "    ' The assessment can take the form of a DPIA with specific  information relating to the supplementary measures.',\n",
       "    'The  documentation is made available to Supervisory Authorities  upon request.']],\n",
       "  'num_chunks': 4}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample an example from the group (note: many samples have only 1 chunk as they have <=10 sentences total)\n",
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "uUJfBxsCl06z",
    "outputId": "d54abd3b-6f66-4e2a-d906-930a2c2b648f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>82.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>82.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.09</td>\n",
       "      <td>2346.77</td>\n",
       "      <td>409.88</td>\n",
       "      <td>12.72</td>\n",
       "      <td>586.69</td>\n",
       "      <td>12.43</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.84</td>\n",
       "      <td>1861.12</td>\n",
       "      <td>318.34</td>\n",
       "      <td>10.33</td>\n",
       "      <td>465.28</td>\n",
       "      <td>9.99</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.25</td>\n",
       "      <td>982.00</td>\n",
       "      <td>162.25</td>\n",
       "      <td>6.00</td>\n",
       "      <td>245.50</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.00</td>\n",
       "      <td>1802.50</td>\n",
       "      <td>301.50</td>\n",
       "      <td>9.00</td>\n",
       "      <td>450.62</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.75</td>\n",
       "      <td>3003.25</td>\n",
       "      <td>577.25</td>\n",
       "      <td>18.75</td>\n",
       "      <td>750.81</td>\n",
       "      <td>18.75</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.00</td>\n",
       "      <td>7394.00</td>\n",
       "      <td>1307.00</td>\n",
       "      <td>47.00</td>\n",
       "      <td>1848.50</td>\n",
       "      <td>45.00</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count        82.00            82.00            82.00                    82.00   \n",
       "mean         16.09          2346.77           409.88                    12.72   \n",
       "std          12.84          1861.12           318.34                    10.33   \n",
       "min           1.00             0.00             1.00                     1.00   \n",
       "25%           5.25           982.00           162.25                     6.00   \n",
       "50%          12.00          1802.50           301.50                     9.00   \n",
       "75%          24.75          3003.25           577.25                    18.75   \n",
       "max          45.00          7394.00          1307.00                    47.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  num_chunks  \n",
       "count             82.00                      82.00       82.00  \n",
       "mean             586.69                      12.43        2.57  \n",
       "std              465.28                       9.99        1.61  \n",
       "min                0.00                       0.00        0.00  \n",
       "25%              245.50                       6.00        1.00  \n",
       "50%              450.62                       9.00        2.00  \n",
       "75%              750.81                      18.75        3.75  \n",
       "max             1848.50                      45.00        8.00  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame to get stats\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2Ba1GK_l06z"
   },
   "source": [
    "Note how the average number of chunks is around 1.5, this is expected since many of our pages only contain an average of 10 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_tMmt53l060"
   },
   "source": [
    "### Splitting each chunk into its own item\n",
    "\n",
    "We'd like to embed each chunk of sentences into its own numerical representation.\n",
    "\n",
    "So to keep things clean, let's create a new list of dictionaries each containing a single chunk of sentences with relative information such as page number as well statistics about each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "94ccc5effc2e470d9c910dd607cbcaa9"
     ]
    },
    "id": "2rvkcj3cl060",
    "outputId": "113dd853-9ad0-407e-f97a-3287812d4ceb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:00<00:00, 16359.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Split each chunk into its own item\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_and_texts):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "        chunk_dict[\"pdf_name\"] = item[\"pdf_name\"]\n",
    "\n",
    "        # Join the sentences together into a paragraph-like structure, aka a chunk (so they are a single string)\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full-stop/capital letter combo\n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "\n",
    "        # Get stats about the chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n",
    "\n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "# How many chunks do we have?\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "ev-TlPkhl060",
    "outputId": "039e9445-4e02-43d1-8d36-b1c898a6a8b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 29,\n",
       "  'pdf_name': 'Hilti_GB_2020_en_pdf.pdf',\n",
       "  'sentence_chunk': 'employees worldwide (2019: 30,006) nationalities in the global team (2019: 127) nationalities at headquarters (2019: 63) of team members worldwide are women (2019: 25%) of team leaders worldwide are women (2019: 21%) 29,549 63 25.5% 21.5% After Lindsay Ophus started her career as a process manager at Hilti in the USA in 2015, it was soon clear she was on the path to a long career with the company. “My goal is to create added value for the company with my team.”Hilti’s approach is to match people with roles they enjoy and are suited for, both laterally and upward. The result is a resilient, high-performing global team. Team members are encouraged to talk frequently with their leaders about their development, whether it be for their current role or one in the future. Lindsay was set to become an area sales manager, but one discussion helped her consider another path. “',\n",
       "  'chunk_char_count': 879,\n",
       "  'chunk_word_count': 150,\n",
       "  'chunk_token_count': 219.75}]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View a random sample\n",
    "random.sample(pages_and_chunks, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9st3NR5l060"
   },
   "source": [
    "Excellent!\n",
    "\n",
    "Now we've broken our whole textbook into chunks of 10 sentences or less as well as the page number they came from.\n",
    "\n",
    "This means we could reference a chunk of text and know its source.\n",
    "\n",
    "Let's get some stats about our chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "0SMiTGfPl060",
    "outputId": "2115b1ee-d252-4b16-d95b-1f75a89cc2d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>211.00</td>\n",
       "      <td>211.00</td>\n",
       "      <td>211.00</td>\n",
       "      <td>211.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.57</td>\n",
       "      <td>896.91</td>\n",
       "      <td>144.79</td>\n",
       "      <td>224.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.13</td>\n",
       "      <td>622.14</td>\n",
       "      <td>99.57</td>\n",
       "      <td>155.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.00</td>\n",
       "      <td>489.00</td>\n",
       "      <td>80.50</td>\n",
       "      <td>122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.00</td>\n",
       "      <td>825.00</td>\n",
       "      <td>133.00</td>\n",
       "      <td>206.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.50</td>\n",
       "      <td>1118.00</td>\n",
       "      <td>188.50</td>\n",
       "      <td>279.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44.00</td>\n",
       "      <td>4348.00</td>\n",
       "      <td>696.00</td>\n",
       "      <td>1087.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count       211.00            211.00            211.00             211.00\n",
       "mean         15.57            896.91            144.79             224.23\n",
       "std          12.13            622.14             99.57             155.54\n",
       "min           1.00             19.00              3.00               4.75\n",
       "25%           6.00            489.00             80.50             122.25\n",
       "50%          12.00            825.00            133.00             206.25\n",
       "75%          23.50           1118.00            188.50             279.50\n",
       "max          44.00           4348.00            696.00            1087.00"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stats about our chunks\n",
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPJvIqJil060"
   },
   "source": [
    "Hmm looks like some of our chunks have quite a low token count.\n",
    "\n",
    "How about we check for samples with less than 30 tokens (about the length of a sentence) and see if they are worth keeping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "id": "vg3CSkVtl064",
    "outputId": "7aeae3df-1739-4bb8-c64c-4ce693e70b4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk token count: 4.75 | Text: COMPANY REPORT 2020\n",
      "Chunk token count: 15.0 | Text: COMPLEX GEOMETRY MADE SIMPLE 2020 Hilti Company Report 34–35\n",
      "Chunk token count: 15.25 | Text: Buyer shall further ensure that it does not intend to use any\n",
      "Chunk token count: 11.0 | Text: TRACEABILITY 2020 Hilti Company Report 14–15\n",
      "Chunk token count: 7.75 | Text: 2020 Hilti Company Report 18–19\n"
     ]
    }
   ],
   "source": [
    "# Show random chunks with under 30 tokens in length\n",
    "min_token_length = 30\n",
    "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(5).iterrows():\n",
    "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6K_2hxMXl064"
   },
   "source": [
    "Looks like many of these are headers and footers of different pages.\n",
    "\n",
    "They don't seem to offer too much information.\n",
    "\n",
    "Let's filter our DataFrame/list of dictionaries to only include chunks with over 30 tokens in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "gALsc54zl064",
    "outputId": "913a1319-0e1d-479d-89ca-f1bdf05bdd8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 1,\n",
       "  'pdf_name': 'Hilti Malaysia - Terms and Conditions 2019.pdf',\n",
       "  'sentence_chunk': 'Hilti Malaysia Sdn. Bhd. (157721-A) F-5-A | Sime Darby Brunsfield Tower No.2 | Jalan PJU 1A/7A Oasis Square I Oasis Damansara 47301 Petaling Jaya I Selangor I Malaysia Toll Free 1800 880 985 | F +603 7848 7399 | www.hilti.com.my HILTI (MALAYSIA) SDN. BHD. TERMS AND CONDITIONS   1.',\n",
       "  'chunk_char_count': 281,\n",
       "  'chunk_word_count': 50,\n",
       "  'chunk_token_count': 70.25},\n",
       " {'page_number': 1,\n",
       "  'pdf_name': 'Hilti Malaysia - Terms and Conditions 2019.pdf',\n",
       "  'sentence_chunk': 'GENERAL  1.1  In these conditions the following words have the meanings shown:   \"Buyer\"  means the person, firm or company purchasing Goods    \"Company\" means Hilti (Malaysia) Sdn Bhd or one of its associated or subsidiary companies as the case may be    \"Contract\" means the agreement between the Company and the Buyer for the purchase of Goods from the Company by the Buyer    \"Contracts\" includes all agreements between the Company and the Buyer for the purchase of Goods from the Company by the Buyer    \"Goods\" means the goods and services supplied by the Company and purchased by the Buyer on the terms of the Contract   “Saleable means those unused items in original packaging, Condition” defect-free and in unbroken quantities  1.2  Unless agreed otherwise, these conditions shall be incorporated in all Contracts of the Company to sell Goods and shall be the entire conditions under which the sale takes place. All other terms, conditions or other representations are excluded from the Contracts between the Buyer and the Company including any terms and conditions which the Buyer may purport to apply under any order for Goods.  1.3  These conditions shall prevail unless expressly varied in writing and signed by a Director on behalf of the Company.  1.4  No statement, description, information, warranty, condition or recommendation contained in any catalogue, price list, advertisement or communication or made verbally by any of the agents or employees of the Company shall be construed to vary in any way any of the conditions under this Contract unless otherwise agreed in accordance with Clause 1.3 above.  1.5  Any written quotation, estimate and/or advertised price for the Goods shall be an invitation to treat and no binding contract shall be created by placing an order on the Company’s website or otherwise until the Company has acknowledged the order to the Buyer either verbally or in writing as appropriate.',\n",
       "  'chunk_char_count': 1934,\n",
       "  'chunk_word_count': 335,\n",
       "  'chunk_token_count': 483.5}]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
    "pages_and_chunks_over_min_token_len[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7cpvLexl065"
   },
   "source": [
    "Smaller chunks filtered!\n",
    "\n",
    "Time to embed our chunks of text!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2UiN3nll065"
   },
   "source": [
    "### Embedding our text chunks\n",
    "\n",
    "While humans understand text, machines understand numbers best.\n",
    "\n",
    "An [embedding](https://vickiboykis.com/what_are_embeddings/index.html) is a broad concept.\n",
    "\n",
    "But one of my favourite and simple definitions is \"a useful numerical representation\".\n",
    "\n",
    "The most powerful thing about modern embeddings is that they are *learned* representations.\n",
    "\n",
    "Meaning rather than directly mapping words/tokens/characters to numbers directly (e.g. `{\"a\": 0, \"b\": 1, \"c\": 3...}`), the numerical representation of tokens is learned by going through large corpuses of text and figuring out how different tokens relate to each other.\n",
    "\n",
    "Ideally, embeddings of text will mean that similar meaning texts have similar numerical representation.\n",
    "\n",
    "> **Note:** Most modern NLP models deal with \"tokens\" which can be considered as multiple different sizes and combinations of words and characters rather than always whole words or single characters. For example, the string `\"hello world!\"` gets mapped to the token values `{15339: b'hello', 1917: b' world', 0: b'!'}` using [Byte pair encoding](https://en.wikipedia.org/wiki/Byte_pair_encoding) (or BPE via OpenAI's [`tiktoken`](https://github.com/openai/tiktoken) library). Google has a tokenization library called [SentencePiece](https://github.com/google/sentencepiece).\n",
    "\n",
    "Our goal is to turn each of our chunks into a numerical representation (an embedding vector, where a vector is a sequence of numbers arranged in order).\n",
    "\n",
    "Once our text samples are in embedding vectors, us humans will no longer be able to understand them.\n",
    "\n",
    "However, we don't need to.\n",
    "\n",
    "The embedding vectors are for our computers to understand.\n",
    "\n",
    "We'll use our computers to find patterns in the embeddings and then we can use their text mappings to further our understanding.\n",
    "\n",
    "Enough talking, how about we import a text embedding model and see what an embedding looks like.\n",
    "\n",
    "To do so, we'll use the [`sentence-transformers`](https://www.sbert.net/docs/installation.html) library which contains many pre-trained embedding models.\n",
    "\n",
    "Specifically, we'll get the `all-mpnet-base-v2` model (you can see the model's intended use on the [Hugging Face model card](https://huggingface.co/sentence-transformers/all-mpnet-base-v2#intended-uses))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "Qw8vlf4Dl065",
    "outputId": "e7801c76-ae38-458e-bde4-d89d99689911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The Sentences Transformers library provides an easy and open-source way to create embeddings.\n",
      "Embedding: [-2.07981840e-02  3.03164609e-02 -2.01218035e-02  6.86483681e-02\n",
      " -2.55255606e-02 -8.47685710e-03 -2.07098550e-04 -6.32377341e-02\n",
      "  2.81606205e-02 -3.33353132e-02  3.02635003e-02  5.30720502e-02\n",
      " -5.03526330e-02  2.62288097e-02  3.33314240e-02 -4.51578312e-02\n",
      "  3.63044441e-02 -1.37111905e-03 -1.20171579e-02  1.14946403e-02\n",
      "  5.04510738e-02  4.70856875e-02  2.11913176e-02  5.14607020e-02\n",
      " -2.03746278e-02 -3.58889289e-02 -6.67838729e-04 -2.94393227e-02\n",
      "  4.95859161e-02 -1.05639659e-02 -1.52014159e-02 -1.31756265e-03\n",
      "  4.48197350e-02  1.56023391e-02  8.60379885e-07 -1.21393730e-03\n",
      " -2.37978660e-02 -9.09396331e-04  7.34482659e-03 -2.53930246e-03\n",
      "  5.23370430e-02 -4.68043163e-02  1.66214686e-02  4.71579209e-02\n",
      " -4.15599309e-02  9.01952910e-04  3.60278748e-02  3.42214517e-02\n",
      "  9.68227386e-02  5.94828427e-02 -1.64984632e-02 -3.51249576e-02\n",
      "  5.92517946e-03 -7.07972853e-04 -2.41031181e-02  3.49740833e-02\n",
      " -2.94746663e-02  6.04267884e-03 -9.80643556e-03  2.83217859e-02\n",
      " -1.85376145e-02  3.63213420e-02  1.30293015e-02 -3.71233188e-02\n",
      "  5.27256615e-02 -1.19706523e-02 -7.18082413e-02  1.24431355e-02\n",
      " -6.70565711e-03  7.42154568e-02  1.16357198e-02 -1.74533334e-02\n",
      " -1.82406195e-02 -1.88930407e-02  2.82414667e-02  1.32828988e-02\n",
      " -3.51909660e-02  8.87300353e-04  5.79572432e-02  3.22093219e-02\n",
      " -3.48586636e-03  4.13768701e-02  1.44357840e-02 -3.28044556e-02\n",
      " -9.79081634e-03 -3.16493325e-02  4.23871167e-02 -4.70847189e-02\n",
      " -2.08936967e-02 -1.91249214e-02 -1.22627066e-02  1.01605328e-02\n",
      "  3.91921960e-02 -2.61895861e-02  1.09028351e-02  1.35722952e-02\n",
      " -5.79267070e-02 -3.21500041e-02 -5.75723173e-03 -2.43516378e-02\n",
      "  5.23417220e-02  5.46125602e-03 -2.30995845e-02  2.57176068e-03\n",
      " -6.63346201e-02  3.54126357e-02 -1.03907408e-02  2.25409605e-02\n",
      " -1.84574258e-02 -2.42006201e-02 -4.78365012e-02 -4.79236245e-03\n",
      " -5.34138307e-02  3.01790778e-02 -1.56130847e-02 -5.51476218e-02\n",
      " -3.91874723e-02  5.92152812e-02 -3.47646512e-02  9.68121085e-03\n",
      "  2.13415232e-02  2.30417494e-02  1.91712752e-02  2.77378634e-02\n",
      " -7.73510523e-03  1.04445638e-02 -2.67719887e-02 -2.40199678e-02\n",
      " -1.92289595e-02  3.91499978e-03 -2.54714936e-02  3.61942910e-02\n",
      "  5.12866899e-02 -8.41696188e-03 -3.13829705e-02  1.47483991e-02\n",
      "  2.13939510e-02 -3.84901352e-02  2.01946255e-02  1.20766135e-02\n",
      " -3.12081375e-03  7.84031488e-03  3.30334250e-03 -4.94357236e-02\n",
      "  5.83886877e-02  3.26131145e-03  4.84485971e-03 -4.50681858e-02\n",
      "  2.45682690e-02  3.55428122e-02 -5.32505885e-02  9.21152756e-02\n",
      "  2.04395410e-02 -3.36952135e-02 -6.19803891e-02 -2.11038925e-02\n",
      "  7.82359913e-02  5.11908270e-02  5.93170859e-02 -1.25080012e-04\n",
      "  4.96349074e-02 -1.55722704e-02 -3.35677760e-03  1.82016082e-02\n",
      " -2.73444280e-02 -1.08772079e-02  1.41475983e-02  1.09877335e-02\n",
      "  4.32553468e-03  8.23311657e-02 -9.85385966e-04  7.58791193e-02\n",
      "  9.44997743e-03  2.37687565e-02  1.61928907e-02  6.24994226e-02\n",
      "  4.75921519e-02 -3.92628461e-03  9.07524675e-02  4.49874029e-02\n",
      " -3.47131267e-02  2.14077216e-02 -3.35604474e-02  4.93849814e-02\n",
      "  1.08670639e-02  2.63447277e-02 -3.26089077e-02  8.00303817e-02\n",
      "  9.29763727e-03  7.16573745e-03 -2.79171988e-02 -3.06820981e-02\n",
      "  4.01061308e-03 -4.93906699e-02 -3.13780084e-03  4.00537476e-02\n",
      " -3.97855155e-02  5.48014082e-02  1.36133485e-05 -8.38373527e-02\n",
      " -1.21547431e-02  3.40950638e-02  3.22400429e-03  6.11846671e-02\n",
      "  5.60066774e-02  9.62877832e-03  2.54615992e-02 -4.64168973e-02\n",
      " -3.98900211e-02  7.68132657e-02  2.28408594e-02 -2.26567611e-02\n",
      " -1.91192981e-02 -6.53028190e-02  4.56780829e-02 -4.43653576e-03\n",
      "  1.49631761e-02 -2.15078238e-02  2.74242368e-03  1.90358777e-02\n",
      "  5.91888539e-02 -2.47569326e-02  3.66144963e-02  5.63083738e-02\n",
      " -8.86450429e-03 -1.74324736e-02 -1.03287213e-03  2.47667059e-02\n",
      "  1.30763259e-02  5.04633151e-02 -5.28498506e-03  5.92396967e-02\n",
      "  6.29906952e-02 -4.36783396e-02 -4.97831143e-02  5.56297190e-02\n",
      " -2.44854484e-02 -8.26755166e-02  2.04911027e-02 -1.06446326e-01\n",
      "  6.64841151e-03  2.97303740e-02 -2.36440469e-02 -8.84612091e-03\n",
      "  2.45553791e-03 -3.35234664e-02  7.52212405e-02 -5.89879937e-02\n",
      " -3.67807671e-02  3.41542438e-02  5.41131087e-02 -1.74904522e-02\n",
      "  1.33919986e-02  4.71681915e-02  1.46116996e-02 -2.12310757e-02\n",
      " -6.55338913e-02  1.23857576e-02  2.76074670e-02 -8.02161451e-03\n",
      " -4.59636562e-02 -8.22443329e-03  9.16954037e-03 -1.56398732e-02\n",
      "  7.54615152e-03  1.58314302e-03 -3.03958859e-02 -5.10671102e-02\n",
      "  1.96313486e-02  1.26263257e-02 -1.51736662e-03  2.02890653e-02\n",
      "  1.37817478e-02  1.49110472e-02  2.50766631e-02 -3.62870470e-02\n",
      "  1.08084809e-02  2.74136220e-03  1.81510597e-02  5.39872274e-02\n",
      " -4.74541970e-02 -4.28731181e-02 -2.89914515e-02  2.13234928e-02\n",
      " -3.85161154e-02  6.31922483e-02 -5.77975810e-02  3.77894845e-03\n",
      " -2.54394431e-02 -1.77206981e-04  9.08245239e-03  1.59095209e-02\n",
      "  4.11799178e-02 -3.94368917e-02 -9.64433886e-03  1.30792521e-02\n",
      "  6.87962249e-02  4.32193130e-02  7.54065986e-04  6.77741244e-02\n",
      "  4.93705831e-02 -3.47819761e-03 -1.06054693e-02  6.72493130e-03\n",
      " -1.39062256e-02  4.88276556e-02 -1.05736302e-02  3.50230536e-03\n",
      "  2.90220580e-03  2.40044203e-02  1.20272087e-02 -2.09796689e-02\n",
      " -2.39112377e-02  3.26579511e-02 -1.01323961e-03 -5.92756132e-03\n",
      " -7.40534207e-03  3.63140530e-03 -2.26698723e-02 -2.21242718e-02\n",
      "  3.86995524e-02  1.72321964e-02  3.85921337e-02 -5.04711494e-02\n",
      " -3.42145041e-02 -4.00443226e-02 -3.57910767e-02 -4.62560691e-02\n",
      "  6.70231730e-02 -4.61645983e-03 -3.29679856e-03  2.08444223e-02\n",
      " -5.14252717e-03 -5.00850193e-02  2.22504456e-02  4.66933176e-02\n",
      "  1.36208320e-02  1.77530497e-02  4.28084843e-03 -2.79332325e-02\n",
      " -1.93420909e-02 -3.87860462e-02 -3.09555437e-02 -6.64134100e-02\n",
      " -1.13434084e-02  1.64267365e-02  1.77629720e-02 -2.28224392e-03\n",
      " -3.30088437e-02 -1.36267603e-03 -2.17934120e-02 -2.67508682e-02\n",
      " -1.26375863e-02  1.61867391e-03 -4.95673046e-02  7.85444975e-02\n",
      "  4.10962477e-02  9.65921767e-03 -1.14642996e-02  1.68853870e-03\n",
      "  5.37663847e-02  2.05536513e-03 -4.11201157e-02  1.46329971e-02\n",
      " -3.75564247e-02 -3.35689262e-02  5.19254431e-03 -6.33089021e-02\n",
      "  3.32963765e-02  8.76122527e-03  1.33858388e-03 -3.95748625e-03\n",
      " -1.61677916e-02  8.26746821e-02  4.75944541e-02 -3.43055427e-02\n",
      "  2.50881668e-02 -3.50976139e-02  3.68657745e-02  4.12656739e-03\n",
      "  4.16018069e-02 -1.35181725e-01 -4.76337373e-02 -1.20025529e-02\n",
      " -3.48891877e-02  3.25454623e-02 -2.93574249e-03 -4.85056126e-03\n",
      " -1.04223773e-01  2.78610718e-02  1.41570419e-02  3.94396149e-02\n",
      " -3.88806053e-02 -1.42463734e-02 -5.19984290e-02  8.92738625e-03\n",
      " -1.99771170e-02 -2.51724999e-02 -3.41300145e-02  1.93041172e-02\n",
      " -5.20207547e-02 -6.71999827e-02 -9.46365017e-03 -1.25587336e-03\n",
      " -5.66048436e-02  2.62098219e-02  9.91585571e-03  4.38286774e-02\n",
      "  2.26639677e-03 -3.11896168e-02 -6.25468194e-02 -3.87793034e-02\n",
      " -6.83938935e-02  4.93722409e-02  5.85507751e-02 -4.08730060e-02\n",
      " -1.98638346e-02 -2.12634597e-02  4.98037040e-02 -4.51748073e-02\n",
      " -2.37141475e-02  2.32674684e-02  1.00594819e-01  9.87114850e-03\n",
      " -1.38014387e-02 -5.21041192e-02  9.08209290e-03  1.72427669e-02\n",
      "  5.91432340e-02  2.62336917e-02 -7.04641547e-03 -1.50032062e-02\n",
      " -3.76657792e-03  6.28261594e-03 -5.23982085e-02 -4.96638492e-02\n",
      "  3.06610782e-02 -3.33646848e-03  2.34911554e-02 -8.58830065e-02\n",
      " -4.62449454e-02  5.59701212e-02  3.09052673e-04  2.01728828e-02\n",
      " -2.98060663e-03  1.76645238e-02  1.54669266e-02 -7.41718337e-02\n",
      "  7.34986505e-03 -1.05014602e-02  2.45247278e-02  1.36878826e-02\n",
      " -1.17803421e-02  4.51544002e-02  3.29039432e-02 -3.50394868e-03\n",
      " -2.71315444e-02 -5.27364761e-02 -4.60164584e-02  2.22849883e-02\n",
      "  2.62272116e-02  5.56150032e-03  1.45788854e-02 -2.97145210e-02\n",
      "  3.57042514e-02  2.22534835e-02  3.89617644e-02 -7.92634636e-02\n",
      " -9.01090261e-03  2.19012760e-02 -5.49062761e-03  8.69959779e-03\n",
      "  4.33030613e-02 -2.12631226e-02  1.13292122e-02 -6.33699149e-02\n",
      "  3.63722965e-02  2.67442819e-02 -6.64251521e-02  1.70499533e-02\n",
      " -2.79691909e-02  2.36354652e-03 -1.81953423e-02  1.52955279e-02\n",
      " -8.50431342e-03  1.16648432e-02 -9.75922048e-02 -2.92093270e-02\n",
      " -5.42547293e-02  3.61234695e-02  3.25116403e-02  8.26973747e-03\n",
      " -2.96499929e-04  1.11555904e-02 -3.85188311e-02  2.36161519e-02\n",
      "  9.85922292e-03  5.73998503e-02  4.86060306e-02 -1.37579953e-02\n",
      " -6.19217288e-03  1.11973099e-02 -3.37174796e-02 -1.10515542e-02\n",
      " -7.08333403e-02 -1.01816338e-02 -3.66010927e-02 -1.55561119e-02\n",
      " -2.13109907e-02 -1.02760158e-02 -4.35733683e-02  5.55186495e-02\n",
      " -3.76547985e-02  5.29252365e-02 -3.45224179e-02 -2.43009068e-03\n",
      "  7.25553632e-02  4.45068441e-03  4.71416563e-02 -9.43878666e-03\n",
      " -1.98978242e-02  5.71899489e-02  8.60540196e-02 -5.25058135e-02\n",
      " -1.39550343e-02  1.17373392e-02  1.33974385e-02 -4.73052599e-02\n",
      " -5.41673377e-02  4.62725312e-02 -2.58970633e-02  1.51415495e-02\n",
      "  3.38944606e-02 -3.78255825e-03 -5.76043092e-02 -1.60082299e-02\n",
      "  2.42738444e-02  3.37360166e-02 -1.96821149e-02 -2.53464077e-02\n",
      " -4.75617275e-02 -5.68755828e-02 -2.28193719e-02  3.83186601e-02\n",
      " -1.78331062e-02  1.35963699e-02  7.86014949e-04  9.74011980e-03\n",
      "  3.34298573e-02 -2.60133930e-02 -7.38569582e-03  3.56451087e-02\n",
      " -2.68532522e-02 -7.53624290e-02 -2.66984086e-02 -4.46457603e-33\n",
      " -3.31645943e-02  1.41704325e-02 -3.92909199e-02 -3.46318744e-02\n",
      " -5.88677870e-03 -1.18212290e-02  1.53951310e-02  1.18473852e-02\n",
      "  1.07757663e-02  3.62141132e-02  7.87953008e-03 -2.31845155e-02\n",
      "  1.07623199e-02  1.72346160e-02  9.54187999e-04  2.83640381e-02\n",
      "  2.37420145e-02 -1.48057519e-02  1.24194997e-03  3.52355326e-03\n",
      "  2.33735386e-02  5.58307953e-02  5.38328066e-02 -3.74078713e-02\n",
      " -2.11805273e-02  1.52731925e-04 -7.27785146e-03  5.50558884e-03\n",
      "  3.05824243e-02  4.54633608e-02 -3.35786864e-02  3.16142477e-02\n",
      " -2.56392965e-03  3.96354981e-02 -1.47573240e-02  5.67167252e-02\n",
      " -5.62787652e-02 -5.04599325e-03  3.56154665e-02 -2.76198797e-02\n",
      " -2.32292023e-02 -4.63292748e-02 -3.70919220e-02 -4.23189476e-02\n",
      "  3.70305777e-02  7.88717996e-03  3.85176279e-02  1.74772495e-03\n",
      "  5.62760187e-03  6.18104404e-03 -6.90268874e-02 -9.42969881e-03\n",
      " -7.74677796e-03  1.68349985e-02  1.22767081e-02  2.26406436e-02\n",
      "  1.21009108e-02  1.11743584e-02  1.21538835e-02 -1.16862003e-02\n",
      " -4.41612527e-02  2.30047926e-02  2.20671743e-02 -5.87504953e-02\n",
      " -3.96428443e-02  6.83135390e-02 -3.29947844e-02 -3.66774090e-02\n",
      " -3.53654958e-02  1.76185351e-02  6.95640733e-03  5.92691973e-02\n",
      "  4.12156358e-02  7.98109546e-02 -5.36567299e-03  1.14238337e-02\n",
      " -2.96388622e-02 -1.15411496e-02  2.22811978e-02  7.93186016e-03\n",
      "  2.60356572e-02  1.28211658e-02  1.71346013e-02 -6.90192636e-03\n",
      " -1.07603688e-02  1.35715539e-02 -9.90709756e-04 -6.16075434e-02\n",
      "  4.40513380e-02 -8.26579169e-04 -2.78340969e-02 -1.23619679e-02\n",
      "  1.34629719e-02 -3.85745168e-02  1.08702248e-03  2.18712874e-02\n",
      " -3.32398340e-02  1.84615478e-02 -5.10102604e-03  3.74665074e-02\n",
      " -3.67544964e-03 -2.19246037e-02 -4.96480847e-03 -9.59828775e-03\n",
      "  2.33591199e-02  1.04876449e-02  4.38721851e-02 -1.51424306e-02\n",
      " -6.30309656e-02  8.23258515e-03 -1.09130759e-02 -4.06409539e-02\n",
      " -6.21690750e-02  2.21326146e-02 -2.71434169e-02  4.05539609e-02\n",
      " -8.09452776e-03 -1.76406628e-03  3.01526170e-02 -5.42265410e-03\n",
      " -4.69821393e-02 -1.73768401e-02  4.11631204e-02  3.20635848e-02\n",
      " -2.22943760e-02 -1.58161670e-02 -4.50720899e-02  5.69486916e-02\n",
      "  4.71596271e-02 -5.78058846e-02  1.32475020e-02 -4.71287593e-03\n",
      "  1.66824520e-07  4.81090769e-02  5.03628105e-02  5.45263812e-02\n",
      "  2.07568165e-02 -1.19080720e-02 -6.37493748e-03  5.26369317e-03\n",
      "  7.21948594e-02 -2.21763197e-02  2.20103078e-02 -9.90448403e-04\n",
      " -1.37163131e-02  6.89209998e-03  2.46912483e-02 -1.39462054e-01\n",
      "  2.56978767e-03 -4.64827679e-02 -4.04967554e-02 -6.08555935e-02\n",
      " -1.53212892e-02  1.36129901e-01  9.45035070e-02  4.25741300e-02\n",
      "  4.67131063e-02 -2.30677929e-02 -1.20965950e-02  3.86673324e-02\n",
      "  2.11655442e-03 -2.51473375e-02 -1.15076471e-02 -3.46506387e-02\n",
      " -2.29533762e-02 -6.33849204e-03 -3.05175893e-02 -1.56236673e-02\n",
      "  1.39514348e-02  3.27456451e-04  2.00327300e-03  4.15106211e-03\n",
      " -2.22924836e-02 -3.62589955e-02 -2.36579124e-02 -1.87817775e-02\n",
      " -1.96288936e-02  4.52126078e-02 -8.12568963e-02 -2.14569494e-02\n",
      " -4.41542715e-02 -2.68476363e-02  2.01974325e-02  2.82995310e-03\n",
      " -1.95011161e-02 -3.45331430e-02  2.26913411e-02  3.78325656e-02\n",
      " -1.02543971e-02 -2.19750847e-03 -8.96744579e-02 -4.50030826e-02\n",
      "  8.09701998e-03 -2.05805898e-02 -2.02998295e-02 -2.09922194e-02\n",
      " -1.79405101e-02  5.81897683e-02 -7.63652148e-03  1.50847267e-02\n",
      "  1.78279812e-34  4.86179441e-02  4.22228239e-02  4.71596345e-02\n",
      "  5.89047372e-02  3.99784744e-02 -5.27070910e-02  1.56905893e-02\n",
      " -5.25129260e-04  1.13652255e-02 -6.56410754e-02 -2.20849011e-02]\n",
      "\n",
      "Sentence: Sentences can be embedded one by one or as a list of strings.\n",
      "Embedding: [ 4.31718007e-02 -5.38701080e-02 -3.78044434e-02  4.27235700e-02\n",
      " -2.35409234e-02  3.44861411e-02  2.89587080e-02  1.92817417e-03\n",
      "  2.41732579e-02 -3.17012109e-02  7.32856095e-02  1.25589613e-02\n",
      "  3.64620946e-02 -2.05251761e-02  2.81973928e-02 -6.87329620e-02\n",
      "  4.22230773e-02  9.31726652e-04  3.54035571e-02  1.41787175e-02\n",
      "  7.83995166e-03  2.31179539e-02 -4.84742876e-03  1.07173854e-02\n",
      "  4.39491682e-03  5.47802867e-03 -3.80338691e-02 -3.05487006e-03\n",
      "  5.72234439e-03 -6.78213835e-02 -4.88008037e-02 -1.45032331e-02\n",
      "  6.68006251e-03 -7.17479810e-02  1.64644871e-06  1.07564069e-02\n",
      " -3.60922106e-02 -2.37057209e-02 -5.22791892e-02  3.46110798e-02\n",
      " -5.42172417e-03  1.62611157e-02  1.96564663e-02  2.25395579e-02\n",
      " -2.25997111e-03  4.06342670e-02  8.17157999e-02  2.48179417e-02\n",
      "  5.31884544e-02  7.82715529e-02 -1.91813335e-02 -1.94087438e-02\n",
      " -2.62805410e-02 -2.44083870e-02  5.49405701e-02  1.90319009e-02\n",
      "  1.60811059e-02 -2.68895905e-02 -8.24690517e-03  7.33444020e-02\n",
      "  1.00122979e-02  2.93315668e-02  3.42863565e-03 -2.13270038e-02\n",
      " -1.62446895e-03 -5.56257041e-03 -7.64880106e-02 -5.85450195e-02\n",
      " -2.82272156e-02  7.51851266e-03  7.11226016e-02  1.95453153e-03\n",
      "  5.45926578e-03  3.22314189e-03  5.12800291e-02 -3.54106054e-02\n",
      " -5.03608659e-02  4.70519513e-02  5.15475357e-03  1.52287260e-02\n",
      " -1.06680905e-02  3.16298902e-02 -9.09037888e-03 -4.01326977e-02\n",
      " -4.35236059e-02 -1.94969382e-02  1.65604949e-02 -4.71168682e-02\n",
      " -3.92091498e-02 -3.07756905e-02 -2.94167176e-02 -4.20826226e-02\n",
      "  2.27070227e-03 -2.78329439e-02  1.69421677e-02  7.74499029e-03\n",
      " -5.23741469e-02 -4.50039506e-02  3.83606218e-02 -4.90786880e-02\n",
      "  5.06618768e-02  1.01615218e-02 -1.25022121e-02 -4.64554224e-03\n",
      " -1.54539719e-02  1.58862602e-02  1.18369777e-02 -3.59232761e-02\n",
      " -7.76226074e-02  3.43358591e-02 -2.14709938e-02 -6.86098784e-02\n",
      " -5.46235852e-02  7.83901364e-02 -3.00703067e-02 -3.37550007e-02\n",
      " -4.04999144e-02  4.80514988e-02  9.53904167e-03  2.31399015e-02\n",
      " -8.16115290e-02 -6.51690876e-03  1.54213039e-02  7.04257339e-02\n",
      " -1.25069013e-02 -2.48266533e-02 -1.71329137e-02  6.13109209e-03\n",
      "  5.44412844e-02 -1.40566202e-02 -6.24515954e-03  3.65787558e-02\n",
      "  7.36230165e-02 -6.05683867e-03 -3.61630172e-02 -1.42202561e-03\n",
      "  4.43165563e-02 -3.14516271e-03  3.18768024e-02 -1.30947744e-02\n",
      " -3.69525142e-02 -4.98030614e-03  1.30016624e-03 -2.05213483e-02\n",
      "  2.06277724e-02  5.93871716e-03 -3.07157612e-03 -3.97512913e-02\n",
      "  4.29889672e-02  6.49802238e-02 -6.76022395e-02  5.41655235e-02\n",
      "  1.52560486e-03 -3.72908525e-02 -4.02427129e-02 -2.28771903e-02\n",
      "  1.31769806e-01  4.87875659e-03  1.39470780e-02  4.92435992e-02\n",
      "  2.49219257e-02 -8.76089465e-03 -5.38766291e-03 -2.65595466e-02\n",
      " -1.19766686e-02 -2.32006628e-02 -2.67434102e-02  5.66913281e-03\n",
      "  2.21721679e-02  4.67294343e-02 -5.78486882e-02  8.22120458e-02\n",
      " -3.36836278e-03  8.09646770e-02  1.41423289e-02  1.02393053e-01\n",
      " -5.76835638e-03 -1.15876896e-02  4.90585007e-02  5.87830134e-02\n",
      "  6.50030822e-02  4.74621654e-02 -2.89464146e-02 -1.76582136e-03\n",
      "  3.32561210e-02  2.91198269e-02  6.03811592e-02  3.73523799e-04\n",
      "  1.06575862e-02 -5.96284494e-02 -7.28600994e-02  2.95080412e-02\n",
      "  9.54460911e-03 -2.71541681e-02 -5.63305244e-02  9.66696767e-04\n",
      " -4.77728806e-02  4.67576683e-02  4.87260381e-03 -6.57520071e-02\n",
      " -1.42248748e-02  3.99872735e-02 -1.09798182e-02  7.68942907e-02\n",
      " -4.00003791e-02  2.96826568e-02  2.81303450e-02 -5.55424541e-02\n",
      "  6.31275866e-03  5.00450321e-02  1.89884380e-02  5.38684018e-02\n",
      " -1.95981320e-02  1.08600976e-02  1.64150707e-02  1.44135151e-02\n",
      "  1.71448886e-02  2.17624847e-02 -4.98863384e-02  1.56105757e-02\n",
      "  4.83735558e-03  1.87053774e-02 -3.18550761e-03  2.66863145e-02\n",
      "  5.55552952e-02 -4.88005616e-02 -3.02929040e-02  2.52110418e-02\n",
      "  1.07264603e-02  1.88270379e-02 -1.50688356e-02  3.43831964e-02\n",
      "  4.15124670e-02  1.37788821e-02 -5.54848090e-02  1.43847931e-02\n",
      " -5.88139966e-02 -6.01676144e-02  2.69856136e-02 -5.46130240e-02\n",
      "  8.14634655e-03 -1.17758662e-02  1.57442074e-02  1.43903110e-03\n",
      " -2.64554657e-02 -4.48877178e-02  4.39732783e-02 -1.06166066e-04\n",
      " -2.25905515e-02  3.00296266e-02  1.97440684e-02  7.44073745e-03\n",
      " -1.93790104e-02  8.09795409e-03  4.34860066e-02 -1.08542612e-04\n",
      " -3.77225690e-02  2.67195869e-02 -4.63157631e-02 -1.53403473e-03\n",
      "  8.05308484e-03 -4.30901535e-02 -2.13848688e-02  1.20185306e-02\n",
      "  8.41403008e-03  2.48270016e-03 -3.09566334e-02 -9.05277878e-02\n",
      " -4.76694070e-02  1.22606382e-02 -1.36466958e-02 -2.63654906e-02\n",
      " -7.65549112e-03  8.72373767e-03  2.65724678e-02  8.40078399e-04\n",
      " -5.55932010e-03 -9.29540675e-03  3.19337472e-02  5.94646558e-02\n",
      "  1.83205921e-02 -7.56547004e-02 -5.59389368e-02 -1.20871151e-02\n",
      " -3.16260867e-02  3.62186879e-02  7.53609417e-03 -6.15654252e-02\n",
      " -2.30458863e-02 -3.51674133e-03  1.23332124e-02 -9.67644528e-03\n",
      "  4.96861115e-02 -8.42256844e-02  1.52396271e-02 -1.82445198e-02\n",
      "  7.70462081e-02  9.28718597e-02  4.03726101e-02  1.11732610e-01\n",
      " -1.03270523e-02 -2.54558548e-02  2.13153698e-02 -1.16184074e-03\n",
      "  2.82596983e-03  5.06967008e-02 -3.13697569e-02 -8.14277586e-03\n",
      "  1.38387289e-02  4.66889441e-02  5.09671047e-02  3.77154201e-02\n",
      " -2.94988789e-02  3.60631943e-02 -2.61162082e-03  2.72223901e-04\n",
      " -6.71807155e-02 -6.54026195e-02 -3.43590714e-02  1.91067494e-02\n",
      "  4.13293950e-02 -1.10970549e-02  4.51952629e-02 -5.93564920e-02\n",
      "  1.06963497e-02 -1.82229523e-02 -5.65814339e-02  1.20387254e-02\n",
      "  4.44774888e-02  1.87049452e-02  1.63810030e-02  5.51151186e-02\n",
      " -2.23332327e-02  2.12861858e-02 -1.20339859e-02  3.26752737e-02\n",
      "  1.47003997e-02 -8.16682260e-03  1.12904413e-02 -3.00620552e-02\n",
      " -2.34345235e-02 -2.68646274e-02 -1.28718663e-03 -7.67190158e-02\n",
      "  2.22606980e-03 -5.89483837e-03  2.63103582e-02  2.07129377e-03\n",
      " -6.91151991e-02 -1.43792639e-02  2.68788524e-02 -3.51540148e-02\n",
      " -2.69612353e-02  2.54717050e-03 -6.48881197e-02  3.18727754e-02\n",
      "  1.70126799e-02 -4.54004630e-02 -1.80616081e-02 -1.61116440e-02\n",
      "  5.70773557e-02 -2.78269593e-03 -6.45586029e-02  7.86598250e-02\n",
      "  2.29075700e-02  6.81841653e-03 -9.11741145e-03 -2.27726232e-02\n",
      " -4.76526171e-02  4.88431044e-02 -2.09891368e-02 -2.43693944e-02\n",
      " -5.01211314e-03  6.70254081e-02  6.91367406e-03  2.25843024e-02\n",
      "  2.51125339e-02 -6.92502782e-03  8.59402772e-03  2.38977484e-02\n",
      "  3.29738222e-02 -1.05310559e-01  1.22094331e-02 -1.22263823e-02\n",
      " -5.73768765e-02  1.84311401e-02  2.97158007e-02 -6.09429218e-02\n",
      " -6.55256137e-02  3.55712734e-02  5.64320758e-03  3.34643037e-03\n",
      " -3.59686390e-02 -8.83415621e-03 -6.97895065e-02  6.89779446e-02\n",
      " -4.88215871e-03  2.23995168e-02 -3.16054001e-02 -7.41182221e-03\n",
      "  3.19351442e-02 -5.18788360e-02  2.11601797e-02 -5.03340103e-02\n",
      "  9.10578482e-03  2.13354584e-02  1.66838467e-02  3.49020325e-02\n",
      " -6.38500452e-02 -6.75629638e-03 -1.27405412e-02 -4.63366620e-02\n",
      " -1.14779398e-02  2.08778717e-02  2.44822539e-02  3.66464420e-03\n",
      " -2.86098244e-03  2.29389761e-02  2.13745739e-02 -3.48900519e-02\n",
      " -3.00388020e-02  4.78870533e-02  5.83370402e-02 -9.70497634e-03\n",
      "  1.38234077e-02 -3.27485651e-02 -8.11426376e-04  9.54228174e-03\n",
      "  1.20401615e-02  1.97230522e-02 -4.74872650e-04 -1.39226140e-02\n",
      " -5.21070100e-02 -1.75592508e-02 -5.41698970e-02 -1.17970295e-02\n",
      " -1.71030331e-02 -3.50194871e-02  3.38661484e-02 -6.76587075e-02\n",
      " -2.27606595e-02  1.95606705e-02  5.50249368e-02  1.22029148e-02\n",
      " -1.75167376e-03  7.22444942e-03  1.16349785e-02 -1.61908511e-02\n",
      " -3.37755010e-02  3.22626531e-02 -2.03813817e-02 -2.33859457e-02\n",
      " -1.29992142e-02 -1.66798979e-02  1.03070438e-02 -1.46030132e-02\n",
      " -7.79070333e-02 -8.25812370e-02 -3.38809639e-02  3.81114520e-02\n",
      "  7.86006916e-03  2.41455007e-02 -2.75715161e-02  1.30867511e-02\n",
      " -7.88596645e-03  1.78651251e-02  5.37323393e-02 -3.01823262e-02\n",
      "  1.69455800e-02  1.19571323e-02  3.52573872e-04  4.90208901e-02\n",
      " -8.57214630e-03  1.71267311e-03  4.83875768e-03 -4.10080813e-02\n",
      " -4.68120314e-02 -2.32559722e-03 -5.16776554e-02  3.10030729e-02\n",
      "  1.60961058e-02 -1.00803655e-02 -3.72485816e-03 -3.53387929e-02\n",
      "  2.95961481e-02  2.89097186e-02 -7.59911388e-02 -5.02980761e-02\n",
      " -2.11783517e-02  3.20462845e-02 -3.84538248e-02  2.45102607e-02\n",
      " -2.04188433e-02  6.02110662e-03 -9.81937349e-03  3.74778137e-02\n",
      "  3.40838432e-02  1.28863677e-02  5.67342043e-02 -8.09703618e-02\n",
      " -8.93603172e-03  1.33352671e-02 -2.51565613e-02  2.58413539e-03\n",
      " -6.51802719e-02  1.34400371e-02 -2.04681773e-02  6.53378246e-03\n",
      "  4.56974003e-03  1.99271012e-02 -6.07340224e-02  1.40691986e-02\n",
      " -5.75334318e-02  9.79797449e-03  3.55392806e-02 -2.45283525e-02\n",
      " -4.73311776e-03 -2.77492944e-02  2.34282911e-02 -8.76331324e-05\n",
      "  7.30442116e-03  1.42028760e-02  4.92807142e-02 -3.16540338e-02\n",
      " -1.34902131e-02  3.08487378e-02  2.80402005e-02 -4.33069021e-02\n",
      " -4.42284457e-02  3.80738862e-02  9.47457811e-05 -4.34895977e-02\n",
      "  1.43868113e-02  2.44333060e-03 -4.84072939e-02  1.08955177e-02\n",
      " -9.87488776e-03  4.59295623e-02  3.96379307e-02 -2.60117166e-02\n",
      "  2.48134229e-02 -5.37149012e-02  5.62824607e-02  8.81360471e-03\n",
      "  5.25077134e-02 -1.47371152e-02 -1.74380839e-02  3.45084667e-02\n",
      "  3.75523269e-02 -4.70167249e-02 -1.94911323e-02  3.82631756e-02\n",
      " -5.67595735e-02 -1.78613467e-03  2.33404227e-02 -5.88216455e-33\n",
      " -4.87187840e-02 -2.76265237e-02 -3.38240787e-02  2.66188253e-02\n",
      " -3.39277238e-02 -8.49197060e-03 -1.91250294e-02  3.00252270e-02\n",
      "  3.40781994e-02  5.11157773e-02 -1.92480199e-02  2.85642501e-02\n",
      "  3.66040282e-02  1.68858338e-02  4.77258638e-02  1.23802377e-02\n",
      "  2.14844178e-02  4.93656378e-04  1.21273603e-02 -5.82143702e-02\n",
      "  1.62954442e-02 -7.14259734e-03  4.80092280e-02  2.51190551e-02\n",
      "  4.60097864e-02 -2.29839664e-02 -2.05696691e-02 -3.22231976e-03\n",
      "  4.00091670e-02  3.52309905e-02 -3.43153812e-02  2.75633764e-03\n",
      " -1.25138173e-02  1.97685659e-02  5.53493388e-03  1.03744522e-01\n",
      "  5.77611523e-03 -5.65426387e-02  4.19558994e-02 -3.78831066e-02\n",
      " -3.93443331e-02 -6.24309704e-02 -2.24396167e-03 -5.46548367e-02\n",
      "  4.56134193e-02 -5.69243124e-03  3.38917114e-02 -1.44448057e-02\n",
      "  2.72110710e-03  1.11190863e-02 -5.00661097e-02 -1.61127187e-02\n",
      "  1.72818103e-03  6.88877255e-02  1.16492454e-02  2.83171274e-02\n",
      "  6.97190594e-03  2.68371888e-02 -7.72084948e-03  2.16828585e-02\n",
      "  1.15182875e-02  8.72832760e-02 -6.27275184e-03 -6.44473583e-02\n",
      " -1.58233736e-02  4.03268486e-02 -1.69728268e-02 -1.61188953e-02\n",
      " -3.75576727e-02  7.02938959e-02 -3.30486335e-02  4.66324203e-02\n",
      "  1.18027637e-02  6.51075691e-02 -1.16979582e-02 -8.28349032e-03\n",
      " -5.46905287e-02 -2.00227052e-02  8.42678361e-04 -8.19525495e-03\n",
      "  2.08357219e-02  1.37454011e-02 -1.29924587e-03 -3.94575261e-02\n",
      " -2.00184733e-02 -1.53721645e-02  1.17271869e-02 -4.40110825e-02\n",
      "  5.39267398e-02 -2.33010426e-02 -2.24211439e-02 -3.65216937e-03\n",
      "  2.92212721e-02  7.56442407e-03 -2.90923528e-02  4.01518010e-02\n",
      " -2.00854093e-02 -1.79865176e-03 -1.26235951e-02  2.51077097e-02\n",
      " -4.69285809e-02 -3.08554042e-02 -3.63357132e-04  6.01791218e-03\n",
      "  3.97508964e-02  1.38547439e-02  2.49774661e-02  1.76975690e-02\n",
      " -9.31573138e-02 -9.83686280e-03  8.44927225e-03 -1.95390526e-02\n",
      " -3.26569006e-02  5.13733970e-03  5.80926565e-03  2.08536796e-02\n",
      " -5.97835332e-03  5.86811639e-02 -1.49496775e-02 -5.72965927e-02\n",
      " -5.98239852e-03  1.95201044e-03  2.72976537e-03  6.07001688e-03\n",
      " -2.00525634e-02 -1.31687485e-02 -4.06228565e-02  5.68997152e-02\n",
      "  4.44969125e-02 -1.24308253e-02  1.96967348e-02  3.80979776e-02\n",
      "  2.30237646e-07  1.10574979e-02  4.79513034e-02  6.18299246e-02\n",
      "  4.40278798e-02  6.17667055e-03  2.58291303e-03  3.38913538e-02\n",
      " -5.32937422e-03 -2.59283856e-02 -1.26144290e-02  2.46495400e-02\n",
      " -1.68767944e-03  1.17907661e-03  2.40442809e-02 -9.77309495e-02\n",
      "  1.97368190e-02 -5.52921519e-02 -6.17424995e-02 -4.87152040e-02\n",
      "  1.11080939e-03  1.18732080e-01  8.13258141e-02  3.32448967e-02\n",
      "  4.38326895e-02 -2.49559190e-02 -3.59626487e-02  1.66319273e-02\n",
      "  5.93768805e-03 -1.43971872e-02  4.46712645e-03 -6.01986647e-02\n",
      " -5.65912202e-02 -8.21541902e-03  5.83057664e-03 -1.69481970e-02\n",
      "  9.58633143e-03  1.46733308e-02  5.05845435e-02  3.06891724e-02\n",
      "  6.60468116e-02 -2.56551877e-02 -2.78858151e-02 -3.19173411e-02\n",
      " -3.39236781e-02  1.49903111e-02 -3.03335823e-02 -6.06490020e-03\n",
      " -4.81769722e-03  1.72137488e-02 -8.23371485e-03  1.55548435e-02\n",
      "  2.69106589e-02  5.44308126e-03 -1.06899384e-02 -7.82138109e-03\n",
      " -4.44506705e-02  2.55874358e-02 -5.74760661e-02 -2.05442496e-02\n",
      " -3.07850186e-02 -1.57855190e-02 -7.07542151e-03 -4.21312526e-02\n",
      "  3.79934758e-02  6.27764687e-02 -7.67792249e-03 -3.18353064e-02\n",
      "  1.99277723e-34  1.04834316e-02 -3.39326151e-02  3.93821523e-02\n",
      "  5.53065315e-02  9.42169223e-03  1.09728128e-02 -4.91939969e-02\n",
      "  2.95024104e-02 -8.85376707e-03 -5.96248172e-02 -2.37825662e-02]\n",
      "\n",
      "Sentence: Embeddings are one of the most powerful concepts in machine learning!\n",
      "Embedding: [-2.98611335e-02 -1.37522332e-02 -4.75402065e-02  2.72126496e-02\n",
      "  3.40054557e-02  3.16465721e-02  4.26963754e-02  3.29794036e-03\n",
      "  4.35717851e-02  2.53837258e-02  3.02529093e-02  3.21131088e-02\n",
      " -3.99913155e-02  1.28761074e-02  6.70220107e-02 -7.92899802e-02\n",
      "  4.68772240e-02  2.40266230e-02 -2.07997561e-02 -1.07433032e-02\n",
      " -1.19410567e-02 -5.39290570e-02  4.21055667e-02  2.23588645e-02\n",
      " -2.98949406e-02  8.35978519e-03  1.58385076e-02 -4.80235554e-02\n",
      "  1.88435987e-03 -1.67521499e-02 -2.15628967e-02 -3.88487950e-02\n",
      "  3.06274630e-02  4.20525968e-02  1.69483383e-06 -1.86928920e-02\n",
      " -1.24558602e-02  1.32128661e-02 -4.89040054e-02  1.34746497e-02\n",
      "  2.28873454e-02  8.81781150e-03  8.64926632e-03 -2.00949535e-02\n",
      " -3.15217786e-02 -2.53432989e-02  7.57318884e-02  3.62445787e-02\n",
      "  1.25289764e-02  3.09694838e-02  4.50759893e-03 -3.50041837e-02\n",
      " -4.42523800e-04 -9.76646598e-03  6.04545437e-02  4.03472260e-02\n",
      "  1.10734627e-02  6.56203832e-03 -5.84599841e-03  3.79781798e-03\n",
      " -4.46915329e-02  1.76404957e-02  2.45916937e-02 -3.60040320e-03\n",
      "  1.02473386e-01  3.73759046e-02  6.13311585e-03 -2.24676393e-02\n",
      "  1.46482149e-02  5.00536971e-02 -2.29907800e-02  1.12924501e-02\n",
      " -3.10552493e-02 -1.49509497e-02 -2.53127958e-03  3.20944525e-02\n",
      " -4.67056111e-02 -4.85887229e-02  2.98306085e-02  6.44215718e-02\n",
      " -3.12613621e-02  3.57407108e-02  4.16527279e-02 -5.52517101e-02\n",
      " -8.74630455e-03 -2.18630452e-02 -1.12744365e-02 -2.14436054e-02\n",
      " -1.32824089e-02 -2.04866175e-02 -1.00575835e-02  3.54763754e-02\n",
      " -7.47605041e-03 -3.70188542e-02  5.77893443e-02 -2.18168851e-02\n",
      "  4.36226744e-03  2.04380676e-02  3.36814895e-02 -4.92800623e-02\n",
      "  4.82793637e-02 -1.81003916e-03 -1.05118714e-02  4.13323008e-02\n",
      " -6.79833218e-02  1.75716002e-02 -4.43412997e-02  9.90839209e-03\n",
      " -3.81809883e-02  1.10827247e-02 -5.07279299e-02 -2.17451062e-02\n",
      " -1.03836004e-02  4.60332148e-02  1.55862756e-02 -4.21366543e-02\n",
      " -2.72146463e-02  3.22818719e-02 -4.24739346e-02  2.71207262e-02\n",
      " -7.41061494e-02  4.20107022e-02  2.02437416e-02  7.31810853e-02\n",
      " -8.97695776e-03 -2.31159981e-02 -3.93559597e-02 -1.46008581e-02\n",
      " -3.30910087e-02  1.12239840e-02  2.58564088e-03 -4.36856225e-03\n",
      "  1.85855757e-02  2.69934963e-02 -1.67214964e-02  3.69569622e-02\n",
      "  4.44489233e-02 -2.21723747e-02  6.72968617e-03  1.22935865e-02\n",
      "  1.71758439e-02 -2.36473209e-03  3.72263864e-02 -2.22870894e-02\n",
      "  2.94603743e-02 -2.33691130e-02  5.38467802e-03 -3.06581371e-02\n",
      " -2.38919947e-02 -2.63614431e-02 -2.01789066e-02  1.11245625e-01\n",
      " -1.99836884e-02 -3.54029946e-02  3.84143293e-02  2.53069103e-02\n",
      "  1.99550800e-02  5.53518161e-02 -1.99332666e-02 -2.16716342e-03\n",
      "  4.91093025e-02 -4.03530821e-02 -1.16976965e-02 -5.33113368e-02\n",
      "  8.29583779e-03 -5.08251674e-02 -2.65503787e-02 -1.53242508e-02\n",
      "  5.78812324e-03  2.46574567e-03 -3.44449542e-02 -1.85132422e-03\n",
      " -3.95730175e-02 -2.71690600e-02  4.93568070e-02  8.38368833e-02\n",
      "  5.43491282e-02  8.22261199e-02  1.23894876e-02 -4.79795039e-03\n",
      "  7.77337700e-04  2.98485924e-02 -1.85584724e-02  5.98795563e-02\n",
      " -6.82792254e-03  9.78193595e-04  2.85485983e-02 -7.64618209e-03\n",
      " -1.86619982e-02 -2.69287508e-02 -2.90332809e-02 -1.37871560e-02\n",
      " -2.57598585e-03 -2.20173486e-02 -1.70821641e-02 -3.81843299e-02\n",
      "  2.21505221e-02 -3.59234400e-02 -1.19439512e-02 -3.18307765e-02\n",
      " -4.80801538e-02  9.77633987e-03 -1.04864908e-03  4.15371843e-02\n",
      " -1.10974172e-02 -4.72830050e-02  1.90984886e-02 -5.31177521e-02\n",
      "  2.11326387e-02 -2.53063673e-03  5.61055206e-02 -1.33795263e-02\n",
      " -5.95856085e-03 -1.20307952e-02  4.63929884e-02 -2.81908866e-02\n",
      "  2.25355066e-02 -2.50472594e-03 -3.52453031e-02  2.55494714e-02\n",
      "  9.10396036e-03  3.25213326e-03  2.55968911e-03 -1.25623923e-02\n",
      " -3.51496413e-02 -4.28946316e-02 -2.32332991e-03  2.41020992e-02\n",
      " -5.16841607e-03  1.68739930e-02  5.52647049e-03  2.36791950e-02\n",
      "  5.65164275e-02 -3.47868837e-02 -6.34517744e-02 -7.45629286e-03\n",
      " -1.78447943e-02  5.35898432e-02  2.67291348e-02 -8.74199420e-02\n",
      "  1.04195531e-02 -4.13963513e-04 -3.04448605e-03  9.14251152e-03\n",
      "  2.91529465e-02 -5.81831746e-02  6.83463514e-02 -4.08618040e-02\n",
      " -9.09787416e-03 -3.40769850e-02  3.52410935e-02 -1.02627790e-02\n",
      " -5.72505931e-04 -2.73455400e-03  1.59635786e-02  4.49070940e-03\n",
      " -2.09051464e-02  3.02769598e-02  2.46119704e-02 -1.44067183e-02\n",
      "  1.73268840e-02  1.99031946e-03  4.23051231e-02 -2.39176955e-02\n",
      " -3.25547867e-02 -1.45939533e-02  3.95101011e-02 -6.04649819e-02\n",
      " -3.02065536e-02  1.67189408e-02 -2.26817783e-02 -2.61955224e-02\n",
      " -5.51320054e-02  1.44908521e-02 -1.99246891e-02  3.99750890e-03\n",
      "  3.12610231e-02 -4.90727909e-02 -9.49712179e-04  5.39497100e-02\n",
      " -9.10081714e-03 -2.69486792e-02 -3.63159440e-02 -1.38437068e-02\n",
      " -4.45622206e-02  5.49358986e-02  2.17594160e-03  2.23447313e-03\n",
      " -5.23019116e-03 -1.47894444e-02  3.60591859e-02  1.45263001e-02\n",
      "  8.39191303e-03 -6.10361174e-02 -7.89950695e-03 -2.98297661e-03\n",
      "  3.56560806e-03  8.33992511e-02 -2.61215121e-02  8.06722045e-02\n",
      "  3.63060110e-03  1.69974733e-02  2.58604512e-02  1.09443406e-03\n",
      " -4.57063057e-02  5.55678457e-02  2.00643502e-02  4.76660691e-02\n",
      " -4.91053909e-02 -1.86081212e-02  3.34404521e-02 -2.57310402e-02\n",
      " -3.16369929e-03  7.21444339e-02 -1.61519032e-02 -1.33933937e-02\n",
      " -6.06293827e-02 -2.82187313e-02 -8.91925395e-03 -2.71172193e-03\n",
      "  8.04915838e-03 -4.95209955e-02  7.89434165e-02  2.76428238e-02\n",
      " -5.42582199e-03 -3.06719914e-03 -4.11826894e-02  1.39172487e-02\n",
      "  3.04253194e-02  1.02856588e-02  1.06679145e-02 -5.56554385e-02\n",
      " -1.75082888e-02  2.03868337e-02  8.43307376e-03  3.82471234e-02\n",
      " -3.89099903e-02 -1.61303710e-02  3.18059400e-02 -7.32970312e-02\n",
      " -1.76502261e-02 -4.79874723e-02 -5.55042140e-02 -5.00752172e-03\n",
      "  4.46791149e-04  3.57333384e-02 -8.24653835e-04 -3.34324278e-02\n",
      " -3.32417116e-02 -2.46460568e-02  2.15331931e-02  3.90855176e-03\n",
      "  2.53471583e-02  6.02990715e-03 -7.81610049e-03  1.23765133e-02\n",
      " -1.71039309e-02  2.68103369e-02  2.83679063e-03 -1.27643654e-02\n",
      "  1.00510910e-01  1.03580886e-02 -3.55143137e-02  1.56616382e-02\n",
      " -9.85949785e-02  4.58441637e-02 -3.15230452e-02 -2.35781241e-02\n",
      " -2.78350357e-02 -7.75307053e-05 -2.82363016e-02 -1.92918424e-02\n",
      "  1.87389627e-02  5.71941175e-02  2.56911945e-02 -3.20030302e-02\n",
      "  1.99074652e-02 -3.15819643e-02 -4.02061380e-02  5.77630550e-02\n",
      "  1.72974467e-02 -5.37013412e-02 -1.25325620e-02 -1.45484125e-02\n",
      " -5.76174706e-02  1.09727560e-02 -2.04727892e-02  2.85540763e-02\n",
      " -5.04399873e-02  4.36991155e-02  1.75711196e-02 -1.02343690e-02\n",
      " -9.69771966e-02 -2.99995504e-02 -2.86679417e-02  2.24936940e-02\n",
      " -1.68121196e-02 -1.43673839e-02 -8.79590493e-03 -1.69044118e-02\n",
      "  2.41557825e-02 -6.53192475e-02 -4.10800055e-02 -2.34058369e-02\n",
      " -6.76065087e-02 -1.55690126e-02  3.62358131e-02  7.83159807e-02\n",
      " -4.97516915e-02 -7.08547756e-02 -5.01179770e-02 -8.56404135e-04\n",
      "  5.44897746e-03  4.34703613e-03  9.88053083e-02 -2.16415580e-02\n",
      " -1.87750813e-02  1.15069589e-02  2.63996385e-02  1.65235661e-02\n",
      " -2.24058032e-02 -4.31826673e-02  1.31803885e-01 -2.97034122e-02\n",
      "  2.65934132e-02 -1.38888787e-02 -1.67003851e-02  3.44145522e-02\n",
      " -8.94354936e-03  6.16001487e-02 -3.42303105e-02  2.46421131e-03\n",
      " -8.14095326e-03  5.80325164e-02  5.24208285e-02 -1.53281046e-02\n",
      "  4.01382335e-02  1.51407188e-02 -3.01462715e-03 -4.97021228e-02\n",
      " -4.24302788e-03  5.77289090e-02  3.17873806e-02  4.74008322e-02\n",
      "  2.95218211e-02 -1.50123015e-02 -2.47945394e-02 -7.11501837e-02\n",
      "  2.06847955e-02  3.11488193e-02 -5.86067978e-03  1.62786860e-02\n",
      " -3.93682979e-02  5.46505675e-02  3.26595455e-02 -1.87021624e-02\n",
      " -9.79863182e-02  4.33778483e-03 -5.58157302e-02 -1.34620788e-02\n",
      "  2.88454238e-02  1.58748217e-02 -3.32564376e-02  1.44418271e-03\n",
      " -5.51108047e-02  8.24674964e-02  2.38845963e-02 -2.04838086e-02\n",
      " -4.78587579e-03  3.78722958e-02 -4.87563051e-02  3.44647244e-02\n",
      "  1.10358596e-02  1.12450458e-02  1.33262808e-02 -3.46375220e-02\n",
      " -6.92220703e-02  7.30120856e-03 -6.57011755e-03  1.73203778e-02\n",
      "  5.23055485e-03  4.48132083e-02  3.89852785e-02 -1.99274719e-02\n",
      " -1.80920269e-02  3.25938128e-02 -2.02027205e-02  4.86271136e-04\n",
      " -8.88757221e-03 -1.91347934e-02  2.50685941e-02  4.74019684e-02\n",
      "  2.18653562e-03 -1.69988237e-02  3.62670906e-02  3.46248061e-03\n",
      "  4.21927962e-03  8.04170966e-02  3.10627073e-02 -1.04945619e-03\n",
      " -3.55466567e-02  4.34836857e-02 -3.06218714e-02 -3.03191822e-02\n",
      " -4.13175374e-02 -1.05258077e-02 -2.35242154e-02 -1.86772346e-02\n",
      "  4.42934828e-03  5.45056500e-02 -6.05017543e-02  2.48421840e-02\n",
      " -3.36967446e-02 -4.54169177e-02 -2.63173152e-02  6.98053418e-03\n",
      "  6.92871362e-02 -2.04491597e-02 -1.96812954e-02 -9.72559676e-03\n",
      " -1.21564763e-02  7.89341703e-03  1.84749323e-03 -6.93651065e-02\n",
      "  2.43357364e-02  4.00609449e-02  3.44013311e-02 -2.84281969e-02\n",
      " -1.09431576e-02  1.38742989e-02 -4.40584915e-03  1.19345926e-03\n",
      " -8.81165117e-02  1.15931612e-02 -2.56350879e-02  5.57525307e-02\n",
      "  1.26946196e-01  5.39565906e-02 -1.41436839e-02  1.27196591e-02\n",
      " -1.32235829e-02 -5.94484620e-02  2.86704022e-02  2.57284474e-02\n",
      " -8.33778083e-03  8.17355118e-04  5.93052525e-03  3.29110399e-02\n",
      "  4.12752070e-02 -5.77966031e-03 -1.71124283e-02  1.06227677e-02\n",
      " -2.19601914e-02 -4.97207269e-02  2.53766086e-02 -5.60257652e-33\n",
      " -1.35397380e-02 -3.77958678e-02 -2.67923321e-03 -3.69707705e-04\n",
      " -1.98267438e-02  5.47052128e-03  6.02688221e-03  1.93069018e-02\n",
      "  3.87977972e-03  2.97698993e-02 -1.88229028e-02  2.20039487e-03\n",
      "  8.17020144e-03  1.61964949e-02  3.17529403e-02 -6.83415076e-03\n",
      "  2.19252128e-02  4.37736977e-04  2.96859108e-02 -2.62557138e-02\n",
      "  6.49377238e-03  3.56025323e-02  1.58605922e-03 -4.76584062e-02\n",
      " -5.26238717e-02  3.78274284e-02  3.54341976e-02 -3.10347639e-02\n",
      "  7.96405692e-03  5.48469909e-02 -3.56443375e-02  9.10137035e-03\n",
      " -9.45986249e-03 -4.63287272e-02 -1.63906552e-02  6.32453188e-02\n",
      " -1.38588166e-02 -5.95724620e-02 -1.57990996e-02  2.01886967e-02\n",
      " -1.98292602e-02 -3.49211581e-02  2.27937549e-02 -5.91621958e-02\n",
      "  4.18854654e-02  1.20739406e-03  5.19158877e-02 -1.88436080e-02\n",
      " -3.12102139e-02  2.34932862e-02 -7.41029978e-02 -2.76594743e-04\n",
      " -1.51719945e-02  6.11713789e-02  1.25065088e-01 -1.28459092e-02\n",
      " -1.12671144e-02  1.51753495e-03 -8.09153542e-02  1.12689203e-02\n",
      " -1.97573546e-02  2.74268426e-02  9.40993428e-03 -9.58756730e-03\n",
      "  2.54850034e-02  6.81658909e-02 -1.83453206e-02 -1.00963950e-01\n",
      " -9.45242029e-03 -5.27015422e-03  1.98684055e-02  9.80847999e-02\n",
      "  3.15633416e-02  5.30422814e-02  3.75123210e-02 -6.64208531e-02\n",
      " -5.92880286e-02 -1.57073885e-02  1.76609289e-02 -5.81073239e-02\n",
      "  2.23230571e-02  1.29869413e-02 -3.30261216e-02  9.96896648e-04\n",
      " -9.87089984e-03 -3.12955193e-02  2.28528515e-03 -4.91250455e-02\n",
      "  1.47693781e-02 -1.83367264e-02 -4.16306220e-02  3.76897119e-02\n",
      "  3.35410275e-02 -7.97111690e-02  4.01299335e-02  1.59071758e-02\n",
      "  5.06082084e-03  4.28808108e-02  2.29760315e-02 -4.13350910e-02\n",
      " -3.10503747e-02 -5.26405051e-02 -4.95404862e-02 -2.94256434e-02\n",
      "  5.94924316e-02 -2.59802695e-02  3.02497260e-02  8.80406424e-03\n",
      " -4.84467149e-02 -2.00851578e-02  9.82179027e-03 -7.89194182e-02\n",
      "  4.52878466e-03 -9.34896991e-03  9.23313852e-03 -3.17361802e-02\n",
      "  2.10833270e-02  6.37117773e-03  3.36348005e-02  3.83613929e-02\n",
      " -4.55527529e-02  1.08120276e-03 -9.83326603e-03  7.70196225e-03\n",
      " -2.87617892e-02 -1.74959507e-02 -4.27815085e-03  2.81287059e-02\n",
      "  4.97339852e-02 -7.45570734e-02 -1.07009150e-02 -7.66055705e-03\n",
      "  2.33968862e-07  1.52483368e-02  8.39613900e-02  3.67242694e-02\n",
      " -3.69248651e-02  3.64751816e-02  4.26422209e-02 -4.39828215e-03\n",
      "  1.78133883e-02 -2.67076623e-02 -7.13901129e-03  5.59975468e-02\n",
      "  3.13966535e-02  2.13443302e-03  3.90371308e-02 -8.78528282e-02\n",
      " -2.21659765e-02 -2.47735474e-02 -1.18189696e-02 -7.89708644e-03\n",
      " -2.08857581e-02  4.30555828e-02  1.07643545e-01  4.40618545e-02\n",
      "  1.47962738e-02  2.44862996e-02 -3.86268236e-02  1.80743653e-02\n",
      " -1.47839868e-03  7.74167031e-02 -4.19565700e-02 -3.80529128e-02\n",
      "  3.61257493e-02  1.59031036e-03  1.95324030e-02 -2.00080797e-02\n",
      "  4.22538295e-02  3.06110885e-02 -3.53689468e-03  5.93103329e-03\n",
      " -2.23223493e-02 -2.07131468e-02 -3.62911192e-03  1.74653828e-02\n",
      " -4.08759005e-02  5.91595173e-02 -5.89099862e-02 -3.96753885e-02\n",
      " -3.33528854e-02  1.02161821e-02  6.97292062e-03  7.70389810e-02\n",
      " -1.86911710e-02 -1.82568543e-02 -2.42319237e-02 -3.40699940e-03\n",
      " -3.60555351e-02  4.33389656e-02 -3.48602235e-02  5.27768470e-02\n",
      "  2.89709717e-02 -4.98462208e-02 -1.94749329e-02  1.16397832e-02\n",
      " -3.04614641e-02  8.04637671e-02  6.56248033e-02 -2.84532979e-02\n",
      "  1.81615312e-34 -4.19157417e-03 -2.57882606e-02  5.17320596e-02\n",
      "  4.94420975e-02  1.32476604e-02 -4.21994254e-02 -1.12458579e-02\n",
      " -2.61519644e-02  5.51130585e-02  2.20024865e-02 -2.51170285e-02]\n",
      "\n",
      "Sentence: Learn to use embeddings well and you'll be well on your way to being an AI engineer.\n",
      "Embedding: [-2.20730789e-02  2.08950378e-02 -6.03005365e-02  8.43946729e-03\n",
      "  4.37650904e-02  1.55070378e-02  4.99907732e-02 -3.03232390e-02\n",
      "  4.94784154e-02  2.35512313e-02  3.29350717e-02  1.53877577e-02\n",
      " -6.68355152e-02  1.11002848e-01  6.92677274e-02 -2.31888648e-02\n",
      "  3.79102752e-02 -4.94146999e-03 -1.57800354e-02 -3.45476493e-02\n",
      " -2.65052747e-02 -2.47879494e-02 -1.86141469e-02  3.00361924e-02\n",
      " -2.81186271e-02 -8.75130203e-03 -3.30773089e-03 -2.06115842e-02\n",
      "  1.03315581e-02 -1.51483119e-02 -3.48330885e-02 -2.63248291e-02\n",
      "  2.06908081e-02  3.79109047e-02  1.81912878e-06 -2.44284887e-03\n",
      " -1.80562399e-03  5.61762601e-03 -2.79870108e-02  1.54703064e-02\n",
      "  3.06456368e-02  3.72600965e-02 -1.55611457e-02  2.54414566e-02\n",
      " -6.42072335e-02  3.16353291e-02  6.63442165e-02  3.80970277e-02\n",
      "  5.57844900e-02  5.31659871e-02 -9.69289709e-03 -3.61423865e-02\n",
      "  3.72434966e-02 -4.67828615e-03  5.14574982e-02  1.00057852e-02\n",
      "  4.90289647e-03  1.41562494e-02  4.95099947e-02  3.32949543e-03\n",
      " -3.21100689e-02  4.42388132e-02  3.27416360e-02 -7.90620223e-03\n",
      "  1.07809782e-01  7.32945055e-02  3.36702541e-02 -4.28345799e-02\n",
      "  1.05966348e-02  2.05653869e-02 -2.02670060e-02  1.04964329e-02\n",
      " -1.97615847e-02 -2.89400868e-05 -2.61862557e-02 -1.85173880e-02\n",
      " -3.44269499e-02 -4.08621430e-02  2.32571661e-02  2.14195754e-02\n",
      "  1.31321000e-02 -3.27211320e-02 -1.91425607e-02 -2.86572073e-02\n",
      " -1.16859321e-02  1.21910684e-02  1.05248326e-02 -3.39584984e-02\n",
      "  3.08906357e-03 -4.44888361e-02  2.65105050e-02  1.09536275e-02\n",
      "  2.51450744e-02 -6.48836140e-03  4.54370398e-03 -2.02785153e-02\n",
      " -1.03216311e-02  2.06590239e-02 -1.65314153e-02 -2.45611984e-02\n",
      "  5.47549464e-02  2.68261284e-02  2.95510739e-02  3.86754386e-02\n",
      " -7.76720047e-02  3.80055718e-02 -2.98364609e-02  7.96886235e-02\n",
      " -3.00943386e-02  7.57847680e-03 -6.89826533e-02 -2.92666741e-02\n",
      " -2.35580001e-02  3.48198116e-02  2.52938196e-02 -4.53817137e-02\n",
      " -1.57938581e-02  4.39031161e-02 -4.04335782e-02  8.32527410e-03\n",
      " -2.84665246e-02  4.94934060e-02  2.41276734e-02  3.02191935e-02\n",
      " -4.99590747e-02 -5.94533049e-02 -3.70175764e-02  1.30330836e-02\n",
      " -3.36468704e-02  3.45589668e-02 -1.44523168e-02  2.57640034e-02\n",
      "  4.61182604e-03  2.21551936e-02 -4.93460149e-03  9.66005027e-02\n",
      " -2.72451574e-03  5.65355062e-04 -3.24248001e-02  1.31681822e-02\n",
      "  4.41607349e-02 -7.03053037e-03  6.84261173e-02 -2.28166487e-02\n",
      " -2.81031011e-03 -4.23883386e-02 -1.33632068e-02 -5.96738867e-02\n",
      " -6.96124090e-03 -2.31901389e-02 -3.78851332e-02  9.80186462e-02\n",
      " -2.21728832e-02 -2.30062660e-02  3.22815180e-02  8.21805652e-03\n",
      " -7.04122894e-03  4.84079421e-02  4.23291177e-02 -2.59713549e-03\n",
      "  1.20481083e-04  1.67414229e-02  2.91198026e-02 -1.28740566e-02\n",
      " -2.41077766e-02 -3.29319388e-02 -3.50287976e-03 -3.19321975e-02\n",
      " -2.64171790e-02  2.30404399e-02  1.11637358e-02 -9.96002089e-03\n",
      " -1.75901111e-02 -2.00277125e-03  1.21594928e-02  4.67823222e-02\n",
      "  5.20882010e-02  7.21171871e-02  1.94978509e-02  1.15072737e-02\n",
      "  5.94164943e-03 -1.47833200e-02 -2.87724324e-02  6.72665983e-02\n",
      " -1.68758631e-02  5.25874132e-03 -3.39737348e-02  5.24596199e-02\n",
      " -2.59793345e-02 -4.41379882e-02  1.47451949e-03 -1.06598893e-02\n",
      " -1.51859261e-02 -1.55875913e-03  1.81505233e-02 -4.85411249e-02\n",
      "  3.67908622e-03 -6.59313798e-02 -1.49418339e-02 -3.23528983e-02\n",
      " -2.79949382e-02  1.71856657e-02 -7.87090510e-03  4.65692319e-02\n",
      "  1.47123458e-02 -7.40438700e-02 -6.52104393e-02 -5.22734933e-02\n",
      " -1.82343386e-02  5.20859174e-02  3.06304563e-02 -2.36037280e-02\n",
      "  2.42384523e-02 -1.83939468e-02 -4.83017601e-03 -2.13386659e-02\n",
      "  1.56583507e-02  9.87340882e-03 -4.25561778e-02  6.00462733e-03\n",
      " -3.14500323e-03  4.51512169e-03 -1.52779440e-03  1.13731585e-02\n",
      " -6.96354210e-02 -3.37257385e-02  1.33406678e-02  4.87288972e-03\n",
      " -7.81492889e-03  4.78049628e-02 -1.59711950e-02  3.14606354e-02\n",
      "  5.15920632e-02 -4.05122526e-02 -5.06461151e-02  9.99931712e-03\n",
      " -2.00729389e-02  4.21552695e-02  3.03182583e-02 -1.00431308e-01\n",
      " -4.12019938e-02  3.43990549e-02  3.29209156e-02  1.07408373e-03\n",
      "  3.70961837e-02 -6.94237277e-02  6.52394071e-02  8.31665471e-03\n",
      "  1.68036297e-02 -2.60705985e-02  8.14495515e-03 -1.48009406e-02\n",
      " -2.65671238e-02  3.29321325e-02 -7.37512484e-03  7.23977387e-03\n",
      " -2.69329324e-02  1.71754733e-02 -2.28083096e-02 -4.75339359e-03\n",
      "  2.88568828e-02  1.30800778e-04  5.44128604e-02 -1.43378610e-02\n",
      "  1.89891569e-02 -1.32732224e-02  4.01177295e-02 -7.29275271e-02\n",
      " -2.41211001e-02  3.16216908e-02 -1.68014541e-02  8.47543124e-03\n",
      " -5.23940548e-02 -1.43882707e-02 -1.46156475e-02  6.39906013e-03\n",
      "  2.15113629e-02 -5.18960319e-02 -4.30576280e-02  2.34075896e-02\n",
      "  2.30273814e-03 -2.48434208e-02 -4.38243262e-02 -2.16570701e-02\n",
      " -6.91595599e-02  1.76769812e-02  2.12067924e-02 -2.20293514e-02\n",
      " -1.06773637e-02  9.57427733e-03  2.21988559e-02  5.51470779e-02\n",
      "  1.03682876e-02 -8.14825371e-02 -7.94705097e-03 -1.85866151e-02\n",
      "  1.20494235e-02  7.51403496e-02 -1.41215865e-02  8.83924663e-02\n",
      "  3.12628560e-02  8.12263787e-03 -2.29444783e-02  3.96010391e-02\n",
      " -2.00167950e-02  9.16027650e-02 -2.06839554e-02  5.84990866e-02\n",
      " -4.32368554e-02 -4.74750809e-03 -9.51891951e-03  5.42950863e-03\n",
      "  1.19126387e-04  6.15377091e-02 -1.68787281e-03 -4.66321409e-02\n",
      " -2.01405138e-02  1.32406233e-02  9.70686972e-03  2.73847468e-02\n",
      "  3.06639802e-02  6.71580108e-03  8.71220902e-02 -1.97375263e-03\n",
      "  8.18298385e-03  5.44363260e-03 -5.76205924e-02  1.34821245e-02\n",
      "  5.06281527e-03 -2.10568774e-02  1.25937080e-02 -5.49777178e-03\n",
      " -1.44645032e-02 -2.92567443e-02  5.53299263e-02 -2.60099564e-02\n",
      " -2.82450509e-03 -2.30902229e-02  8.89710709e-03 -2.61565186e-02\n",
      "  9.08613089e-04 -6.16204254e-02 -7.56418929e-02 -1.05932355e-02\n",
      " -1.19563723e-02  6.71458542e-02 -1.96234621e-02 -5.00934310e-02\n",
      " -3.91229242e-02 -3.07008494e-02  7.18906447e-02  9.29245353e-03\n",
      " -6.34388346e-03  7.86940742e-04 -1.36484224e-02  2.87188552e-02\n",
      "  4.01224680e-02  1.28037268e-02  1.77381393e-02 -4.75977454e-03\n",
      "  5.47173657e-02  1.10810972e-03 -2.25790367e-02 -2.80290749e-03\n",
      " -1.13696076e-01  2.55904589e-02  4.00445570e-04 -4.39810567e-02\n",
      "  1.36319092e-02 -1.54137574e-02 -4.99015115e-02 -2.32889634e-02\n",
      " -1.62987469e-03  3.95835154e-02  1.89040210e-02 -3.02703064e-02\n",
      "  2.71438062e-02  1.05685764e-03 -4.21068780e-02  3.71961370e-02\n",
      "  3.54258530e-02 -6.98274672e-02 -2.20937636e-02 -4.01495770e-02\n",
      " -1.90164130e-02 -2.69835424e-02 -1.51212923e-02  3.33365463e-02\n",
      " -9.74889472e-02  1.73102580e-02  6.21013576e-03 -2.59423093e-03\n",
      " -1.10152960e-01 -6.10186458e-02 -1.36549752e-02 -1.35034993e-02\n",
      " -6.72574267e-02 -4.05119825e-03 -6.64984901e-03  3.86568811e-03\n",
      "  9.43471678e-03 -3.86636667e-02 -1.93593167e-02  1.34933861e-02\n",
      " -4.58106883e-02  6.06737509e-02  6.06380180e-02  4.85596098e-02\n",
      " -4.56088744e-02 -5.71936443e-02 -1.55094853e-02  3.40963267e-02\n",
      "  9.48153553e-04 -9.94347408e-03  2.84657683e-02 -3.29024643e-02\n",
      " -2.83211116e-02  3.19907628e-02  2.61299107e-02 -2.74054855e-02\n",
      " -1.36352722e-02  7.47715589e-03  1.19430296e-01 -4.45807092e-02\n",
      "  1.07671879e-02 -8.69424269e-02 -2.19551232e-02  1.83874518e-02\n",
      " -1.06521556e-02 -1.89243145e-02 -3.06513999e-02 -3.04701868e-02\n",
      " -3.22214998e-02  4.12150919e-02  8.95758998e-03 -2.73179747e-02\n",
      "  9.39996447e-03 -9.57189419e-04 -1.94010269e-02 -4.92622592e-02\n",
      " -9.18892305e-03  4.66893949e-02  5.41893542e-02  2.21609436e-02\n",
      " -2.86352020e-02  5.20295575e-02  2.47589722e-02 -7.14267865e-02\n",
      " -1.26206921e-02  7.35522620e-03  2.13784967e-02  2.93514151e-02\n",
      " -2.57651191e-02  5.20562343e-02 -2.74892393e-02 -3.10242567e-02\n",
      " -9.02880505e-02  6.10371791e-02 -5.22610024e-02  2.13111378e-02\n",
      "  4.41735461e-02  3.23370770e-02  1.75648611e-02 -2.39519849e-02\n",
      " -2.69709565e-02  5.11278845e-02  2.69064419e-02 -4.51932661e-02\n",
      "  2.52656150e-03  2.44934224e-02 -2.89541222e-02  2.79992614e-02\n",
      " -1.36022344e-02 -4.32368480e-02  1.85830146e-02  7.63600547e-05\n",
      "  2.43510236e-03 -3.73321772e-03 -1.72279850e-02  1.01292739e-02\n",
      "  1.98437292e-02 -2.60018334e-02 -3.40177747e-03  1.09125776e-02\n",
      " -4.16363589e-02  3.37032191e-02 -2.81634834e-02  1.79126430e-02\n",
      " -4.53095213e-02 -1.09819025e-02 -2.20828876e-03  1.99102368e-02\n",
      "  3.56372371e-02 -3.11799124e-02  3.78752537e-02 -1.41408965e-02\n",
      " -2.16907579e-02  2.73019914e-02  3.69818695e-03  6.35387599e-02\n",
      "  1.22669153e-02 -6.02271082e-03 -7.60753360e-03 -1.86565034e-02\n",
      " -5.64716849e-03 -2.20050756e-03 -1.31825674e-02  1.67723969e-02\n",
      " -3.77264321e-02  2.97895428e-02 -5.01569882e-02  4.89088148e-02\n",
      " -6.07445128e-02 -8.39419141e-02 -5.09001054e-02  1.81768201e-02\n",
      "  6.66732788e-02 -3.30036576e-03 -2.82403431e-03 -5.35406061e-02\n",
      "  3.90341058e-02  2.19852515e-02  3.13554965e-02 -3.36526856e-02\n",
      "  1.96913630e-02  1.67883337e-02  5.04003018e-02  3.08061484e-03\n",
      " -7.24790676e-04  4.42907102e-02 -4.12959186e-03  4.29329164e-02\n",
      " -6.62552416e-02  1.16061489e-03 -2.81716399e-02  1.56885628e-02\n",
      "  9.78133827e-02  5.53594567e-02 -1.39378663e-02  2.12306920e-02\n",
      " -1.30955493e-02 -6.82027638e-02 -8.09120596e-04  4.99291569e-02\n",
      " -2.69266032e-02 -2.97804121e-02  3.84462103e-02  1.97354686e-02\n",
      "  3.37088406e-02  1.65873710e-02  5.77318622e-03 -3.04898154e-02\n",
      " -1.52511839e-02 -3.56159322e-02 -8.69218260e-03 -5.42296833e-33\n",
      "  3.24374111e-03 -3.46329659e-02  3.58932763e-02  1.83770731e-02\n",
      " -2.17505209e-02 -3.26411501e-02  2.88398727e-03  1.50463730e-02\n",
      " -1.75262569e-03 -1.99418589e-02 -6.10355847e-03  2.23847125e-02\n",
      " -8.78949009e-04  2.48684827e-02  3.39736640e-02  2.75593083e-02\n",
      "  3.37792486e-02  3.98564674e-02  2.55545266e-02  1.83042735e-02\n",
      " -2.92878766e-02  5.18082874e-03  8.37716216e-04 -3.66560258e-02\n",
      " -3.46732773e-02  3.82687002e-02  5.50824916e-03 -4.35187705e-02\n",
      "  2.44077872e-02  3.54167409e-02 -2.13442389e-02  2.86623873e-02\n",
      " -2.65393202e-04  3.73409092e-02 -8.68169963e-03  3.04786791e-03\n",
      " -2.71682106e-02 -3.85088064e-02 -6.12388700e-02 -2.00843648e-03\n",
      " -1.22080101e-02 -8.67197886e-02  3.75361089e-03 -1.77707635e-02\n",
      "  8.32475629e-03 -1.69167910e-02  7.02404156e-02  3.32234018e-02\n",
      "  4.34313193e-02  1.47016672e-02 -1.25546902e-01  1.50866620e-02\n",
      " -5.43164499e-02 -1.79150619e-03  4.99600917e-02 -1.53786503e-02\n",
      "  3.32683846e-02 -3.07708886e-02 -1.83896720e-02  9.45797563e-03\n",
      " -4.60291207e-02 -2.03868700e-03  2.62429062e-02 -5.00789396e-02\n",
      "  2.01835707e-02  6.08983077e-02 -2.01180689e-02 -2.60054376e-02\n",
      "  1.05925510e-02 -3.31153870e-02  1.62595529e-02  7.77862370e-02\n",
      " -1.90729683e-03 -5.62888850e-03  1.43715795e-02 -4.06833775e-02\n",
      " -5.14971018e-02  1.66253143e-04 -3.33061465e-03  1.44688822e-02\n",
      "  4.24922648e-04  3.04452889e-02 -1.83636770e-02  1.51186541e-03\n",
      "  2.99861338e-02 -3.68002243e-02  8.35627690e-03 -3.31025571e-02\n",
      "  2.66911834e-02  5.47830900e-03 -1.80524234e-02  2.42577009e-02\n",
      "  5.72709087e-03 -5.93372509e-02  1.04358487e-01 -9.87923238e-03\n",
      " -1.36105847e-02  5.79998605e-02  2.50108726e-02  2.89337393e-02\n",
      " -3.20521444e-02 -3.40233222e-02 -3.41698676e-02 -2.76981182e-02\n",
      "  6.47003129e-02  1.50797870e-02 -1.61925498e-02  3.03265937e-02\n",
      " -2.67187860e-02 -3.67774218e-02 -2.27845497e-02 -5.36433943e-02\n",
      "  1.90500021e-02 -3.42503376e-02  1.32688442e-02 -5.41318813e-03\n",
      "  7.49741821e-03 -7.37009745e-04 -3.08569707e-02  3.82288657e-02\n",
      " -2.08311230e-02 -3.43154930e-02  5.60238911e-03  1.45000098e-02\n",
      " -3.76364142e-02 -5.11782467e-02 -3.51075493e-02  1.71867963e-02\n",
      "  1.50721548e-02 -9.62026268e-02 -1.53545467e-02  1.58376452e-02\n",
      "  2.42940956e-07 -5.88808162e-03  7.68795833e-02  5.86063564e-02\n",
      "  2.21232697e-02 -2.36690864e-02  5.25274239e-02  1.48661416e-02\n",
      "  7.34179141e-03 -4.98920865e-03  4.37413752e-02 -1.28331883e-02\n",
      "  3.37342396e-02 -1.10814888e-02 -1.33938054e-02 -7.80063495e-02\n",
      " -1.36330593e-02  1.94749013e-02  1.91750925e-03 -3.00251786e-02\n",
      "  1.02691185e-04  9.54533294e-02  1.19653948e-01  3.73371728e-02\n",
      "  4.25125007e-03  2.05129907e-02 -3.85414846e-02 -1.90614536e-02\n",
      "  5.88793531e-02  6.81264624e-02 -3.12595740e-02 -6.50441125e-02\n",
      "  2.48045102e-02  3.90083675e-04  7.54761621e-02 -3.46075781e-02\n",
      "  1.32949334e-02  4.14005816e-02  3.07569169e-02  5.50354179e-03\n",
      " -1.53087277e-03  2.75993627e-02  6.46030158e-03  1.05398176e-02\n",
      " -3.09298709e-02  4.60232422e-02 -3.64921205e-02 -1.39540434e-02\n",
      " -3.53720710e-02  7.97824992e-04  1.40632782e-02  1.80258583e-02\n",
      " -1.43368607e-02  2.19214708e-03 -3.96873355e-02 -1.17282113e-02\n",
      " -4.45220545e-02  8.05770420e-03 -4.04861309e-02  3.56149152e-02\n",
      "  5.12852445e-02 -6.64038956e-02 -5.32594919e-02  8.92902352e-03\n",
      "  1.56424306e-02  1.02110937e-01  8.10770784e-03 -4.03859885e-03\n",
      "  2.02352536e-34 -1.38294064e-02 -1.17623620e-02  1.51006067e-02\n",
      "  8.25896338e-02  2.39228457e-02 -1.10378051e-02  3.65654519e-03\n",
      " -7.44783180e-03  2.94554979e-02  3.52995517e-03 -6.10421821e-02]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Requires !pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",\n",
    "                                      device=\"cuda\") # choose the device to load the model to (note: GPU will often be *much* faster than CPU)\n",
    "\n",
    "# Create a list of sentences to turn into numbers\n",
    "sentences = [\n",
    "    \"The Sentences Transformers library provides an easy and open-source way to create embeddings.\",\n",
    "    \"Sentences can be embedded one by one or as a list of strings.\",\n",
    "    \"Embeddings are one of the most powerful concepts in machine learning!\",\n",
    "    \"Learn to use embeddings well and you'll be well on your way to being an AI engineer.\"\n",
    "]\n",
    "\n",
    "# Sentences are encoded/embedded by calling model.encode()\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "embeddings_dict = dict(zip(sentences, embeddings))\n",
    "\n",
    "# See the embeddings\n",
    "for sentence, embedding in embeddings_dict.items():\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODZNQXgul065"
   },
   "source": [
    "Woah! That's a lot of numbers.\n",
    "\n",
    "How about we do just once sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "WoYXVVJel065",
    "outputId": "b8da0357-2ebb-47dd-8c67-f51c8435857c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Yo! How cool are embeddings?\n",
      "Embedding:\n",
      "[-1.97447482e-02 -4.51083714e-03 -4.98482492e-03  6.55445009e-02\n",
      " -9.87671968e-03  2.72835568e-02  3.66426110e-02 -3.30221280e-03\n",
      "  8.50079115e-03  8.24954547e-03 -2.28497442e-02  4.02430184e-02\n",
      " -5.75200021e-02  6.33692294e-02  4.43207473e-02 -4.49507162e-02\n",
      "  1.25284223e-02 -2.52012350e-02 -3.55292335e-02  1.29558872e-02\n",
      "  8.67024530e-03 -1.92917641e-02  3.55635560e-03  1.89506002e-02\n",
      " -1.47128012e-02 -9.39845853e-03  7.64171872e-03  9.62188747e-03\n",
      " -5.98928286e-03 -3.90169397e-02 -5.47824539e-02 -5.67456661e-03\n",
      "  1.11644994e-02  4.08067293e-02  1.76319099e-06  9.15297959e-03\n",
      " -8.77260044e-03  2.39382759e-02 -2.32784562e-02  8.04999545e-02\n",
      "  3.19176838e-02  5.12595987e-03 -1.47708356e-02 -1.62524562e-02\n",
      " -6.03213347e-02 -4.35689725e-02  4.51211482e-02 -1.79053750e-02\n",
      "  2.63367202e-02 -3.47867161e-02 -8.89172871e-03 -5.47674894e-02\n",
      " -1.24372896e-02 -2.38606650e-02  8.33496898e-02  5.71242124e-02\n",
      "  1.13328528e-02 -1.49594611e-02  9.20378417e-02  2.72709243e-02\n",
      " -1.42185939e-02  1.91209260e-02  1.49963228e-02 -3.12198643e-02\n",
      "  8.99579823e-02  4.51188534e-02  2.58020461e-02 -5.51741524e-03\n",
      "  1.15909772e-02  4.72100638e-02 -1.51018742e-02  1.70818474e-02\n",
      " -7.22598145e-03  3.45763154e-02 -8.76467675e-03  5.22016548e-02\n",
      " -6.49008900e-02 -4.31378707e-02  6.36964664e-02  4.02881205e-02\n",
      " -1.99043099e-02  5.39063942e-03  1.28820585e-02 -4.81255278e-02\n",
      "  4.58801389e-02 -2.17094850e-02  1.89203434e-02 -3.46344486e-02\n",
      " -1.66457538e-02  7.65167410e-03 -2.26693358e-02 -1.96454320e-02\n",
      "  1.87632348e-02  1.01383058e-02  6.85413331e-02 -5.39851096e-03\n",
      " -3.38229374e-03  4.08413187e-02  4.98623587e-02 -1.16485702e-02\n",
      "  8.91739130e-02  4.02785726e-02 -3.64715629e-03  4.37758416e-02\n",
      " -2.96079442e-02 -5.53758210e-03 -2.00209003e-02 -2.01983340e-02\n",
      "  4.59849201e-02  2.29337476e-02 -5.37305214e-02 -3.19279172e-02\n",
      "  1.37544516e-03  6.25036582e-02 -2.18308866e-02 -6.43255413e-02\n",
      " -2.24791579e-02  3.31954993e-02 -3.12837362e-02  5.17936535e-02\n",
      " -2.84002796e-02  2.55067609e-02  3.36492881e-02  7.50667453e-02\n",
      " -4.46477439e-03 -4.87705655e-02 -7.35218823e-02 -5.46353199e-02\n",
      "  8.88531469e-03  2.95797009e-02 -9.95698292e-03 -6.32764585e-03\n",
      "  4.46259677e-02 -1.58483926e-02 -1.71330161e-02  3.36602628e-02\n",
      " -1.57673669e-03 -5.45971990e-02  2.91161370e-02 -2.80596428e-02\n",
      "  2.96793431e-02  5.12153432e-02  1.48766255e-02 -4.76489253e-02\n",
      "  1.26052024e-02  1.49846170e-03  1.33206844e-02 -2.82468796e-02\n",
      " -3.29254717e-02 -8.53571109e-03 -5.27607650e-02  7.29350299e-02\n",
      " -6.41821325e-02 -2.51785270e-03 -9.02634952e-03 -1.10468804e-03\n",
      "  1.57514606e-02  4.30823714e-02  1.12269418e-02 -3.54585238e-02\n",
      "  4.95163426e-02  1.21271312e-02  1.66344142e-03 -5.06923348e-03\n",
      " -1.11001991e-02 -8.66917614e-03 -3.26440148e-02 -3.98021825e-02\n",
      " -2.05971245e-02  1.09074069e-02 -6.62529394e-02  3.71706709e-02\n",
      " -3.74916419e-02 -3.24731544e-02  5.85900024e-02  8.48080739e-02\n",
      "  3.92412357e-02  3.15814205e-02  3.78386565e-02 -1.35472659e-02\n",
      "  5.95062524e-02  2.58904938e-02 -1.31899957e-02  6.30589947e-02\n",
      "  3.27136889e-02  6.92141149e-03 -1.42606813e-02  7.76676685e-02\n",
      " -1.16103357e-02 -3.66427824e-02 -2.83837561e-02  2.72279810e-02\n",
      "  2.49365233e-02 -4.22296859e-03 -3.63100767e-02 -2.04887781e-02\n",
      "  3.98861095e-02 -2.64727455e-02  4.41382686e-03 -5.19635305e-02\n",
      "  1.71360953e-05  4.81284186e-02  2.04450246e-02  9.84970331e-02\n",
      "  3.68267894e-02  1.53405191e-02  7.50977953e-04 -3.38638760e-02\n",
      " -2.69872528e-02  4.72445413e-02  4.56702374e-02 -3.49246152e-02\n",
      " -1.18770394e-02  3.45578697e-03 -6.32300042e-03 -4.78412062e-02\n",
      "  1.84098631e-02 -2.23157480e-02 -3.70728038e-02  5.87340072e-02\n",
      "  6.22731587e-03 -1.46716051e-02  7.29223490e-02  2.21958780e-03\n",
      " -6.53119385e-02  3.51679511e-02 -1.54901613e-02  6.01421483e-02\n",
      " -9.41004604e-03  2.81196572e-02 -1.12651670e-02  5.24157600e-04\n",
      "  1.01888604e-01 -5.69957606e-02 -3.52360532e-02 -5.20476885e-03\n",
      " -8.46638158e-03  1.39209190e-02  1.80780292e-02 -1.10494018e-01\n",
      "  5.13116829e-02 -4.36432287e-02  2.84142829e-02  9.55941435e-03\n",
      "  4.28096354e-02 -3.95833254e-02  5.25829196e-02  1.92814805e-02\n",
      "  3.44889238e-03 -1.76870935e-02  3.85699086e-02  6.92507671e-03\n",
      " -3.59440632e-02 -2.63613500e-02 -4.96692583e-03  4.24526036e-02\n",
      " -4.22464050e-02  3.45897977e-03  3.55866700e-02 -1.68201849e-02\n",
      "  3.54331285e-02  4.52799909e-03  6.46285806e-03 -2.17710994e-02\n",
      " -2.50033587e-02  1.41418381e-02  1.51257794e-02 -2.99570095e-02\n",
      " -3.94227430e-02  1.87821761e-02 -1.68782321e-03 -9.83500388e-04\n",
      " -3.26321572e-02  5.06564742e-03 -8.90460890e-03 -1.55095328e-02\n",
      "  1.87758189e-02 -4.52472977e-02 -1.72956958e-02  3.50973569e-02\n",
      "  1.33018196e-02  1.00633400e-02 -4.36593518e-02 -1.68619324e-02\n",
      " -1.91048104e-02  6.35489151e-02  8.08325037e-03 -1.02532981e-02\n",
      " -4.53625293e-03 -4.60835919e-02 -1.64704509e-02 -6.24686573e-03\n",
      "  2.58868430e-02 -6.39064312e-02 -7.82397017e-03 -2.36076061e-02\n",
      "  2.74617579e-02  5.80535643e-02 -3.40748802e-02  6.46012202e-02\n",
      "  2.00063139e-02 -2.14935541e-02  1.69361047e-02 -5.54066058e-03\n",
      " -2.40397155e-02  3.09443735e-02 -2.34441948e-03  3.02590001e-02\n",
      " -4.57217880e-02  2.00641416e-02 -2.57117078e-02 -1.13376952e-03\n",
      " -3.57524678e-02  6.92953393e-02  2.80844164e-03  3.58742326e-02\n",
      " -1.52722728e-02 -3.41523327e-02  1.80923212e-02  1.65400058e-02\n",
      "  1.31705785e-02 -6.36677351e-03  5.49303479e-02  8.47315975e-03\n",
      " -4.26077135e-02  2.17085406e-02 -4.89023812e-02  1.18925047e-04\n",
      "  5.16286455e-02  7.59207818e-04  1.59222856e-02 -1.61299985e-02\n",
      "  1.44981612e-02  2.19508670e-02  3.02651450e-02 -3.44151556e-02\n",
      " -4.80380319e-02 -3.71690840e-02  4.68194634e-02 -3.46219279e-02\n",
      "  4.74828237e-04 -4.34820466e-02 -1.80124827e-02 -6.44845441e-02\n",
      " -2.66967788e-02  3.63660567e-02 -3.76219191e-02 -1.64600797e-02\n",
      "  2.20249202e-02  2.16018161e-04  3.64510342e-02 -2.76135597e-02\n",
      " -5.87059325e-03  6.97317207e-03 -1.25864451e-03  2.12773588e-02\n",
      "  6.21467736e-03 -3.57214026e-02 -5.09367175e-02  2.85553113e-02\n",
      "  6.48821816e-02  3.45731191e-02 -2.57280990e-02  4.52552829e-03\n",
      " -4.63605858e-02  3.32225636e-02  1.69977732e-03 -1.29354866e-02\n",
      " -3.03734578e-02  1.23609323e-02 -3.17942817e-04  1.66232195e-02\n",
      "  1.04892068e-02  1.71540510e-02  1.88860502e-02 -3.62256654e-02\n",
      "  4.65737022e-02  2.17129495e-02  4.97536734e-02  3.03067379e-02\n",
      "  1.59916270e-03 -6.30024523e-02 -6.34590676e-03  1.07311680e-04\n",
      " -5.56743983e-03  2.37264447e-02 -8.38231388e-03  5.38897254e-02\n",
      " -9.08976719e-02 -1.37359742e-02  1.18454266e-02  3.37265804e-03\n",
      " -2.81855222e-02  1.56337360e-03  2.22415235e-02  6.21024333e-02\n",
      " -8.68120864e-02 -4.40636184e-03 -1.63995549e-02  1.69665106e-02\n",
      " -1.34548368e-02  3.00701382e-03 -2.14617867e-02 -2.09503751e-02\n",
      " -1.39878122e-02 -1.23850219e-02  5.39979562e-02  6.03615008e-02\n",
      "  2.52982490e-02 -1.29661411e-01 -1.08081624e-01 -4.15776111e-03\n",
      " -7.20269838e-03  2.75885388e-02  4.87622209e-02 -2.95971315e-02\n",
      " -4.32554819e-02  2.75214985e-02  1.35718649e-02  3.87700349e-02\n",
      "  2.42039971e-02 -2.70842314e-02  8.59166011e-02 -1.98402517e-02\n",
      " -2.26343870e-02 -6.24927655e-02 -1.56844892e-02  4.11566496e-02\n",
      "  1.66952573e-02  7.97291473e-02 -3.24839130e-02  1.46564597e-03\n",
      " -3.27905975e-02  6.44815192e-02  2.09739301e-02 -7.56984949e-02\n",
      " -1.31795625e-03  2.24046316e-03 -6.60838466e-03 -6.84252307e-02\n",
      " -5.36860852e-03  6.55135512e-02  5.45568718e-03  1.58993062e-02\n",
      " -2.18052100e-02  2.16421345e-03  4.72959410e-03 -7.25654885e-02\n",
      " -1.59350727e-02 -1.05623119e-02  2.70786379e-02  1.93770020e-03\n",
      " -4.45122570e-02  2.89782919e-02  2.43083555e-02 -1.73885599e-02\n",
      " -3.80669311e-02 -3.06799207e-02 -3.24778147e-02 -4.33336420e-04\n",
      "  2.55846605e-02  2.70478558e-02 -1.72474902e-04 -4.93671570e-04\n",
      " -7.12094307e-02  5.69768772e-02  6.61401153e-02 -3.87267880e-02\n",
      " -1.30683789e-02  1.00663370e-02 -2.17740145e-02  1.92212630e-02\n",
      "  7.66692031e-03 -3.86652686e-02 -1.66109186e-02 -3.41467969e-02\n",
      " -1.04186218e-02  1.75906345e-02 -1.23776291e-02 -1.68434083e-02\n",
      " -2.40112878e-02  4.70195059e-03  4.88457037e-03  4.73663397e-02\n",
      "  4.34112139e-02 -8.08339287e-03 -2.48272233e-02 -1.93978008e-02\n",
      " -3.16525623e-02 -1.56418588e-02 -7.79947126e-03  1.28888143e-02\n",
      "  2.61943545e-02  3.65826674e-03  5.79228476e-02  5.43152057e-02\n",
      " -5.05587161e-02  1.78920361e-03 -2.45471038e-02 -2.47596204e-02\n",
      "  3.60354176e-03  1.94152538e-02 -4.23822962e-02 -1.86907127e-02\n",
      "  2.32946388e-02 -3.17982771e-02 -2.60645617e-02 -5.40358713e-03\n",
      " -3.82070281e-02  2.21719686e-02  1.33360550e-02  5.58054261e-02\n",
      " -3.57716866e-02 -3.54791805e-02  1.27723301e-02  6.80178180e-02\n",
      "  5.37151955e-02  2.54151542e-02 -1.16639193e-02 -1.07512558e-02\n",
      " -9.74426605e-03  7.20506487e-03  9.21904389e-03 -4.73684780e-02\n",
      " -3.89397307e-03  3.11453696e-02  3.62331942e-02 -1.65903158e-02\n",
      " -3.63394432e-02  1.95634961e-02 -2.15059184e-02 -7.04772118e-03\n",
      "  9.13179107e-03 -4.05358374e-02 -3.67075615e-02  1.16995983e-01\n",
      "  1.17913850e-01  8.00503418e-02 -1.61983352e-02 -2.00732816e-02\n",
      " -5.54061346e-02 -7.22410679e-02  2.14557331e-02 -4.46441787e-04\n",
      " -1.42903300e-02  8.35543312e-03  3.34207267e-02  1.42891230e-02\n",
      "  4.62512746e-02 -3.53420489e-02  1.68673582e-02 -2.99740909e-03\n",
      " -5.44997044e-02 -4.80719693e-02  9.47544875e-04 -6.29721654e-33\n",
      " -2.30286438e-02 -2.51127873e-02 -5.35219461e-02 -2.09470168e-02\n",
      " -6.79715350e-03 -4.64015789e-02 -4.49631456e-03  1.65114906e-02\n",
      " -1.12677775e-02  1.33013520e-02 -1.72552820e-02 -1.96653251e-02\n",
      "  5.53235505e-03  1.02775563e-02  9.47347027e-04 -2.24023033e-02\n",
      "  5.30364737e-02  7.77775282e-03 -9.48472135e-03  2.25515962e-02\n",
      " -4.34492249e-03  2.25208588e-02  1.98086351e-02 -7.57428780e-02\n",
      " -4.36679320e-03  2.50829607e-02  2.59393342e-02 -3.07076629e-02\n",
      "  7.04764798e-02  8.63500610e-02 -7.75880441e-02  1.59991737e-02\n",
      " -5.04692160e-02  4.88355123e-02  3.74994357e-03 -6.12926262e-04\n",
      " -3.87277529e-02 -2.32235566e-02 -3.63983363e-02 -5.07025793e-03\n",
      "  1.10517936e-02 -3.26515622e-02  3.68387289e-02 -4.54949550e-02\n",
      " -1.18533219e-03  1.92691654e-03  2.18783766e-02  2.71093231e-02\n",
      " -4.06263769e-02  6.99159801e-02 -7.33281747e-02 -8.15294031e-03\n",
      " -1.42555702e-02  3.78031377e-03  1.20974272e-01 -6.68213442e-02\n",
      "  3.05051822e-02  1.24480631e-02 -4.59294505e-02  1.03872959e-02\n",
      " -3.97978090e-02 -1.33042084e-02 -1.59402210e-02 -4.29347157e-02\n",
      "  4.05275300e-02  7.07073957e-02 -4.50929552e-02 -3.62473391e-02\n",
      " -1.87588837e-02  1.60928089e-02  2.12657340e-02  6.70026019e-02\n",
      "  3.25864665e-02  1.51126049e-02  3.20371911e-02 -1.35436021e-02\n",
      "  2.31780857e-02 -1.13125425e-02  1.23796072e-02 -3.73517126e-02\n",
      "  1.55541906e-03  2.15824191e-02 -3.49441990e-02 -2.97690462e-02\n",
      "  2.32397765e-02 -1.25702573e-02 -1.09432777e-02 -8.87969136e-02\n",
      " -2.20183823e-02 -1.18423002e-02 -5.71083613e-02  3.91809531e-02\n",
      " -1.98827442e-02 -5.59270680e-02  7.60347676e-03  2.23641749e-02\n",
      " -1.86266955e-02  3.79805490e-02 -8.79606989e-04 -5.26199415e-02\n",
      "  2.05063773e-03  1.72815304e-02 -4.84029129e-02 -1.87740661e-02\n",
      "  9.82840191e-08  2.06594896e-02  3.03574465e-02  5.71858697e-03\n",
      " -5.33938445e-02 -2.46520881e-02  1.80341452e-02 -3.39978226e-02\n",
      "  3.46393754e-05 -6.40035272e-02  2.50049569e-02 -2.04112139e-02\n",
      " -2.72042444e-03 -3.55961472e-02  2.71922927e-02  6.48940429e-02\n",
      "  9.83456615e-04 -4.38491069e-02 -4.45296802e-02 -7.44884461e-03\n",
      "  1.15205320e-02 -2.91253487e-03 -2.15495229e-02  2.84248521e-03\n",
      "  4.29399312e-02 -6.09040521e-02 -7.86324218e-03 -3.90127441e-03\n",
      "  2.47718305e-07  7.75856082e-04  7.47736692e-02  1.99314253e-03\n",
      " -6.07223576e-03  3.69210541e-02  2.78421156e-02 -5.64900488e-02\n",
      "  1.61058959e-02 -9.50820278e-03 -2.60852836e-03 -2.45737787e-02\n",
      "  1.91390626e-02  5.08196205e-02  2.61258874e-02 -1.03838064e-01\n",
      " -3.05815972e-02 -3.53344530e-02 -4.07037176e-02 -2.19842251e-02\n",
      " -2.24092342e-02  5.05567938e-02  7.22607300e-02  5.54789566e-02\n",
      "  4.89434302e-02  3.37951025e-03 -6.84760213e-02  7.10320845e-03\n",
      "  3.15669365e-03  4.78091463e-02 -7.19796121e-02 -3.30301449e-02\n",
      "  3.19159552e-02  1.76428293e-03 -4.62790541e-02 -1.96379647e-02\n",
      "  1.67493951e-02  4.73603792e-02 -2.09441260e-02  7.10241217e-03\n",
      "  4.53146249e-02 -4.76523489e-02 -4.74880971e-02  1.00799482e-02\n",
      " -8.39594901e-02  3.36930044e-02 -3.72189730e-02  1.19432351e-02\n",
      " -3.16896439e-02 -1.29722897e-03 -1.55541347e-02  1.81728359e-02\n",
      " -1.49368802e-02 -1.70671400e-02 -4.19716462e-02  3.94657440e-03\n",
      " -2.24301796e-02  2.07292121e-02 -4.61415462e-02  8.50215554e-03\n",
      " -2.56865062e-02 -1.65337883e-02 -1.51847014e-02 -1.00041814e-02\n",
      "  2.19642632e-02  2.61104126e-02  7.31358975e-02 -1.83709357e-02\n",
      "  1.93979458e-34 -7.27937045e-03  5.96489012e-03  4.44310978e-02\n",
      "  4.14822884e-02  1.12917265e-02 -1.93217676e-02  4.41878550e-02\n",
      " -8.93788971e-03  3.61120105e-02 -5.52126244e-02 -2.89572217e-02]\n",
      "Embedding size: (768,)\n"
     ]
    }
   ],
   "source": [
    "single_sentence = \"Yo! How cool are embeddings?\"\n",
    "single_embedding = embedding_model.encode(single_sentence)\n",
    "print(f\"Sentence: {single_sentence}\")\n",
    "print(f\"Embedding:\\n{single_embedding}\")\n",
    "print(f\"Embedding size: {single_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4e9PtXCyl065"
   },
   "source": [
    "Nice! We've now got a way to numerically represent each of our chunks.\n",
    "\n",
    "Our embedding has a shape of `(768,)` meaning it's a vector of 768 numbers which represent our text in high-dimensional space, too many for a human to comprehend but machines love high-dimensional space.\n",
    "\n",
    "> **Note:** No matter the size of the text input to our `all-mpnet-base-v2` model, it will be turned into an embedding size of `(768,)`. This value is fixed. So whether a sentence is 1 token long or 1000 tokens long, it will be truncated/padded with zeros to size 384 and then turned into an embedding vector of size `(768,)`. Of course, other embedding models may have different input/output shapes.\n",
    "\n",
    "How about we add an embedding field to each of our chunk items?\n",
    "\n",
    "Let's start by trying to create embeddings on the CPU, we'll time it with the `%%time` magic to see how long it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "QrRM1RZal065",
    "outputId": "f02ab3fd-e9f3-4312-ca1c-76b10bc5cc60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Uncomment to see how long it takes to create embeddings on CPU\n",
    "# # Make sure the model is on the CPU\n",
    "# embedding_model.to(\"cpu\")\n",
    "\n",
    "# # Embed each chunk one by one\n",
    "# for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "#     item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQCsBIyol065"
   },
   "source": [
    "Ok not too bad... but this would take a *really* long time if we had a larger dataset.\n",
    "\n",
    "Now let's see how long it takes to create the embeddings with a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "93f0fc4be888494193dc535a676cc431"
     ]
    },
    "id": "xgBA-lF1l065",
    "outputId": "8ed1728c-b294-4326-dd1a-a2dc7258c2ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:03<00:00, 55.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.97 s\n",
      "Wall time: 3.56 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Send the model to the GPU\n",
    "embedding_model.to(\"cuda\") # requires a GPU installed, for reference on my local machine, I'm using a NVIDIA RTX 4090\n",
    "\n",
    "# Create embeddings one by one on the GPU\n",
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlVYxBp0l066"
   },
   "source": [
    "Woah! Looks like the embeddings get created much faster (~10x faster on my machine) on the GPU!\n",
    "\n",
    "You'll likely notice this trend with many of your deep learning workflows. If you have access to a GPU, especially a NVIDIA GPU, you should use one if you can.\n",
    "\n",
    "But what if I told you we could go faster again?\n",
    "\n",
    "You see many modern models can handle batched predictions.\n",
    "\n",
    "This means computing on multiple samples at once.\n",
    "\n",
    "Those are the types of operations where a GPU flourishes!\n",
    "\n",
    "We can perform batched operations by turning our target text samples into a single list and then passing that list to our embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "LlNOpG-Ql066"
   },
   "outputs": [],
   "source": [
    "# Turn text chunks into a single list\n",
    "text_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks_over_min_token_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "cDaRZCr-l066",
    "outputId": "b388751f-42ea-4cb1-8a39-2133cffcd4be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.06 s\n",
      "Wall time: 3.03 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0068, -0.0498, -0.0305,  ..., -0.0212, -0.0335, -0.0145],\n",
       "        [ 0.0720, -0.0776,  0.0147,  ..., -0.0024, -0.0726, -0.0001],\n",
       "        [ 0.0319, -0.0595, -0.0103,  ..., -0.0043, -0.0772, -0.0126],\n",
       "        ...,\n",
       "        [ 0.0313,  0.0054, -0.0286,  ...,  0.0091, -0.0014,  0.0090],\n",
       "        [ 0.0250, -0.0382,  0.0085,  ...,  0.0007, -0.0105, -0.0290],\n",
       "        [-0.0733,  0.0374, -0.0053,  ...,  0.0104, -0.0782, -0.0013]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Embed all texts in batches\n",
    "text_chunk_embeddings = embedding_model.encode(text_chunks,\n",
    "                                               batch_size=32, # you can use different batch sizes here for speed/performance, I found 32 works well for this use case\n",
    "                                               convert_to_tensor=True) # optional to return embeddings as tensor instead of array\n",
    "\n",
    "text_chunk_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0U8Xdk49l066"
   },
   "source": [
    "That's what I'm talking about!\n",
    "\n",
    "A ~4x improvement (on my GPU) in speed thanks to batched operations.\n",
    "\n",
    "So the tip here is to use a GPU when you can and use batched operations if you can too.\n",
    "\n",
    "Now let's save our chunks and their embeddings so we could import them later if we wanted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zulo_C8l066"
   },
   "source": [
    "### Save embeddings to file\n",
    "\n",
    "Since creating embeddings can be a timely process (not so much for our case but it can be for more larger datasets), let's turn our `pages_and_chunks_over_min_token_len` list of dictionaries into a DataFrame and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "_afqLY-El066"
   },
   "outputs": [],
   "source": [
    "# Save embeddings to file\n",
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
    "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k80jmZbdl066"
   },
   "source": [
    "And we can make sure it imports nicely by loading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "I35ImH-5l066",
    "outputId": "9efa8a19-4bcc-4bfa-8aa6-21d23eeba299"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
       "      <td>Hilti Malaysia Sdn. Bhd. (157721-A) F-5-A | Si...</td>\n",
       "      <td>281</td>\n",
       "      <td>50</td>\n",
       "      <td>70.25</td>\n",
       "      <td>[ 6.78907195e-03 -4.97652031e-02 -3.04607451e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
       "      <td>GENERAL  1.1  In these conditions the followin...</td>\n",
       "      <td>1934</td>\n",
       "      <td>335</td>\n",
       "      <td>483.50</td>\n",
       "      <td>[ 7.20427632e-02 -7.75793642e-02  1.46522094e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
       "      <td>Hilti Malaysia Sdn. Bhd. (157721-A) F-5-A | Si...</td>\n",
       "      <td>872</td>\n",
       "      <td>156</td>\n",
       "      <td>218.00</td>\n",
       "      <td>[ 3.19398865e-02 -5.95324412e-02 -1.02918353e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
       "      <td>The Company accordingly reserves the right to ...</td>\n",
       "      <td>1133</td>\n",
       "      <td>209</td>\n",
       "      <td>283.25</td>\n",
       "      <td>[ 4.59260643e-02 -1.06616899e-01  1.31733194e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Hilti Malaysia - Terms and Conditions 2019.pdf</td>\n",
       "      <td>Any such additional costs may be invoiced by t...</td>\n",
       "      <td>702</td>\n",
       "      <td>130</td>\n",
       "      <td>175.50</td>\n",
       "      <td>[ 3.28748487e-02 -7.55417421e-02 -3.63777671e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                        pdf_name  \\\n",
       "0            1  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
       "1            1  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
       "2            2  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
       "3            2  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
       "4            2  Hilti Malaysia - Terms and Conditions 2019.pdf   \n",
       "\n",
       "                                      sentence_chunk  chunk_char_count  \\\n",
       "0  Hilti Malaysia Sdn. Bhd. (157721-A) F-5-A | Si...               281   \n",
       "1  GENERAL  1.1  In these conditions the followin...              1934   \n",
       "2  Hilti Malaysia Sdn. Bhd. (157721-A) F-5-A | Si...               872   \n",
       "3  The Company accordingly reserves the right to ...              1133   \n",
       "4  Any such additional costs may be invoiced by t...               702   \n",
       "\n",
       "   chunk_word_count  chunk_token_count  \\\n",
       "0                50              70.25   \n",
       "1               335             483.50   \n",
       "2               156             218.00   \n",
       "3               209             283.25   \n",
       "4               130             175.50   \n",
       "\n",
       "                                           embedding  \n",
       "0  [ 6.78907195e-03 -4.97652031e-02 -3.04607451e-...  \n",
       "1  [ 7.20427632e-02 -7.75793642e-02  1.46522094e-...  \n",
       "2  [ 3.19398865e-02 -5.95324412e-02 -1.02918353e-...  \n",
       "3  [ 4.59260643e-02 -1.06616899e-01  1.31733194e-...  \n",
       "4  [ 3.28748487e-02 -7.55417421e-02 -3.63777671e-...  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import saved file and view\n",
    "text_chunks_and_embedding_df_load = pd.read_csv(embeddings_df_save_path)\n",
    "text_chunks_and_embedding_df_load.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpksJFHgl067"
   },
   "source": [
    "## 2. RAG - Search and Answer\n",
    "\n",
    "We discussed RAG briefly in the beginning but let's quickly recap.\n",
    "\n",
    "RAG stands for Retrieval Augmented Generation.\n",
    "\n",
    "Which is another way of saying \"given a query, search for relevant resources and answer based on those resources\".\n",
    "\n",
    "Let's breakdown each step:\n",
    "* **Retrieval** - Get relevant resources given a query. For example, if the query is \"what are the macronutrients?\" the ideal results will contain information about protein, carbohydrates and fats (and possibly alcohol) rather than information about which tractors are the best for farming (though that is also cool information).\n",
    "* **Augmentation** - LLMs are capable of generating text given a prompt. However, this generated text is designed to *look* right. And it often has some correct information, however, they are prone to hallucination (generating a result that *looks* like legit text but is factually wrong). In augmentation, we pass relevant information into the prompt and get an LLM to use that relevant information as the basis of its generation.\n",
    "* **Generation** - This is where the LLM will generate a response that has been flavoured/augmented with the retrieved resources. In turn, this not only gives us a potentially more correct answer, it also gives us resources to investigate more (since we know which resources went into the prompt).\n",
    "\n",
    "The whole idea of RAG is to get an LLM to be more factually correct based on your own input as well as have a reference to where the generated output may have come from.\n",
    "\n",
    "This is an incredibly helpful tool.\n",
    "\n",
    "Let's say you had 1000s of customer support documents.\n",
    "\n",
    "You could use RAG to generate direct answers to questions with links to relevant documentation.\n",
    "\n",
    "Or you were an insurance company with large chains of claims emails.\n",
    "\n",
    "You could use RAG to answer questions about the emails with sources.\n",
    "\n",
    "One helpful analogy is to think of LLMs as calculators for words.\n",
    "\n",
    "With good inputs, the LLM can sort them into helpful outputs.\n",
    "\n",
    "How?\n",
    "\n",
    "It starts with better search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXx2x6Sul067"
   },
   "source": [
    "### Similarity search\n",
    "\n",
    "Similarity search or semantic search or vector search is the idea of searching on *vibe*.\n",
    "\n",
    "If this sounds like woo, woo. It's not.\n",
    "\n",
    "Perhaps searching via *meaning* is a better analogy.\n",
    "\n",
    "With keyword search, you are trying to match the string \"apple\" with the string \"apple\".\n",
    "\n",
    "Whereas with similarity/semantic search, you may want to search \"macronutrients functions\".\n",
    "\n",
    "And get back results that don't necessarily contain the words \"macronutrients functions\" but get back pieces of text that match that meaning.\n",
    "\n",
    "> **Example:** Using similarity search on our textbook data with the query \"macronutrients function\" returns a paragraph that starts with:\n",
    ">\n",
    ">*There are three classes of macronutrients: carbohydrates, lipids, and proteins. These can be metabolically processed into cellular energy. The energy from macronutrients comes from their chemical bonds. This chemical energy is converted into cellular energy that is then utilized to perform work, allowing our bodies to conduct their basic functions.*\n",
    ">\n",
    "> as the first result. How cool!\n",
    "\n",
    "If you've ever used Google, you know this kind of workflow.\n",
    "\n",
    "But now we'd like to perform that across our own data.\n",
    "\n",
    "Let's import our embeddings we created earlier (tk -link to embedding file) and prepare them for use by turning them into a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2Yy0Pg3gl067",
    "outputId": "262d4680-a5e2-4e57-8443-aa74ffa12b3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([133, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Import texts and embedding df\n",
    "text_chunks_and_embedding_df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
    "\n",
    "# Convert embedding column back to np.array (it got converted to string when it got saved to CSV)\n",
    "text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
    "\n",
    "# Convert texts and embedding df to list of dicts\n",
    "pages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")\n",
    "\n",
    "# Convert embeddings to torch tensor and send to device (note: NumPy arrays are float64, torch tensors are float32 by default)\n",
    "embeddings = torch.tensor(np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()), dtype=torch.float32).to(device)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bxIEBi69l067",
    "outputId": "afc5648b-ddf4-432a-c639-ceeb3950d941"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10_Object and Class Structuring.pptx</td>\n",
       "      <td>Object and Class Structuring CT015-3-2 Design ...</td>\n",
       "      <td>417</td>\n",
       "      <td>63</td>\n",
       "      <td>104.25</td>\n",
       "      <td>[0.00895868056, -0.0445464216, -0.0190935209, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10_Object and Class Structuring.pptx</td>\n",
       "      <td>Object and class structuring criteria are prov...</td>\n",
       "      <td>533</td>\n",
       "      <td>77</td>\n",
       "      <td>133.25</td>\n",
       "      <td>[-0.0127386739, -0.000978663214, 0.00970725249...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10_Object and Class Structuring.pptx</td>\n",
       "      <td>Object and Class Structuring Criteria Slide &lt;6...</td>\n",
       "      <td>386</td>\n",
       "      <td>61</td>\n",
       "      <td>96.50</td>\n",
       "      <td>[0.010841215, -0.0202376209, 0.00245435373, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>10_Object and Class Structuring.pptx</td>\n",
       "      <td>System Interface Objects represent external sy...</td>\n",
       "      <td>321</td>\n",
       "      <td>45</td>\n",
       "      <td>80.25</td>\n",
       "      <td>[-0.0332218222, -0.0271735694, -0.00854785275,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>10_Object and Class Structuring.pptx</td>\n",
       "      <td>– Software object that contains the details of...</td>\n",
       "      <td>580</td>\n",
       "      <td>84</td>\n",
       "      <td>145.00</td>\n",
       "      <td>[0.0173595063, -0.0475490652, -0.00125845731, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                              pdf_name  \\\n",
       "0            1  10_Object and Class Structuring.pptx   \n",
       "1            1  10_Object and Class Structuring.pptx   \n",
       "2            2  10_Object and Class Structuring.pptx   \n",
       "3            2  10_Object and Class Structuring.pptx   \n",
       "4            3  10_Object and Class Structuring.pptx   \n",
       "\n",
       "                                      sentence_chunk  chunk_char_count  \\\n",
       "0  Object and Class Structuring CT015-3-2 Design ...               417   \n",
       "1  Object and class structuring criteria are prov...               533   \n",
       "2  Object and Class Structuring Criteria Slide <6...               386   \n",
       "3  System Interface Objects represent external sy...               321   \n",
       "4  – Software object that contains the details of...               580   \n",
       "\n",
       "   chunk_word_count  chunk_token_count  \\\n",
       "0                63             104.25   \n",
       "1                77             133.25   \n",
       "2                61              96.50   \n",
       "3                45              80.25   \n",
       "4                84             145.00   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.00895868056, -0.0445464216, -0.0190935209, ...  \n",
       "1  [-0.0127386739, -0.000978663214, 0.00970725249...  \n",
       "2  [0.010841215, -0.0202376209, 0.00245435373, 0....  \n",
       "3  [-0.0332218222, -0.0271735694, -0.00854785275,...  \n",
       "4  [0.0173595063, -0.0475490652, -0.00125845731, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embedding_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaPjacwRl067"
   },
   "source": [
    "Nice!\n",
    "\n",
    "Now let's prepare another instance of our embedding model. Not because we have to but because we'd like to make it so you can start the notebook from the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TX5ueeAjl068"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\\HuggingFace\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util, SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",\n",
    "                                      device=device) # choose the device to load the model to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pEejPWdl068"
   },
   "source": [
    "Embedding model ready!\n",
    "\n",
    "Time to perform a semantic search.\n",
    "\n",
    "Let's say you were studying the macronutrients.\n",
    "\n",
    "And wanted to search your textbook for \"macronutrients functions\".\n",
    "\n",
    "Well, we can do so with the following steps:\n",
    "1. Define a query string (e.g. `\"macronutrients functions\"`) - note: this could be anything, specific or not.\n",
    "2. Turn the query string in an embedding with same model we used to embed our text chunks.\n",
    "3. Perform a [dot product](https://pytorch.org/docs/stable/generated/torch.dot.html) or [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) function between the text embeddings and the query embedding (we'll get to what these are shortly) to get similarity scores.\n",
    "4. Sort the results from step 3 in descending order (a higher score means more similarity in the eyes of the model) and use these values to inspect the texts.\n",
    "\n",
    "Easy!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhQEO3prl068"
   },
   "source": [
    "Woah!! Now that was fast!\n",
    "\n",
    "~0.00008 seconds to perform a dot product comparison across 1680 embeddings on my machine (NVIDIA RTX 4090 GPU).\n",
    "\n",
    "GPUs are optimized for these kinds of operations.\n",
    "\n",
    "So even if you we're to increase our embeddings by 100x (1680 -> 168,000), an exhaustive dot product operation would happen in ~0.008 seconds (assuming linear scaling).\n",
    "\n",
    "Heck, let's try it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "we9I-8-Al068"
   },
   "source": [
    "Wow. That's quick!\n",
    "\n",
    "That means we can get pretty far by just storing our embeddings in `torch.tensor` for now.\n",
    "\n",
    "However, for *much* larger datasets, we'd likely look at a dedicated vector database/indexing libraries such as [Faiss](https://github.com/facebookresearch/faiss).\n",
    "\n",
    "Let's check the results of our original similarity search.\n",
    "\n",
    "[`torch.topk`](https://pytorch.org/docs/stable/generated/torch.topk.html) returns a tuple of values (scores) and indicies for those scores.\n",
    "\n",
    "The indicies relate to which indicies in the `embeddings` tensor have what scores in relation to the query embedding (higher is better).\n",
    "\n",
    "We can use those indicies to map back to our text chunks.\n",
    "\n",
    "First, we'll define a small helper function to print out wrapped text (so it doesn't print a whole text chunk as a single line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gXrIPk0rl068"
   },
   "outputs": [],
   "source": [
    "# Define helper function to print wrapped text\n",
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIuczigYl068"
   },
   "source": [
    "Now we can loop through the `top_results_dot_product` tuple and match up the scores and indicies and then use those indicies to index on our `pages_and_chunks` variable to get the relevant text chunk.\n",
    "\n",
    "Sounds like a lot but we can do it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reqnCTpMl069"
   },
   "source": [
    "The first result looks to have nailed it!\n",
    "\n",
    "We get a very relevant answer to our query `\"macronutrients functions\"` even though its quite vague.\n",
    "\n",
    "That's the power of semantic search!\n",
    "\n",
    "And even better, if we wanted to inspect the result further, we get the page number where the text appears.\n",
    "\n",
    "How about we check the page to verify?\n",
    "\n",
    "We can do so by loading the page number containing the highest result (page 5 but really page 5 + 41 since our PDF page numbers start on page 41)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrZohOTEl069"
   },
   "source": [
    "Nice!\n",
    "\n",
    "Now we can do extra research if we'd like.\n",
    "\n",
    "We could repeat this workflow for any kind of query we'd like on our textbook.\n",
    "\n",
    "And it would also work for other datatypes too.\n",
    "\n",
    "We could use semantic search on customer support documents.\n",
    "\n",
    "Or email threads.\n",
    "\n",
    "Or company plans.\n",
    "\n",
    "Or our old journal entries.\n",
    "\n",
    "Almost anything!\n",
    "\n",
    "The workflow is the same:\n",
    "\n",
    "`ingest documents -> split into chunks -> embed chunks -> make a query -> embed the query -> compare query embedding to chunk embeddings`\n",
    "\n",
    "And we get relevant resources *along with* the source they came from!\n",
    "\n",
    "That's the **retrieval** part of Retrieval Augmented Generation (RAG).\n",
    "\n",
    "Before we get to the next two steps, let's take a small aside and discuss similarity measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjRxBCBAl069"
   },
   "source": [
    "### Similarity measures: dot product and cosine similarity\n",
    "\n",
    "Let's talk similarity measures between vectors.\n",
    "\n",
    "Specifically, embedding vectors which are representations of data with magnitude and direction in high dimensional space (our embedding vectors have 768 dimensions).\n",
    "\n",
    "Two of the most common you'll across are the dot product and cosine similarity.\n",
    "\n",
    "They are quite similar.\n",
    "\n",
    "The main difference is that cosine similarity has a normalization step.\n",
    "\n",
    "| Similarity measure | Description | Code |\n",
    "| ----- | ----- | ----- |\n",
    "| [Dot Product](https://en.wikipedia.org/wiki/Dot_product) | - Measure of magnitude and direction between two vectors<br>- Vectors that are aligned in direction and magnitude have a higher positive value<br>- Vectors that are opposite in direction and magnitude have a higher negative value | [`torch.dot`](https://pytorch.org/docs/stable/generated/torch.dot.html), [`np.dot`](https://numpy.org/doc/stable/reference/generated/numpy.dot.html), [`sentence_transformers.util.dot_score`](https://www.sbert.net/docs/package_reference/util.html#sentence_transformers.util.dot_score) |\n",
    "| [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) | - Vectors get normalized by magnitude/[Euclidean norm](https://en.wikipedia.org/wiki/Norm_(mathematics))/L2 norm so they have unit length and are compared more so on direction<br>- Vectors that are aligned in direction have a value close to 1<br>- Vectors that are opposite in direction have a value close to -1 | [`torch.nn.functional.cosine_similarity`](https://pytorch.org/docs/stable/generated/torch.nn.functional.cosine_similarity.html), [`1 - scipy.spatial.distance.cosine`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html) (subtract the distance from 1 for similarity measure), [`sentence_transformers.util.cos_sim`](https://www.sbert.net/docs/package_reference/util.html#sentence_transformers.util.cos_sim) |\n",
    "\n",
    "For text similarity, you generally want to use cosine similarity as you are after the semantic measurements (direction) rather than magnitude.\n",
    "\n",
    "In our case, our embedding model `all-mpnet-base-v2` outputs normalized outputs (see the [Hugging Face model card](https://huggingface.co/sentence-transformers/all-mpnet-base-v2#usage-huggingface-transformers) for more on this) so dot product and cosine similarity return the same results. However, dot product is faster due to not need to perform a normalize step.\n",
    "\n",
    "To make things bit more concrete, let's make simple dot product and cosine similarity functions and view their results on different vectors.\n",
    "\n",
    "> **Note:** Similarity measures between vectors and embeddings can be used on any kind of embeddings, not just text embeddings. For example, you could measure image embedding similarity or audio embedding similarity. Or with text and image models like [CLIP](https://github.com/mlfoundations/open_clip), you can measure the similarity between text and image embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "f-bDNw8fl069",
    "outputId": "88cdd01d-e272-4bef-ad74-0c459d4662e7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def dot_product(vector1, vector2):\n",
    "    return torch.dot(vector1, vector2)\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = torch.dot(vector1, vector2)\n",
    "\n",
    "    # Get Euclidean/L2 norm of each vector (removes the magnitude, keeps direction)\n",
    "    norm_vector1 = torch.sqrt(torch.sum(vector1**2))\n",
    "    norm_vector2 = torch.sqrt(torch.sum(vector2**2))\n",
    "\n",
    "    return dot_product / (norm_vector1 * norm_vector2)\n",
    "\n",
    "# Example tensors\n",
    "#vector1 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "#vector2 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "#vector3 = torch.tensor([4, 5, 6], dtype=torch.float32)\n",
    "#vector4 = torch.tensor([-1, -2, -3], dtype=torch.float32)\n",
    "#\n",
    "## Calculate dot product\n",
    "#print(\"Dot product between vector1 and vector2:\", dot_product(vector1, vector2))\n",
    "#print(\"Dot product between vector1 and vector3:\", dot_product(vector1, vector3))\n",
    "#print(\"Dot product between vector1 and vector4:\", dot_product(vector1, vector4))\n",
    "#\n",
    "## Calculate cosine similarity\n",
    "#print(\"Cosine similarity between vector1 and vector2:\", cosine_similarity(vector1, vector2))\n",
    "#print(\"Cosine similarity between vector1 and vector3:\", cosine_similarity(vector1, vector3))\n",
    "#print(\"Cosine similarity between vector1 and vector4:\", cosine_similarity(vector1, vector4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiaOufr0l069"
   },
   "source": [
    "Notice for both dot product and cosine similarity the comparisons of `vector1` and `vector2` are the opposite of `vector1` and `vector4`.\n",
    "\n",
    "Comparing `vector1` and `vector2` both equations return positive values (14 for dot product and 1.0 for cosine similarity).\n",
    "\n",
    "But comparing `vector1` and `vector4` the result is in the negative direction.\n",
    "\n",
    "This makes sense because `vector4` is the negative version of `vector1`.\n",
    "\n",
    "Whereas comparing `vector1` and `vector3` shows a different outcome.\n",
    "\n",
    "For the dot product, the value is positive and larger then the comparison of two exactly the same vectors (32 vs 14).\n",
    "\n",
    "However, for the cosine similarity, thanks to the normalization step, comparing `vector1` and `vector3` results in a postive value close to 1 but not exactly 1.\n",
    "\n",
    "It is because of this that when comparing text embeddings, cosine similarity is generally favoured as it measures the difference in direction of a pair of vectors rather than difference in magnitude.\n",
    "\n",
    "And it is this difference in direction that is more generally considered to capture the semantic meaning/vibe of the text.\n",
    "\n",
    "The good news is that as mentioned before, the outputs of our embedding model `all-mpnet-base-v2` are already normalized.\n",
    "\n",
    "So we can continue using the dot product (cosine similarity is dot product + normalization).\n",
    "\n",
    "With similarity measures explained, let's functionize our semantic search steps from above so we can repeat them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cR2PU5NKl069"
   },
   "source": [
    "### Functionizing our semantic search pipeline\n",
    "\n",
    "Let's put all of the steps from above for semantic search into a function or two so we can repeat the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Se7N8Qztl069"
   },
   "outputs": [],
   "source": [
    "def retrieve_relevant_resources(query: str,\n",
    "                                embeddings: torch.tensor,\n",
    "                                model: SentenceTransformer=embedding_model,\n",
    "                                n_resources_to_return: int=5,\n",
    "                                print_time: bool=True):\n",
    "    \"\"\"\n",
    "    Embeds a query with model and returns top k scores and indices from embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = model.encode(query,\n",
    "                                   convert_to_tensor=True)\n",
    "\n",
    "    # Get dot product scores on embeddings\n",
    "    start_time = timer()\n",
    "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
    "    end_time = timer()\n",
    "\n",
    "    if print_time:\n",
    "        print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "    scores, indices = torch.topk(input=dot_scores,\n",
    "                                 k=n_resources_to_return)\n",
    "\n",
    "    return scores, indices\n",
    "\n",
    "def print_top_results_and_scores(query: str,\n",
    "                                 embeddings: torch.tensor,\n",
    "                                 pages_and_chunks: list[dict]=pages_and_chunks,\n",
    "                                 n_resources_to_return: int=5):\n",
    "    \"\"\"\n",
    "    Takes a query, retrieves most relevant resources and prints them out in descending order.\n",
    "\n",
    "    Note: Requires pages_and_chunks to be formatted in a specific way (see above for reference).\n",
    "    \"\"\"\n",
    "\n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings,\n",
    "                                                  n_resources_to_return=n_resources_to_return)\n",
    "\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(\"Results:\")\n",
    "    # Loop through zipped together scores and indicies\n",
    "    for score, index in zip(scores, indices):\n",
    "        print(f\"Score: {score:.4f}\")\n",
    "        # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
    "        print_wrapped(pages_and_chunks[index][\"sentence_chunk\"])\n",
    "        # Print the page number too so we can reference the textbook further and check the results\n",
    "        print(f\"Page number: {pages_and_chunks[index]['page_number']}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCoT3diOl069"
   },
   "source": [
    "Excellent! Now let's test our functions out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Z1cQZ99el069",
    "outputId": "2d209b2d-2e85-4a74-894c-7de0001261ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 133 embeddings: 0.00069 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.0877, 0.0644, 0.0600, 0.0540, 0.0459], device='cuda:0'),\n",
       " tensor([ 19, 124,  31, 123, 125], device='cuda:0'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"symptoms of pellagra\"\n",
    "from time import perf_counter as timer\n",
    "\n",
    "# Get just the scores and indices of top related results\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "scores, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "uMBdvMSQl06-",
    "outputId": "6eec0061-1f57-43a2-f467-916223320b00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 133 embeddings: 0.00005 seconds.\n",
      "Query: symptoms of pellagra\n",
      "\n",
      "Results:\n",
      "Score: 0.0877\n",
      "You can put a guard in each fragment to indicate under what condition it can\n",
      "run. A guard of else indicates a fragment that should run if no other guard is\n",
      "true. If all guards are false and there is no else, then none\n",
      "Page number: 5\n",
      "\n",
      "\n",
      "Score: 0.0644\n",
      "any absence from class. Three cases of Late will be equal to 1 absence. Use\n",
      "proper academic references – APA Referencing only. Academic Dishonesty /\n",
      "Plagiarism is a serious offence.\n",
      "Page number: 7\n",
      "\n",
      "\n",
      "Score: 0.0600\n",
      "Exit/ display message Cancelling Appointment Entry/ received request Do/\n",
      "cancelling the appointment Exit/ display message • A transition is the path\n",
      "taken during a change of state from one state to the next in response to a\n",
      "triggering event • Guard condition: Optional condition to be evaluated; if\n",
      "false, the transition is not taken Transitions State Machines Transitions Slide\n",
      "‹#› of 20 Waiting for Approval Creating Appointment Viewing Appointment List\n",
      "Initiate [true]/ get appointment list submitted [true]/ sent to approval queue\n",
      "submitted [false]/ request new input Applying Appointment Submit Clicked [true]/\n",
      "Creating Trigger event or action\n",
      "Page number: 3\n",
      "\n",
      "\n",
      "Score: 0.0540\n",
      "% Continuous Assessment Individual Assignment Week 3 Week 8-9 10% Individual\n",
      "Assignment Week 3 Week 13-14 30% Final Assessment Exam Exam Week - 60%\n",
      "Assessment requirement: Include any specific requirement to pass the module\n",
      "(refer to module handbook for the information), such as: To pass the module, you\n",
      "must attempt every element of assessment and achieve at least 50% in the module\n",
      "overall. Abide by ALL rules and regulations of APU. Proper attire. Attendance is\n",
      "compulsory.\n",
      "Page number: 6\n",
      "\n",
      "\n",
      "Score: 0.0459\n",
      "Any suspicions will be referred to the University’s Academic Dishonesty Board.\n",
      "Formal assessments must be submitted on time in the specified format given.\n",
      "Failure to meet deadlines will be treated as non- submission and no marks will\n",
      "be awarded. Incomplete submissions will be subjected to penalty of mark\n",
      "deductions or forfeit.\n",
      "Page number: 7\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the texts of the top scores\n",
    "print_top_results_and_scores(query=query,\n",
    "                             embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading LLM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEfzFbyql06-"
   },
   "source": [
    "### Checking local GPU memory availability\n",
    "\n",
    "Let's find out what hardware we've got available and see what kind of model(s) we'll be able to load.\n",
    "\n",
    "> **Note:** You can also check this with the `!nvidia-smi` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PzckE6hfl06-",
    "outputId": "94b3c813-6772-40d3-b988-afe63c559948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU memory: 6 GB\n"
     ]
    }
   ],
   "source": [
    "# Get GPU available memory\n",
    "import torch\n",
    "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
    "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
    "gpu_memory_gb = 6\n",
    "print(f\"Available GPU memory: {gpu_memory_gb} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TuMBhHs5l06-",
    "outputId": "93123b85-b348-4d59-ab52-49b6b4183b78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory: 6 | Recommended model: Gemma 2B in 4-bit precision.\n",
      "use_quantization_config set to: True\n",
      "model_id set to: google/gemma-2b-it\n"
     ]
    }
   ],
   "source": [
    "# Note: the following is Gemma focused, however, there are more and more LLMs of the 2B and 7B size appearing for local use.\n",
    "if gpu_memory_gb < 5.1:\n",
    "    print(f\"Your available GPU memory is {gpu_memory_gb}GB, you may not have enough memory to run a Gemma LLM locally without quantization.\")\n",
    "elif gpu_memory_gb < 8.1:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in 4-bit precision.\")\n",
    "    use_quantization_config = True\n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "elif gpu_memory_gb < 19.0:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in float16 or Gemma 7B in 4-bit precision.\")\n",
    "    use_quantization_config = False\n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "elif gpu_memory_gb > 19.0:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommend model: Gemma 7B in 4-bit or float16 precision.\")\n",
    "    use_quantization_config = False\n",
    "    model_id = \"google/gemma-7b-it\"\n",
    "\n",
    "print(f\"use_quantization_config set to: {use_quantization_config}\")\n",
    "print(f\"model_id set to: {model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRvOj0TAl06-"
   },
   "source": [
    "### Loading an LLM locally\n",
    "\n",
    "Alright! Looks like `gemma-7b-it` it is (for my local machine with an RTX 4090, change the `model_id` and `use_quantization_config` values to suit your needs)!\n",
    "\n",
    "There are plenty of examples of how to load the model on the `gemma-7b-it` [Hugging Face model card](https://huggingface.co/google/gemma-7b-it).\n",
    "\n",
    "Good news is, the Hugging Face [`transformers`](https://huggingface.co/docs/transformers/) library has all the tools we need.\n",
    "\n",
    "To load our LLM, we're going to need a few things:\n",
    "1. A quantization config (optional) - This will determine whether or not we load the model in 4bit precision for lower memory usage. The we can create this with the [`transformers.BitsAndBytesConfig`](https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/quantization#transformers.BitsAndBytesConfig) class (requires installing the [`bitsandbytes` library](https://github.com/TimDettmers/bitsandbytes)).\n",
    "2. A model ID - This is the reference Hugging Face model ID which will determine which tokenizer and model gets used. For example `gemma-7b-it`.\n",
    "3. A tokenzier - This is what will turn our raw text into tokens ready for the model. We can create it using the [`transformers.AutoTokenzier.from_pretrained`](https://huggingface.co/docs/transformers/v4.38.2/en/model_doc/auto#transformers.AutoTokenizer) method and passing it our model ID.\n",
    "4. An LLM model - Again, using our model ID we can load a specific LLM model. To do so we can use the [`transformers.AutoModelForCausalLM.from_pretrained`](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForCausalLM.from_pretrained) method and passing it our model ID as well as other various parameters.\n",
    "\n",
    "As a bonus, we'll check if [Flash Attention 2](https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2) is available using `transformers.utils.is_flash_attn_2_available()`. Flash Attention 2 speeds up the attention mechanism in Transformer architecture models (which is what many modern LLMs are based on, including Gemma). So if it's available and the model is supported (not all models support Flash Attention 2), we'll use it. If it's not available, you can install it by following the instructions on the [GitHub repo](https://github.com/Dao-AILab/flash-attention).\n",
    "\n",
    "> **Note:** Flash Attention 2 currently works on NVIDIA GPUs with a compute capability score of 8.0+ (Ampere, Ada Lovelace, Hopper architectures). We can check our GPU compute capability score with [`torch.cuda.get_device_capability(0)`](https://pytorch.org/docs/stable/generated/torch.cuda.get_device_capability.html).\n",
    "\n",
    "> **Note:** To get access to the Gemma models, you will have to [agree to the terms & conditions](https://huggingface.co/google/gemma-7b-it) on the Gemma model page on Hugging Face. You will then have to authorize your local machine via the [Hugging Face CLI/Hugging Face Hub `login()` function](https://huggingface.co/docs/huggingface_hub/en/quick-start#authentication). Once you've done this, you'll be able to download the models. If you're using Google Colab, you can add a [Hugging Face token](https://huggingface.co/docs/hub/en/security-tokens) to the \"Secrets\" tab.\n",
    ">\n",
    "> Downloading an LLM locally can take a fair bit of time depending on your internet connection. Gemma 7B is about a 16GB download and Gemma 2B is about a 6GB download.\n",
    "\n",
    "Let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "60a7efc798a14a2a8c68ce3063368715"
     ]
    },
    "id": "p8dADd5Jl06-",
    "outputId": "56376a7f-cdd5-4cc3-8799-ccc1808eb4f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:32: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<>:33: SyntaxWarning: invalid escape sequence '\\H'\n",
      "<>:38: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<>:40: SyntaxWarning: invalid escape sequence '\\H'\n",
      "<>:32: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<>:33: SyntaxWarning: invalid escape sequence '\\H'\n",
      "<>:38: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<>:40: SyntaxWarning: invalid escape sequence '\\H'\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_1324\\3334276752.py:32: SyntaxWarning: invalid escape sequence '\\g'\n",
      "  tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=\"models\\gemma-2b\",\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_1324\\3334276752.py:33: SyntaxWarning: invalid escape sequence '\\H'\n",
      "  cache_dir=\"D:\\HuggingFace\",\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_1324\\3334276752.py:38: SyntaxWarning: invalid escape sequence '\\g'\n",
      "  llm_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=\"models\\gemma-2b\",\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_1324\\3334276752.py:40: SyntaxWarning: invalid escape sequence '\\H'\n",
      "  cache_dir=\"D:\\HuggingFace\",\n",
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[INFO] Using attention implementation: sdpa\n",
      "[INFO] Using model_id: google/gemma-2b-it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:22<00:00, 11.23s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.utils import is_flash_attn_2_available\n",
    "\n",
    "\n",
    "# 1. Create quantization config for smaller model loading (optional)\n",
    "# Requires !pip install bitsandbytes accelerate, see: https://github.com/TimDettmers/bitsandbytes, https://huggingface.co/docs/accelerate/\n",
    "# For models that require 4-bit quantization (use this if you have low GPU memory available)\n",
    "from transformers import BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_use_double_quant=True,\n",
    "                                          bnb_4bit_quant_type=\"nf4\",\n",
    "                                          bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "\n",
    "# Bonus: Setup Flash Attention 2 for faster inference, default to \"sdpa\" or \"scaled dot product attention\" if it's not available\n",
    "# Flash Attention 2 requires NVIDIA GPU compute capability of 8.0 or above, see: https://developer.nvidia.com/cuda-gpus\n",
    "# Requires !pip install flash-attn, see: https://github.com/Dao-AILab/flash-attention\n",
    "print(is_flash_attn_2_available())\n",
    "if (is_flash_attn_2_available()) and (torch.cuda.get_device_capability(0)[0] >= 8):\n",
    "  attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "  attn_implementation = \"sdpa\"\n",
    "print(f\"[INFO] Using attention implementation: {attn_implementation}\")\n",
    "\n",
    "# 2. Pick a model we'd like to use (this will depend on how much GPU memory you have available)\n",
    "#model_id = \"google/gemma-7b-it\"\n",
    "model_id = \"google/gemma-2b-it\" # (we already set this above)\n",
    "print(f\"[INFO] Using model_id: {model_id}\")\n",
    "access_token = \"put your access token here\"\n",
    "\n",
    "# 3. Instantiate tokenizer (tokenizer turns text into numbers ready for the model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=\"models\\gemma-2b\", \n",
    "                                          cache_dir=\"D:\\HuggingFace\", \n",
    "                                          token=access_token,\n",
    "                                          local_files_only=True)\n",
    "\n",
    "# 4. Instantiate the model\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=\"models\\gemma-2b\",\n",
    "                                               token=access_token,\n",
    "                                               cache_dir=\"D:\\HuggingFace\",\n",
    "                                               local_files_only=True,\n",
    "                                               quantization_config=quantization_config,\n",
    "                                               torch_dtype=torch.float16, # datatype to use, we want float16\n",
    "                                               low_cpu_mem_usage=True, # use full memory\n",
    "                                               attn_implementation=attn_implementation) # which attention version to use\n",
    "\n",
    "#llm_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XbYI5y0l06-"
   },
   "source": [
    "We've got an LLM!\n",
    "\n",
    "Let's check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Q3x7casjl06-",
    "outputId": "9b5042d9-069e-44f8-b2f3-146657334d90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaForCausalLM(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-17): 18 x GemmaDecoderLayer(\n",
       "        (self_attn): GemmaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): GemmaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): GemmaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=16384, out_features=2048, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): GemmaRMSNorm()\n",
       "        (post_attention_layernorm): GemmaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): GemmaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8ax32ICl06_"
   },
   "source": [
    "Ok, ok a bunch of layers ranging from embedding layers to attention layers (see the `GemmaFlashAttention2` layers!) to MLP and normalization layers.\n",
    "\n",
    "The good news is that we don't have to know too much about these to use the model.\n",
    "\n",
    "How about we get the number of parameters in our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1NHSf3ZQl06_",
    "outputId": "7af7647e-5338-4ad3-a2f9-27de3c9a45a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1515268096"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_num_params(model: torch.nn.Module):\n",
    "    return sum([param.numel() for param in model.parameters()])\n",
    "\n",
    "get_model_num_params(llm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFadcXdCl06_"
   },
   "source": [
    "Hmm, turns out that Gemma 7B is really Gemma 8.5B.\n",
    "\n",
    "It pays to do your own investigations!\n",
    "\n",
    "How about we get the models memory requirements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9WcsKnMFl06_",
    "outputId": "f6cc1ae0-53a9-4ca9-aae2-764349cf5426"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_mem_bytes': 2039631872, 'model_mem_mb': 1945.14, 'model_mem_gb': 1.9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_mem_size(model: torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Get how much memory a PyTorch model takes up.\n",
    "\n",
    "    See: https://discuss.pytorch.org/t/gpu-memory-that-model-uses/56822\n",
    "    \"\"\"\n",
    "    # Get model parameters and buffer sizes\n",
    "    mem_params = sum([param.nelement() * param.element_size() for param in model.parameters()])\n",
    "    mem_buffers = sum([buf.nelement() * buf.element_size() for buf in model.buffers()])\n",
    "\n",
    "    # Calculate various model sizes\n",
    "    model_mem_bytes = mem_params + mem_buffers # in bytes\n",
    "    model_mem_mb = model_mem_bytes / (1024**2) # in megabytes\n",
    "    model_mem_gb = model_mem_bytes / (1024**3) # in gigabytes\n",
    "\n",
    "    return {\"model_mem_bytes\": model_mem_bytes,\n",
    "            \"model_mem_mb\": round(model_mem_mb, 2),\n",
    "            \"model_mem_gb\": round(model_mem_gb, 2)}\n",
    "\n",
    "get_model_mem_size(llm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Db3euU1fl06_"
   },
   "source": [
    "Nice, looks like this model takes up 15.97GB of space on the GPU.\n",
    "\n",
    "Plus a little more for the forward pass (due to all the calculations happening between the layers).\n",
    "\n",
    "Hence why I rounded it up to be ~19GB in the table above.\n",
    "\n",
    "Now let's get to the fun part, generating some text!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_Ovjx2Bl06_"
   },
   "source": [
    "### Generating text with our LLM\n",
    "\n",
    "We can generate text with our LLM `model` instance by calling the [`generate()` method](https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/text_generation#transformers.GenerationConfig) (this method has plenty of options to pass into it alongside the text) on it and passing it a tokenized input.\n",
    "\n",
    "The tokenized input comes from passing a string of text to our `tokenizer`.\n",
    "\n",
    "It's important to note that you should use a tokenizer that has been paired with a model.\n",
    "\n",
    "Otherwise if you try to use a different tokenizer and then pass those inputs to a model, you will likely get errors/strange results.\n",
    "\n",
    "For some LLMs, there's a specific template you should pass to them for ideal outputs.\n",
    "\n",
    "For example, the `gemma-7b-it` model has been trained in a dialogue fashion (instruction tuning).\n",
    "\n",
    "In this case, our `tokenizer` has a [`apply_chat_template()` method](https://huggingface.co/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.apply_chat_template) which can prepare our input text in the right format for the model.\n",
    "\n",
    "Let's try it out.\n",
    "\n",
    "> **Note:** The following demo has been modified from the Hugging Face model card for [Gemma 7B](https://huggingface.co/google/gemma-7b-it). Many similar demos of usage are available on the model cards of similar models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YlTORYDIl06_",
    "outputId": "993cab8e-743e-49fa-e6cf-a0ced52a6ac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "What are the macronutrients, and what roles do they play in the human body?\n",
      "\n",
      "Prompt (formatted):\n",
      "<bos><start_of_turn>user\n",
      "What are the macronutrients, and what roles do they play in the human body?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What are the macronutrients, and what roles do they play in the human body?\"\n",
    "print(f\"Input text:\\n{input_text}\")\n",
    "\n",
    "# Create prompt template for instruction-tuned model\n",
    "dialogue_template = [\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": input_text}\n",
    "]\n",
    "\n",
    "# Apply the chat template\n",
    "prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                       tokenize=False, # keep as raw text (not tokenized)\n",
    "                                       add_generation_prompt=True)\n",
    "print(f\"\\nPrompt (formatted):\\n{prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91ag5Hm4l06_"
   },
   "source": [
    "Notice the scaffolding around our input text, this is the kind of turn-by-turn instruction tuning our model has gone through.\n",
    "\n",
    "Our next step is to tokenize this formatted text and pass it to our model's `generate()` method.\n",
    "\n",
    "We'll make sure our tokenized text is on the same device as our model (GPU) using `to(\"cuda\")`.\n",
    "\n",
    "Let's generate some text!\n",
    "\n",
    "We'll time it for fun with the `%%time` magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "E02YELGyl06_",
    "outputId": "26b84717-b184-46aa-9d2b-9b18eab35949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input (tokenized):\n",
      "{'input_ids': tensor([[     2,      2,    106,   1645,    108,   1841,    708,    573, 186809,\n",
      "         184592, 235269,    578,   1212,  16065,    749,    984,   1554,    575,\n",
      "            573,   3515,   2971, 235336,    107,    108,    106,   2516,    108]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\gemma\\modeling_gemma.py:573: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output (tokens):\n",
      "tensor([     2,      2,    106,   1645,    108,   1841,    708,    573, 186809,\n",
      "        184592, 235269,    578,   1212,  16065,    749,    984,   1554,    575,\n",
      "           573,   3515,   2971, 235336,    107,    108,    106,   2516,    108,\n",
      "         21404, 235269,   1517, 235303, 235256,    476,  25497,    576,    573,\n",
      "        186809, 184592,    578,   1024,  16065,    575,    573,   3515,   2971,\n",
      "        235292,    109,    688,  12298,   1695, 184592,    688,    708,  37132,\n",
      "           674,    573,   2971,   4026,    575,   8107,  15992,   1178,  34366,\n",
      "        235265,   2365,   3658,    573,   4547,  13854,    604,  29703, 235269,\n",
      "         44760, 235269,    578,   1156,  24582,    674,   1501,    908,    573,\n",
      "          2971, 235265,    109,    688,    651,   2149,   1872, 186809, 184592,\n",
      "           708,  66058,    109, 235287,   5231, 156615,  56227,  66058,  34428,\n",
      "          4134,    604,    573,   2971, 235303, 235256,   5999,    578,  29703,\n",
      "        235265,   2365,    708,    573,   2971, 235303, 235256,   1872,   4303,\n",
      "           576,   9719, 235265,    108, 235287,   5231,  49471,  66058,   2125,\n",
      "          8727,    604,   4547,    578,  68808,  29703, 235269,  44760, 235269,\n",
      "           578,  53186, 235265,   1165,   1170,   7154,    577,  41748,   5330,\n",
      "          9347,   5902, 235265,    108, 235287,   5231,  33690,  66058,  57697,\n",
      "          4134, 235269,   7154,    577,  33398,  48765,    578,  31740, 235269,\n",
      "           578,   7154,    577,   2029,   7459,    573,   2971, 235265,    109,\n",
      "           688,   6273,   2845, 186809, 184592,   3707,  66058,    109, 235287,\n",
      "          5231, 156615,  56227,  66058,    108,    141, 235287,  13702,  72780,\n",
      "        235269,   1582,    685,  30859, 235269, 162835, 235269,    578, 109955,\n",
      "        235269,    708,   7290, 122712,    578,  36105,    731,    573,   2971,\n",
      "        235265,    108,    141, 235287,  25280,  72780, 235269,   1582,    685,\n",
      "         57634, 235269,  20149, 235269,    578,  77723, 235269,    708, 122712,\n",
      "           978,  13708,    578,   3658,    476,  27476,   4303,    576,   4134,\n",
      "        235265,    108, 235287,   5231,  49471,  66058,    108,    141, 235287,\n",
      "         47839,  26005,  22589,    708,    573,   4547,  13854,    576,  20361,\n",
      "        235265,    108,    141, 235287,   8345, 235290,  53763,  26005,  22589,\n",
      "           798,    614,  78472,    731,    573,   2971,    774,   1156,  37132,\n",
      "        235265,    108, 235287,   5231,  33690,  66058,    108,    141, 235287,\n",
      "        128508,   6181,    603,    476], device='cuda:0')\n",
      "\n",
      "CPU times: total: 2.89 s\n",
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Tokenize the input text (turn it into numbers) and send it to GPU\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "print(f\"Model input (tokenized):\\n{input_ids}\\n\")\n",
    "\n",
    "# Generate outputs passed on the tokenized input\n",
    "# See generate docs: https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/text_generation#transformers.GenerationConfig\n",
    "outputs = llm_model.generate(**input_ids,\n",
    "                             max_new_tokens=256) # define the maximum number of new tokens to create\n",
    "print(f\"Model output (tokens):\\n{outputs[0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcrWDD7xl06_"
   },
   "source": [
    "Woohoo! We just generated some text on our local GPU!\n",
    "\n",
    "Well not just yet...\n",
    "\n",
    "Our LLM accepts tokens in and sends tokens back out.\n",
    "\n",
    "We can conver the output tokens to text using [`tokenizer.decode()`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizer.decode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DWrMF0jxl06_",
    "outputId": "b2ee68d8-5c75-44c1-a9b6-5d04adde3f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output (decoded):\n",
      "<bos><bos><start_of_turn>user\n",
      "What are the macronutrients, and what roles do they play in the human body?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "Sure, here's a breakdown of the macronutrients and their roles in the human body:\n",
      "\n",
      "**Macronutrients** are nutrients that the body needs in larger amounts than calories. They provide the building blocks for tissues, enzymes, and other molecules that make up the body.\n",
      "\n",
      "**The three main macronutrients are:**\n",
      "\n",
      "* **Carbohydrates:** Provide energy for the body's cells and tissues. They are the body's main source of fuel.\n",
      "* **Protein:** Is essential for building and repairing tissues, enzymes, and hormones. It also helps to regulate blood sugar levels.\n",
      "* **Fat:** Provides energy, helps to absorb vitamins and minerals, and helps to insulate the body.\n",
      "\n",
      "**Other important macronutrients include:**\n",
      "\n",
      "* **Carbohydrates:**\n",
      "    * Simple carbohydrates, such as glucose, fructose, and lactose, are quickly digested and absorbed by the body.\n",
      "    * Complex carbohydrates, such as starch, fiber, and cellulose, are digested more slowly and provide a sustained source of energy.\n",
      "* **Protein:**\n",
      "    * Essential amino acids are the building blocks of proteins.\n",
      "    * Non-essential amino acids can be synthesized by the body from other nutrients.\n",
      "* **Fat:**\n",
      "    * Dietary fat is a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decode the output tokens to text\n",
    "outputs_decoded = tokenizer.decode(outputs[0])\n",
    "print(f\"Model output (decoded):\\n{outputs_decoded}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7vyRcx1l07A"
   },
   "source": [
    "Woah! That looks like a pretty good answer.\n",
    "\n",
    "But notice how the output contains the prompt text as well?\n",
    "\n",
    "How about we do a little formatting to replace the prompt in the output text?\n",
    "\n",
    "> **Note:** `\"<bos>\"` and `\"<eos>\"` are special tokens to denote \"beginning of sentence\" and \"end of sentence\" respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VSCKc45Jl07A",
    "outputId": "166735d2-641b-4654-9eab-c252030af3cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: What are the macronutrients, and what roles do they play in the human body?\n",
      "\n",
      "Output text:\n",
      "Sure, here's a breakdown of the macronutrients and their roles in the human body:\n",
      "\n",
      "**Macronutrients** are nutrients that the body needs in larger amounts than calories. They provide the building blocks for tissues, enzymes, and other molecules that make up the body.\n",
      "\n",
      "**The three main macronutrients are:**\n",
      "\n",
      "* **Carbohydrates:** Provide energy for the body's cells and tissues. They are the body's main source of fuel.\n",
      "* **Protein:** Is essential for building and repairing tissues, enzymes, and hormones. It also helps to regulate blood sugar levels.\n",
      "* **Fat:** Provides energy, helps to absorb vitamins and minerals, and helps to insulate the body.\n",
      "\n",
      "**Other important macronutrients include:**\n",
      "\n",
      "* **Carbohydrates:**\n",
      "    * Simple carbohydrates, such as glucose, fructose, and lactose, are quickly digested and absorbed by the body.\n",
      "    * Complex carbohydrates, such as starch, fiber, and cellulose, are digested more slowly and provide a sustained source of energy.\n",
      "* **Protein:**\n",
      "    * Essential amino acids are the building blocks of proteins.\n",
      "    * Non-essential amino acids can be synthesized by the body from other nutrients.\n",
      "* **Fat:**\n",
      "    * Dietary fat is a\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input text: {input_text}\\n\")\n",
    "print(f\"Output text:\\n{outputs_decoded.replace(prompt, '').replace('<bos>', '').replace('<eos>', '')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSxEW_5hl07A"
   },
   "source": [
    "How cool is that!\n",
    "\n",
    "We just officially generated text from an LLM running locally.\n",
    "\n",
    "So we've covered the R (retrieval) and G (generation) of RAG.\n",
    "\n",
    "How about we check out the last step?\n",
    "\n",
    "Augmentation.\n",
    "\n",
    "First, let's put together a list of queries we can try out with our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YmBPmA1Hl07A"
   },
   "outputs": [],
   "source": [
    "# Nutrition-style questions generated with GPT4\n",
    "gpt4_questions = [\n",
    "    \"What are the macronutrients, and what roles do they play in the human body?\",\n",
    "    \"How do vitamins and minerals differ in their roles and importance for health?\",\n",
    "    \"Describe the process of digestion and absorption of nutrients in the human body.\",\n",
    "    \"What role does fibre play in digestion? Name five fibre containing foods.\",\n",
    "    \"Explain the concept of energy balance and its importance in weight management.\"\n",
    "]\n",
    "\n",
    "# Manually created question list\n",
    "manual_questions = [\n",
    "    \"How often should infants be breastfed?\",\n",
    "    \"What are symptoms of pellagra?\",\n",
    "    \"How does saliva help with digestion?\",\n",
    "    \"What is the RDI for protein per day?\",\n",
    "    \"water soluble vitamins\"\n",
    "]\n",
    "\n",
    "query_list = gpt4_questions + manual_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NX-Mj9XXl07A"
   },
   "source": [
    "And now let's check if our `retrieve_relevant_resources()` function works with our list of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "q14-3Y_bl07A",
    "outputId": "48af748c-ff36-4968-f8d7-6f171b867dae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How often should infants be breastfed?\n",
      "[INFO] Time taken to get scores on 133 embeddings: 0.00006 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.1373, 0.1077, 0.0738, 0.0661, 0.0622], device='cuda:0'),\n",
       " tensor([123, 121, 132,  21,  29], device='cuda:0'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "query = random.choice(query_list)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Get just the scores and indices of top related results\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "scores, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzdVb7sWl07A"
   },
   "source": [
    "Beautiful!\n",
    "\n",
    "Let's augment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dq_80636l07A"
   },
   "source": [
    "### Augmenting our prompt with context items\n",
    "\n",
    "What we'd like to do with augmentation is take the results from our search for relevant resources and put them into the prompt that we pass to our LLM.\n",
    "\n",
    "In essence, we start with a base prompt and update it with context text.\n",
    "\n",
    "Let's write a function called `prompt_formatter` that takes in a query and our list of context items (in our case it'll be select indices from our list of dictionaries inside `pages_and_chunks`) and then formats the query with text from the context items.\n",
    "\n",
    "We'll apply the dialogue and chat template to our prompt before returning it as well.\n",
    "\n",
    "> **Note:** The process of augmenting or changing a prompt to an LLM is known as prompt engineering. And the best way to do it is an active area of research. For a comprehensive guide on different prompt engineering techniques, I'd recommend the Prompt Engineering Guide ([promptingguide.ai](https://www.promptingguide.ai/)), [Brex's Prompt Engineering Guide](https://github.com/brexhq/prompt-engineering) and the paper [Prompt Design and Engineering: Introduction and Advanced Models](https://arxiv.org/abs/2401.14423)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "L_4SsfKwl07A"
   },
   "outputs": [],
   "source": [
    "def prompt_formatter(query: str,\n",
    "                     context_items: list[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Augments query with text-based context from context_items.\n",
    "    \"\"\"\n",
    "    # Join context items into one dotted paragraph\n",
    "    context = \"- \" + \"\\n- \".join([item[\"sentence_chunk\"] for item in context_items])\n",
    "\n",
    "    # Create a base prompt with examples to help the model\n",
    "    # Note: this is very customizable, I've chosen to use 3 examples of the answer style we'd like.\n",
    "    # We could also write this in a txt file and import it in if we wanted.\n",
    "    base_prompt = \"\"\"Based on the following context items, please answer the query.\n",
    "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
    "Don't return the thinking, only return the answer.\n",
    "Make sure your answers are as explanatory as possible.\n",
    "Use the following examples as reference for the ideal answer style.\n",
    "\\nExample 1:\n",
    "Query: What are the fat-soluble vitamins?\n",
    "Answer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\n",
    "\\nExample 2:\n",
    "Query: What are the causes of type 2 diabetes?\n",
    "Answer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\n",
    "\\nExample 3:\n",
    "Query: What is the importance of hydration for physical performance?\n",
    "Answer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\n",
    "\\nNow use the following context to answer the user query:\n",
    "{context}\n",
    "\\nRelevant passages: <extract relevant passages from the context here>\n",
    "User query: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Update base prompt with context items and query\n",
    "    base_prompt = base_prompt.format(context=context, query=query)\n",
    "    \n",
    "    # Create prompt template for instruction-tuned model\n",
    "    dialogue_template = [\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": base_prompt}\n",
    "    ]\n",
    "    print(dialogue_template)\n",
    "    # Apply the chat template\n",
    "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                          tokenize=False,\n",
    "                                          add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYCQpdWll07B"
   },
   "source": [
    "What a good looking prompt!\n",
    "\n",
    "We can tokenize this and pass it straight to our LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUtM4Jozl07B"
   },
   "source": [
    "\n",
    "How about we functionize the generation step to make it easier to use?\n",
    "\n",
    "We can put a little formatting on the text being returned to make it look nice too.\n",
    "\n",
    "And we'll make an option to return the context items if needed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rHpOPHIIl07B"
   },
   "outputs": [],
   "source": [
    "def ask(query,\n",
    "        temperature=0.7,\n",
    "        max_new_tokens=512,\n",
    "        format_answer_text=True,\n",
    "        return_references=True):\n",
    "    \"\"\"\n",
    "    Takes a query, finds relevant resources/context and generates an answer to the query based on the relevant resources.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get just the scores and indices of top related results\n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings)\n",
    "\n",
    "    # Create a list of context items\n",
    "    context_items = [pages_and_chunks[i] for i in indices]\n",
    "\n",
    "    # Add score to context item\n",
    "    for i, item in enumerate(context_items):\n",
    "        item[\"score\"] = scores[i].cpu() # return score back to CPU\n",
    "\n",
    "    # Format the prompt with context items\n",
    "    prompt = prompt_formatter(query=query,\n",
    "                              context_items=context_items)\n",
    "\n",
    "    # Tokenize the prompt\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate an output of tokens\n",
    "    outputs = llm_model.generate(**input_ids,\n",
    "                                 temperature=temperature,\n",
    "                                 do_sample=True,\n",
    "                                 max_new_tokens=max_new_tokens)\n",
    "\n",
    "    # Turn the output tokens into text\n",
    "    output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "    if format_answer_text:\n",
    "        # Replace special tokens and unnecessary help message\n",
    "        output_text = output_text.replace(prompt, \"\").replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").replace(\"Sure, here is the answer to the user query:\\n\\n\", \"\")\n",
    "\n",
    "    # Only return the answer without the context items\n",
    "    if return_references:\n",
    "        return output_text, context_items\n",
    "\n",
    "    return output_text, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtpIifj3l07B"
   },
   "source": [
    "What a good looking function!\n",
    "\n",
    "The workflow could probably be a little refined but this should work!\n",
    "\n",
    "Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "cO3YVVHjl07B",
    "outputId": "23f475d8-a716-4b57-c37d-6c3f2316a9ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How do vitamins and minerals differ in their roles and importance for health?\n",
      "[INFO] Time taken to get scores on 133 embeddings: 0.00008 seconds.\n",
      "[{'role': 'user', 'content': \"Based on the following context items, please answer the query.\\nGive yourself room to think by extracting relevant passages from the context before answering the query.\\nDon't return the thinking, only return the answer.\\nMake sure your answers are as explanatory as possible.\\nUse the following examples as reference for the ideal answer style.\\n\\nExample 1:\\nQuery: What are the fat-soluble vitamins?\\nAnswer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\\n\\nExample 2:\\nQuery: What are the causes of type 2 diabetes?\\nAnswer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\\n\\nExample 3:\\nQuery: What is the importance of hydration for physical performance?\\nAnswer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\\n\\nNow use the following context to answer the user query:\\n- Students learn to allocate their time efficiently, which is a crucial life skill. Self-Discipline: Working independently requires self-discipline. It helps students develop the ability to stay focused and avoid distractions, leading to improved productivity. Confidence Building: As students successfully complete assignments on their own, it boosts their confidence in their abilities and problem-solving skills, contributing to a positive self-image.\\n- Packages Slide <18> of 32 Possible relationships between packages are dependency and generalization/specialization relationships. Packages may be used to contain classes, objects, or use cases. Packages Slide <19> of 32 An active object can be used to depict a concurrent object, process, thread, or task.\\n- Object and Class Structuring CT015-3-2 Design Methods TOPIC LEARNING OUTCOMES At the end of this topic, you should be able to: 1. Describe object structuring criteria and categories Object structuring criteria and categories Contents & Structure Recap From Last Lesson What is multiplicity?First attempt at determining the software objects in the system.a class is categorized by the role it plays in the application.\\n- Expectations Complete your assignments with independence, which means you are self-reliant and can handle them on your own, minimizing the need for external help or close supervision. Enhanced Problem-Solving Skills: It encourages students to think critically and solve problems on their own. This skill extends beyond assignments and proves valuable in various aspects of life. Time Management: Independently managing assignments fosters better time management skills.\\n- It is represented as a straight, slightly thicker line in an activity diagram. Elements in Activity Diagram Example: Elements\\n\\nRelevant passages: <extract relevant passages from the context here>\\nUser query: How do vitamins and minerals differ in their roles and importance for health?\\nAnswer:\"}]\n",
      "Answer:\n",
      "\n",
      "The context does not provide any information about the roles and importance of vitamins and minerals, so I cannot answer this query from the provided context.\n",
      "Context items:\n",
      "- SOURCE:Introduction and Module Overview_DMTD VE.pptx.PageNumber:7.Context:Students learn to allocate their time efficiently, which is a crucial life skill. Self-Discipline: Working independently requires self-discipline. It helps students develop the ability to stay focused and avoid distractions, leading to improved productivity. Confidence Building: As students successfully complete assignments on their own, it boosts their confidence in their abilities and problem-solving skills, contributing to a positive self-image.\n",
      "- SOURCE:3_Overview of the UML notations.pptx.PageNumber:5.Context:Packages Slide <18> of 32 Possible relationships between packages are dependency and generalization/specialization relationships. Packages may be used to contain classes, objects, or use cases. Packages Slide <19> of 32 An active object can be used to depict a concurrent object, process, thread, or task.\n",
      "- SOURCE:10_Object and Class Structuring.pptx.PageNumber:1.Context:Object and Class Structuring CT015-3-2 Design Methods TOPIC LEARNING OUTCOMES At the end of this topic, you should be able to: 1. Describe object structuring criteria and categories Object structuring criteria and categories Contents & Structure Recap From Last Lesson What is multiplicity?First attempt at determining the software objects in the system.a class is categorized by the role it plays in the application.\n",
      "- SOURCE:Introduction and Module Overview_DMTD VE.pptx.PageNumber:7.Context:Expectations Complete your assignments with independence, which means you are self-reliant and can handle them on your own, minimizing the need for external help or close supervision. Enhanced Problem-Solving Skills: It encourages students to think critically and solve problems on their own. This skill extends beyond assignments and proves valuable in various aspects of life. Time Management: Independently managing assignments fosters better time management skills.\n",
      "- SOURCE:8_Behavior Modelling Part 3.pptx.PageNumber:4.Context:It is represented as a straight, slightly thicker line in an activity diagram. Elements in Activity Diagram Example: Elements\n"
     ]
    }
   ],
   "source": [
    "query = random.choice(query_list)\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Answer query with context and return context\n",
    "answer, context_items = ask(query=query,\n",
    "                            temperature=0.7,\n",
    "                            max_new_tokens=512,\n",
    "                            return_references=True)\n",
    "\n",
    "print(f\"Answer:\\n\")\n",
    "print(answer)\n",
    "#print_wrapped(answer)\n",
    "print(f\"Context items:\")\n",
    "context = \"- \" + \"\\n- \".join([str(\"SOURCE:\" + item[\"pdf_name\"] + \".PageNumber:\" + str(item[\"page_number\"]) + \".Context:\" + item[\"sentence_chunk\"]) for item in context_items])\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e14TK6Nfl07B"
   },
   "source": [
    "Local RAG workflow complete!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting in Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.26.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (5.3.0)\n",
      "Requirement already satisfied: fastapi in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.110.1)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==0.15.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.22.2)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (3.8.4)\n",
      "Requirement already satisfied: numpy~=1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (3.10.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (24.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.2.1)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (10.3.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.6.4)\n",
      "Requirement already satisfied: pydub in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.3.5)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer[all]<1.0,>=0.9 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.9.4)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.29.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio-client==0.15.1->gradio) (2024.3.1)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio-client==0.15.1->gradio) (11.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.21.1)\n",
      "Requirement already satisfied: toolz in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (4.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (3.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.3)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.0->gradio) (2.16.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.1)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi->gradio) (0.37.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.17.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
    "!pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "IMPORTANT: You are using gradio version 4.26.0, however version 4.44.1 is available, please upgrade.\n",
      "--------\n",
      "Running on public URL: https://0cd3b9788049e026bb.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://0cd3b9788049e026bb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 133 embeddings: 0.00035 seconds.\n",
      "[{'role': 'user', 'content': \"Based on the following context items, please answer the query.\\nGive yourself room to think by extracting relevant passages from the context before answering the query.\\nDon't return the thinking, only return the answer.\\nMake sure your answers are as explanatory as possible.\\nUse the following examples as reference for the ideal answer style.\\n\\nExample 1:\\nQuery: What are the fat-soluble vitamins?\\nAnswer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\\n\\nExample 2:\\nQuery: What are the causes of type 2 diabetes?\\nAnswer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\\n\\nExample 3:\\nQuery: What is the importance of hydration for physical performance?\\nAnswer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\\n\\nNow use the following context to answer the user query:\\n- Behaviour Modelling (Continue) CT015-3-2 Design Methods TOPIC LEARNING OUTCOMES At the end of this topic, you should be able to: 1. Documenting use cases Documenting Use Cases based on Use Case Diagram Contents & Structure Recap From Last Lesson What is use case?How to naming use case?Each use case in the model requires a detailed description to fully understand its functionality.\\n- Behaviour Modelling (Continue) CT015-3-2 Design Methods TOPIC LEARNING OUTCOMES At the end of this topic, you should be able to: Describe the kinds of actions in an activity Describe control and object flows Create an activity diagram Elements in an activity diagram Control and object flows Contents & Structure Recap From Last Lesson What is post condition?Explain standard flows / process. Activity diagrams show the order or flow of operations in a system. An activity diagram is like a flowchart that shows the sequence of activities in a process.\\n- Behaviour Modelling (Continue) CT015-3-2 Design Methods TOPIC LEARNING OUTCOMES At the end of this topic, you should be able to: Describe the elements in a state machine diagram Create a state machine diagram Finite State Machine Modelling -Notations Contents & Structure Recap From Last Lesson Describes differences between lifeline and message. Also referred to as state machine Finite state machines are used for modeling the control and sequencing view of a system or object. Notations used to define finite state machines are the state transition, triggering events and actions. Finite State Machines Shows the behavior of one object of a single class shows all possible states of this object shows how the object’s state changes as a result of messages it receives Finite State Machines • State = a recognizable situation that exists over an interval of\\n- Behaviour Modelling CT015-3-2 Design Methods TOPIC LEARNING OUTCOMES At the end of this topic, you should be able to: Describe the elements in a use-case diagram Describe the associations and relationships in a use-case model Create a use-case diagram Use case notations Relationship Contents & Structure Recap From Last Lesson When will you create a class diagram based on the COMET methodology phase?A use case defines a sequence of interactions between one or more actors and the system. A use case diagram elements - actors, use cases and system boundaries. The system is defined through the system boundaries.\\n- Explain activities that occur in Analysis Modeling. Slide <2> of 21 Summary of Teaching points Software Methodology (COMET) Slide <2> of 21 Behaviour Modelling What We Will Cover Next Slide <#> of 24\\n\\nRelevant passages: <extract relevant passages from the context here>\\nUser query: What is Behaviour Modelling\\nAnswer:\"}]\n",
      "[INFO] Time taken to get scores on 133 embeddings: 0.00006 seconds.\n",
      "[{'role': 'user', 'content': \"Based on the following context items, please answer the query.\\nGive yourself room to think by extracting relevant passages from the context before answering the query.\\nDon't return the thinking, only return the answer.\\nMake sure your answers are as explanatory as possible.\\nUse the following examples as reference for the ideal answer style.\\n\\nExample 1:\\nQuery: What are the fat-soluble vitamins?\\nAnswer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\\n\\nExample 2:\\nQuery: What are the causes of type 2 diabetes?\\nAnswer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\\n\\nExample 3:\\nQuery: What is the importance of hydration for physical performance?\\nAnswer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\\n\\nNow use the following context to answer the user query:\\n- Encloses a sequence that might or might not happen. You can specify, in the guard, the condition under which it occurs. Alt Contains a list of fragments that contain alternative sequences of messages. Only one sequence occurs on any occasion.\\n- Design Methods CT015-3-2 (Version E) Week 1 Introduction and Module Overview Lecturer Name: Salasiah Sulaiman Email: salasiah@apu.edu.my Consultation Hours: Refer to iConsult Lecturer Information Systems Analysis & Design CT026-3-1 or equivalent Pre-Requisites For This Module OBE is education based on producing particular educational outcomes that: Focus on what students can actually do after they are taught. Expect all learners / students to successfully achieve particular (sometimes minimum) level of knowledge and abilities. It’s NOT what We want to teach. It’s WHAT You should learn.\\n- Use Case Built in early stages of development To demonstrate the different ways that a user might interact with a system.\\n- Behaviour Modelling (Continue) CT015-3-2 Design Methods TOPIC LEARNING OUTCOMES At the end of this topic, you should be able to: 1. Documenting use cases Documenting Use Cases based on Use Case Diagram Contents & Structure Recap From Last Lesson What is use case?How to naming use case?Each use case in the model requires a detailed description to fully understand its functionality.\\n- Combined Fragments Slide <13> of 23 Combined Fragments Slide <14> of 23 Alternative fragment box Loop/iterative fragment box Optional fragment box Interaction use / reference fragment box Use Case Specification Slide <11> of 23 Alternative Process N/A Exception Flow\\n\\nRelevant passages: <extract relevant passages from the context here>\\nUser query: \\nAnswer:\"}]\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def question(message, history, return_references):\n",
    "  answer, context_items = ask   (query=message,\n",
    "                                temperature=0.9,\n",
    "                                max_new_tokens=512,\n",
    "                                return_references=return_references)\n",
    "  if context_items == None:\n",
    "    return answer\n",
    "  else:\n",
    "    context = \"\\n\".join([\n",
    "f\"\"\"{index+1}. src: http://localhost:3000/pdfs/{item[\"pdf_name\"]}#page={item[\"page_number\"]}.\n",
    "PageNumber: **{item[\"page_number\"]}**.\n",
    "> \"{item[\"sentence_chunk\"]}\"\n",
    "\n",
    "*****\n",
    "\n",
    "\"\"\" for index, item in enumerate(context_items)])\n",
    "    result = answer + \"\\n## References:\\n\" + context\n",
    "    return result  # Return both the answer and the return_answer\n",
    "\n",
    "\n",
    "demo = gr.ChatInterface(question,\n",
    "                        additional_inputs=[\n",
    "                            gr.Checkbox(label=\"Return References\", interactive=True)\n",
    "                        ]\n",
    "                        )\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The context does not provide any information about the macronutrients, so I cannot answer this question from the provided context.\n",
      "## References:\n",
      "1. src: http://localhost:3000/pdfs/10_Object and Class Structuring.pptx#1.\n",
      "\n",
      "PageNumber: **1**.\n",
      "> \"Object and Class Structuring CT015-3-2 Design Methods TOPIC LEARNING OUTCOMES At the end of this topic, you should be able to: 1. Describe object structuring criteria and categories Object structuring criteria and categories Contents & Structure Recap From Last Lesson What is multiplicity?First attempt at determining the software objects in the system.a class is categorized by the role it plays in the application.\"\n",
      "\n",
      "*****\n",
      "\n",
      "\n",
      "1. src: http://localhost:3000/pdfs/13_Overview of other UML diagrams.pptx#5.\n",
      "\n",
      "PageNumber: **5**.\n",
      "> \"Reading Slide ‹18› of 20 Other UML Diagrams Slide ‹19› of 20 Summary of Main Teaching Points Question and Answer Session Slide ‹20› of 20 Q & A\"\n",
      "\n",
      "*****\n",
      "\n",
      "\n",
      "1. src: http://localhost:3000/pdfs/13_Overview of other UML diagrams.pptx#2.\n",
      "\n",
      "PageNumber: **2**.\n",
      "> \"Package Diagram, Deployment Diagram. Structure Diagrams Slide ‹5› of 20 Is a graph of instances, including objects and data values. A static object diagram is an instance of a class diagram Use a subset of the elements of a class diagram in order to emphasize the relationship between instances of classes at some point in time Object Diagram Slide ‹6› of 20 Object Diagram Slide ‹7› of 20 Higher level of abstraction than a Class Diagram Component diagram shows components, provided and required interfaces, ports, and relationships between them. Component Diagram Slide ‹8› of 20 Package diagram is UML structure diagram which shows structure of the designed system at the level of packages.\"\n",
      "\n",
      "*****\n",
      "\n",
      "\n",
      "1. src: http://localhost:3000/pdfs/3_Overview of the UML notations.pptx#2.\n",
      "\n",
      "PageNumber: **2**.\n",
      "> \"Use case diagram Slide <5> of 32 Use case diagram Slide <6> of 32 Classes and objects are depicted as boxes. The class box holds the class name Optionally, the attributes and operations of a class may also be depicted. Classes and Objects Slide <7> of 32 To distinguish between a class (the type) and an object (an instance of the type), an object name is shown underlined. Classes and objects are depicted on various UML diagrams Classes and Objects Slide <8> of 32 In a class diagram, classes are depicted as boxes, and the relationships between them are depicted as lines connecting the boxes.\"\n",
      "\n",
      "*****\n",
      "\n",
      "\n",
      "1. src: http://localhost:3000/pdfs/3_Overview of the UML notations.pptx#5.\n",
      "\n",
      "PageNumber: **5**.\n",
      "> \"Packages Slide <18> of 32 Possible relationships between packages are dependency and generalization/specialization relationships. Packages may be used to contain classes, objects, or use cases. Packages Slide <19> of 32 An active object can be used to depict a concurrent object, process, thread, or task.\"\n",
      "\n",
      "*****\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = \"\\n\".join([\n",
    "f\"\"\"1. src: http://localhost:3000/pdfs/{item[\"pdf_name\"]}#{item[\"page_number\"]}.\n",
    "\n",
    "PageNumber: **{item[\"page_number\"]}**.\n",
    "> \"{item[\"sentence_chunk\"]}\"\n",
    "\n",
    "*****\n",
    "\n",
    "\"\"\" for item in context_items])\n",
    "result = answer + \"\\n## References:\\n\" + context\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
